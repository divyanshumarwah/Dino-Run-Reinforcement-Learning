{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 3 of /Users/divyanshumarwah/anaconda3/lib/python3.7/site-packages/googleapis_common_protos-1.6.0-py3.7-nspkg.pth:\n",
      "\n",
      "  Traceback (most recent call last):\n",
      "    File \"/Users/divyanshumarwah/anaconda3/lib/python3.7/site.py\", line 168, in addpackage\n",
      "      exec(line)\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"<frozen importlib._bootstrap>\", line 580, in module_from_spec\n",
      "  AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\n",
      "Remainder of file ignored\n",
      "Requirement already satisfied: selenium in /Users/divyanshumarwah/anaconda3/lib/python3.7/site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in /Users/divyanshumarwah/anaconda3/lib/python3.7/site-packages (from selenium) (1.24.2)\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "!pip install selenium\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 #opencv\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from random import randint\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#keras imports\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD , Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from collections import deque\n",
    "import random\n",
    "import pickle\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path variables\n",
    "game_url = \"chrome://dino\"\n",
    "chrome_driver_path = \"./chrome_driver/chromedriver\"\n",
    "loss_file_path = \"./objects/loss_df.csv\"\n",
    "actions_file_path = \"./objects/actions_df.csv\"\n",
    "q_value_file_path = \"./objects/q_values.csv\"\n",
    "scores_file_path = \"./objects/scores_df.csv\"\n",
    "\n",
    "#scripts\n",
    "#create id for canvas for faster selection from DOM\n",
    "init_script = \"document.getElementsByClassName('runner-canvas')[0].id = 'runner-canvas'\"\n",
    "\n",
    "#get image from canvas\n",
    "getbase64Script = \"canvasRunner = document.getElementById('runner-canvas'); \\\n",
    "return canvasRunner.toDataURL().substring(22)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Game class: Selenium interfacing between the python and browser\n",
    "* __init__():  Launch the broswer window using the attributes in chrome_options\n",
    "* get_crashed() : return true if the agent as crashed on an obstacles. Gets javascript variable from game decribing the state\n",
    "* get_playing(): true if game in progress, false is crashed or paused\n",
    "* restart() : sends a signal to browser-javascript to restart the game\n",
    "* press_up(): sends a single to press up get to the browser\n",
    "* get_score(): gets current game score from javascript variables.\n",
    "* pause(): pause the game\n",
    "* resume(): resume a paused game if not crashed\n",
    "* end(): close the browser and end the game\n",
    "'''\n",
    "class Game:\n",
    "    def __init__(self,custom_config=True):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"disable-infobars\")\n",
    "        chrome_options.add_argument(\"--mute-audio\")\n",
    "        self._driver = webdriver.Chrome(executable_path = chrome_driver_path,chrome_options=chrome_options)\n",
    "        self._driver.set_window_position(x=-10,y=0)\n",
    "        self._driver.get('chrome://dino')\n",
    "        self._driver.execute_script(\"Runner.config.ACCELERATION=0\")\n",
    "        self._driver.execute_script(init_script)\n",
    "    def get_crashed(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.crashed\")\n",
    "    def get_playing(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.playing\")\n",
    "    def restart(self):\n",
    "        self._driver.execute_script(\"Runner.instance_.restart()\")\n",
    "    def press_up(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ARROW_UP)\n",
    "    def get_score(self):\n",
    "        score_array = self._driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = ''.join(score_array) # the javascript object is of type array with score in the formate[1,0,0] which is 100.\n",
    "        return int(score)\n",
    "    def pause(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.stop()\")\n",
    "    def resume(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.play()\")\n",
    "    def end(self):\n",
    "        self._driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinoAgent:\n",
    "    def __init__(self,game): #takes game as input for taking actions\n",
    "        self._game = game; \n",
    "        self.jump(); #to start the game, we need to jump once\n",
    "    def is_running(self):\n",
    "        return self._game.get_playing()\n",
    "    def is_crashed(self):\n",
    "        return self._game.get_crashed()\n",
    "    def jump(self):\n",
    "        self._game.press_up()\n",
    "    def duck(self):\n",
    "        self._game.press_down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game_sate:\n",
    "    def __init__(self,agent,game):\n",
    "        self._agent = agent\n",
    "        self._game = game\n",
    "        self._display = show_img() #display the processed image on screen using openCV, implemented using python coroutine \n",
    "        self._display.__next__() # initiliaze the display coroutine \n",
    "    def get_state(self,actions):\n",
    "        actions_df.loc[len(actions_df)] = actions[1] # storing actions in a dataframe\n",
    "        score = self._game.get_score() \n",
    "        reward = 0.1\n",
    "        is_over = False #game over\n",
    "        if actions[1] == 1:\n",
    "            self._agent.jump()\n",
    "        image = grab_screen(self._game._driver) \n",
    "        self._display.send(image) #display the image on screen\n",
    "        if self._agent.is_crashed():\n",
    "            scores_df.loc[len(loss_df)] = score # log the score when game is over\n",
    "            self._game.restart()\n",
    "            reward = -1\n",
    "            is_over = True\n",
    "        return image, reward, is_over #return the Experience tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('./objects/'+ name + '.pkl', 'wb') as f: #dump files into objects folder\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "def load_obj(name ):\n",
    "    with open('./objects/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def grab_screen(_driver):\n",
    "    image_b64 = _driver.execute_script(getbase64Script)\n",
    "    screen = np.array(Image.open(BytesIO(base64.b64decode(image_b64))))\n",
    "    image = process_img(screen)#processing image as required\n",
    "    return image\n",
    "\n",
    "def process_img(image):\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #RGB to Grey Scale\n",
    "    image = image[:300, :500] #Crop Region of Interest(ROI)\n",
    "    image = cv2.resize(image, (80,80))\n",
    "    return  image\n",
    "\n",
    "def show_img(graphs = False):\n",
    "    \"\"\"\n",
    "    Show images in new window\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        screen = (yield)\n",
    "        window_title = \"logs\" if graphs else \"game_play\"\n",
    "        cv2.namedWindow(window_title, cv2.WINDOW_NORMAL)        \n",
    "        imS = cv2.resize(screen, (800, 400)) \n",
    "        cv2.imshow(window_title, screen)\n",
    "        if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize log structures from file if exists else create new\n",
    "loss_df = pd.read_csv(loss_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns =['loss'])\n",
    "scores_df = pd.read_csv(scores_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns = ['scores'])\n",
    "actions_df = pd.read_csv(actions_file_path) if os.path.isfile(actions_file_path) else pd.DataFrame(columns = ['actions'])\n",
    "q_values_df =pd.read_csv(actions_file_path) if os.path.isfile(q_value_file_path) else pd.DataFrame(columns = ['qvalues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game parameters\n",
    "ACTIONS = 2 # possible actions: jump, do nothing\n",
    "GAMMA = 0.99 # decay rate of past observations original 0.99\n",
    "OBSERVATION = 100. # timesteps to observe before training\n",
    "EXPLORE = 100000  # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.0001 # final value of epsilon\n",
    "INITIAL_EPSILON = 0.1 # starting value of epsilon\n",
    "REPLAY_MEMORY = 50000 # number of previous transitions to remember\n",
    "BATCH = 16 # size of minibatch\n",
    "FRAME_PER_ACTION = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "img_rows , img_cols = 80,80\n",
    "img_channels = 4 #We stack 4 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# training variables saved as checkpoints to filesystem to resume training from the same step\n",
    "def init_cache():\n",
    "    \"\"\"initial variable caching, done only once\"\"\"\n",
    "    save_obj(INITIAL_EPSILON,\"epsilon\")\n",
    "    t = 0\n",
    "    save_obj(t,\"time\")\n",
    "    D = deque()\n",
    "    save_obj(D,\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Call only once to init file structure\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Call only once to init file structure\n",
    "'''\n",
    "#init_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildmodel():\n",
    "    print(\"Now we build the model\")\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (8, 8), padding='same',strides=(4, 4),input_shape=(img_cols,img_rows,img_channels)))  #80*80*4\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (4, 4),strides=(2, 2),  padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3),strides=(1, 1),  padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(ACTIONS))\n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    model.compile(loss='mse',optimizer=adam)\n",
    "    \n",
    "    #create model file if not present\n",
    "    if not os.path.isfile(loss_file_path):\n",
    "        model.save_weights('model.h5')\n",
    "    print(\"We finish building the model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "main training module\n",
    "Parameters:\n",
    "* model => Keras Model to be trained\n",
    "* game_state => Game State module with access to game environment and dino\n",
    "* observe => flag to indicate wherther the model is to be trained(weight updates), else just play\n",
    "'''\n",
    "def trainNetwork(model,game_state,observe=False):\n",
    "    last_time = time.time()\n",
    "    # store the previous observations in replay memory\n",
    "    D = load_obj(\"D\") #load from file system\n",
    "    # get the first state by doing nothing\n",
    "    do_nothing = np.zeros(ACTIONS)\n",
    "    do_nothing[0] =1 #0 => do nothing,\n",
    "                     #1=> jump\n",
    "    \n",
    "    x_t, r_0, terminal = game_state.get_state(do_nothing) # get next step after performing the action\n",
    "    \n",
    "\n",
    "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2) # stack 4 images to create placeholder input\n",
    "    \n",
    "\n",
    "    \n",
    "    s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])  #1*20*40*4\n",
    "    \n",
    "    initial_state = s_t \n",
    "\n",
    "    if observe :\n",
    "        OBSERVE = 999999999    #We keep observe, never train\n",
    "        epsilon = FINAL_EPSILON\n",
    "        print (\"Now we load weight\")\n",
    "        model.load_weights(\"model.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "        print (\"Weight load successfully\")    \n",
    "    else:                       #We go to training mode\n",
    "        OBSERVE = OBSERVATION\n",
    "        epsilon = load_obj(\"epsilon\") \n",
    "        model.load_weights(\"model.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "\n",
    "    t = load_obj(\"time\") # resume from the previous time step stored in file system\n",
    "    while (True): #endless running\n",
    "        \n",
    "        loss = 0\n",
    "        Q_sa = 0\n",
    "        action_index = 0\n",
    "        r_t = 0 #reward at 4\n",
    "        a_t = np.zeros([ACTIONS]) # action at t\n",
    "        \n",
    "        #choose an action epsilon greedy\n",
    "        if t % FRAME_PER_ACTION == 0: #parameter to skip frames for actions\n",
    "            if  random.random() <= epsilon: #randomly explore an action\n",
    "                print(\"----------Random Action----------\")\n",
    "                action_index = random.randrange(ACTIONS)\n",
    "                a_t[action_index] = 1\n",
    "            else: # predict the output\n",
    "                q = model.predict(s_t)       #input a stack of 4 images, get the prediction\n",
    "                max_Q = np.argmax(q)         # chosing index with maximum q value\n",
    "                action_index = max_Q \n",
    "                a_t[action_index] = 1        # o=> do nothing, 1=> jump\n",
    "                \n",
    "        #We reduced the epsilon (exploration parameter) gradually\n",
    "        if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE \n",
    "\n",
    "        #run the selected action and observed next state and reward\n",
    "        x_t1, r_t, terminal = game_state.get_state(a_t)\n",
    "        print('fps: {0}'.format(1 / (time.time()-last_time))) # helpful for measuring frame rate\n",
    "        last_time = time.time()\n",
    "        x_t1 = x_t1.reshape(1, x_t1.shape[0], x_t1.shape[1], 1) #1x20x40x1\n",
    "        s_t1 = np.append(x_t1, s_t[:, :, :, :3], axis=3) # append the new image to input stack and remove the first one\n",
    "        \n",
    "        \n",
    "        # store the transition in D\n",
    "        D.append((s_t, action_index, r_t, s_t1, terminal))\n",
    "        if len(D) > REPLAY_MEMORY:\n",
    "            D.popleft()\n",
    "\n",
    "        #only train if done observing\n",
    "        if t > OBSERVE: \n",
    "            \n",
    "            #sample a minibatch to train on\n",
    "            minibatch = random.sample(D, BATCH)\n",
    "            inputs = np.zeros((BATCH, s_t.shape[1], s_t.shape[2], s_t.shape[3]))   #32, 20, 40, 4\n",
    "            targets = np.zeros((inputs.shape[0], ACTIONS))                         #32, 2\n",
    "\n",
    "            #Now we do the experience replay\n",
    "            for i in range(0, len(minibatch)):\n",
    "                state_t = minibatch[i][0]    # 4D stack of images\n",
    "                action_t = minibatch[i][1]   #This is action index\n",
    "                reward_t = minibatch[i][2]   #reward at state_t due to action_t\n",
    "                state_t1 = minibatch[i][3]   #next state\n",
    "                terminal = minibatch[i][4]   #wheather the agent died or survided due the action\n",
    "                \n",
    "\n",
    "                inputs[i:i + 1] = state_t    \n",
    "\n",
    "                targets[i] = model.predict(state_t)  # predicted q values\n",
    "                Q_sa = model.predict(state_t1)      #predict q values for next step\n",
    "                \n",
    "                if terminal:\n",
    "                    targets[i, action_t] = reward_t # if terminated, only equals reward\n",
    "                else:\n",
    "                    targets[i, action_t] = reward_t + GAMMA * np.max(Q_sa)\n",
    "\n",
    "            loss += model.train_on_batch(inputs, targets)\n",
    "            loss_df.loc[len(loss_df)] = loss\n",
    "            q_values_df.loc[len(q_values_df)] = np.max(Q_sa)\n",
    "        s_t = initial_state if terminal else s_t1 #reset game to initial frame if terminate\n",
    "        t = t + 1\n",
    "        \n",
    "        # save progress every 1000 iterations\n",
    "        if t % 1000 == 0:\n",
    "            print(\"Now we save model\")\n",
    "            game_state._game.pause() #pause game while saving to filesystem\n",
    "            model.save_weights(\"model.h5\", overwrite=True)\n",
    "            save_obj(D,\"D\") #saving episodes\n",
    "            save_obj(t,\"time\") #caching time steps\n",
    "            save_obj(epsilon,\"epsilon\") #cache epsilon to avoid repeated randomness in actions\n",
    "            loss_df.to_csv(\"./objects/loss_df.csv\",index=False)\n",
    "            scores_df.to_csv(\"./objects/scores_df.csv\",index=False)\n",
    "            actions_df.to_csv(\"./objects/actions_df.csv\",index=False)\n",
    "            q_values_df.to_csv(q_value_file_path,index=False)\n",
    "            with open(\"model.json\", \"w\") as outfile:\n",
    "                json.dump(model.to_json(), outfile)\n",
    "            clear_output()\n",
    "            game_state._game.resume()\n",
    "        # print info\n",
    "        state = \"\"\n",
    "        if t <= OBSERVE:\n",
    "            state = \"observe\"\n",
    "        elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "            state = \"explore\"\n",
    "        else:\n",
    "            state = \"train\"\n",
    "\n",
    "        print(\"TIMESTEP\", t, \"/ STATE\", state,             \"/ EPSILON\", epsilon, \"/ ACTION\", action_index, \"/ REWARD\", r_t,             \"/ Q_MAX \" , np.max(Q_sa), \"/ Loss \", loss)\n",
    "\n",
    "    print(\"Episode finished!\")\n",
    "    print(\"************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function\n",
    "def playGame(observe=False):\n",
    "    game = Game()\n",
    "    dino = DinoAgent(game)\n",
    "    game_state = Game_sate(dino,game)    \n",
    "    model = buildmodel()\n",
    "    try:\n",
    "        trainNetwork(model,game_state,observe=observe)\n",
    "    except StopIteration:\n",
    "        game.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 168000 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.918343 / Loss  0.04561358690261841\n",
      "fps: 0.18825257984737476\n",
      "TIMESTEP 168001 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.858714 / Loss  0.12031500041484833\n",
      "fps: 9.512317036109712\n",
      "TIMESTEP 168002 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.976743 / Loss  0.11943970620632172\n",
      "fps: 10.443619993326926\n",
      "TIMESTEP 168003 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.37862 / Loss  0.08359667658805847\n",
      "fps: 10.605147447388982\n",
      "TIMESTEP 168004 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.022592 / Loss  0.0821111872792244\n",
      "fps: 10.577653363596243\n",
      "TIMESTEP 168005 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  2.0756605 / Loss  0.07464657723903656\n",
      "fps: 10.670085731003079\n",
      "TIMESTEP 168006 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.389736 / Loss  0.12790627777576447\n",
      "fps: 8.839138910255734\n",
      "TIMESTEP 168007 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.94319 / Loss  0.023392029106616974\n",
      "fps: 10.672692203952224\n",
      "TIMESTEP 168008 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.020161 / Loss  0.11643829941749573\n",
      "fps: 8.726080434732859\n",
      "TIMESTEP 168009 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.595384 / Loss  0.067903071641922\n",
      "fps: 8.25975580937377\n",
      "TIMESTEP 168010 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.9948513 / Loss  0.09681287407875061\n",
      "fps: 10.609734750560298\n",
      "TIMESTEP 168011 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.630637 / Loss  2.142162561416626\n",
      "fps: 10.2671467772455\n",
      "TIMESTEP 168012 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.222311 / Loss  0.14373832941055298\n",
      "fps: 10.620669048589711\n",
      "TIMESTEP 168013 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.010332 / Loss  0.04223001375794411\n",
      "fps: 10.427755609422587\n",
      "TIMESTEP 168014 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.066553 / Loss  0.034646641463041306\n",
      "fps: 10.567126876952534\n",
      "TIMESTEP 168015 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.898111 / Loss  0.0405920073390007\n",
      "fps: 10.411887657073066\n",
      "TIMESTEP 168016 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.738842 / Loss  0.09362002462148666\n",
      "fps: 9.160529149294446\n",
      "TIMESTEP 168017 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.31354 / Loss  0.08747021853923798\n",
      "fps: 10.53331793045601\n",
      "TIMESTEP 168018 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.880346 / Loss  0.06960077583789825\n",
      "fps: 9.131352186880891\n",
      "TIMESTEP 168019 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.24907 / Loss  0.06047987937927246\n",
      "fps: 10.758598046458179\n",
      "TIMESTEP 168020 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.379504 / Loss  0.11330612748861313\n",
      "fps: 10.181560428303365\n",
      "TIMESTEP 168021 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.066475 / Loss  0.10624220222234726\n",
      "fps: 8.906333145763215\n",
      "TIMESTEP 168022 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.986856 / Loss  0.09132145345211029\n",
      "fps: 10.211777996357723\n",
      "TIMESTEP 168023 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.909899 / Loss  0.0969085544347763\n",
      "fps: 10.250836455530383\n",
      "TIMESTEP 168024 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.728834 / Loss  0.138235405087471\n",
      "fps: 10.33711232476981\n",
      "TIMESTEP 168025 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.370916 / Loss  0.0320720374584198\n",
      "fps: 10.854908293801453\n",
      "TIMESTEP 168026 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.9232645 / Loss  0.07747023552656174\n",
      "fps: 8.850105606981666\n",
      "TIMESTEP 168027 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.934981 / Loss  0.2599804401397705\n",
      "fps: 9.25488361624805\n",
      "TIMESTEP 168028 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  16.319313 / Loss  0.17342105507850647\n",
      "fps: 8.863290379568152\n",
      "TIMESTEP 168029 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.191089 / Loss  0.02822657860815525\n",
      "fps: 8.960254304092492\n",
      "TIMESTEP 168030 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.347729 / Loss  0.13808012008666992\n",
      "fps: 10.845028687856983\n",
      "TIMESTEP 168031 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.238315 / Loss  0.03928150609135628\n",
      "fps: 10.364392958456476\n",
      "TIMESTEP 168032 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.231253 / Loss  0.12372832745313644\n",
      "fps: 10.154470403098898\n",
      "TIMESTEP 168033 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.999521 / Loss  0.0682142823934555\n",
      "fps: 8.723648442065986\n",
      "TIMESTEP 168034 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.427338 / Loss  0.07472386956214905\n",
      "fps: 10.641930327556897\n",
      "TIMESTEP 168035 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.204958 / Loss  0.06939102709293365\n",
      "fps: 8.450720797864303\n",
      "TIMESTEP 168036 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.412911 / Loss  0.08091524243354797\n",
      "fps: 10.496807890304545\n",
      "TIMESTEP 168037 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.621628 / Loss  0.047631800174713135\n",
      "fps: 10.737555680712713\n",
      "TIMESTEP 168038 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.397284 / Loss  0.06460733711719513\n",
      "fps: 8.651867009360831\n",
      "TIMESTEP 168039 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.301466 / Loss  0.0671427920460701\n",
      "fps: 10.4101820781129\n",
      "TIMESTEP 168040 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.183895 / Loss  0.08893530815839767\n",
      "fps: 10.534852412241044\n",
      "TIMESTEP 168041 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.47415 / Loss  0.07454027980566025\n",
      "fps: 10.539299642182286\n",
      "TIMESTEP 168042 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.40828 / Loss  0.04742619767785072\n",
      "fps: 10.80346283326937\n",
      "TIMESTEP 168043 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.725144 / Loss  0.06207554042339325\n",
      "fps: 10.62144901111702\n",
      "TIMESTEP 168044 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.411052 / Loss  0.14380988478660583\n",
      "fps: 10.106732272934282\n",
      "TIMESTEP 168045 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.444366 / Loss  0.06864818930625916\n",
      "fps: 8.041874537443583\n",
      "TIMESTEP 168046 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.605285 / Loss  0.06205938383936882\n",
      "fps: 10.645549701012193\n",
      "TIMESTEP 168047 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.357179 / Loss  0.05277785658836365\n",
      "fps: 10.815497479403309\n",
      "TIMESTEP 168048 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.909522 / Loss  0.31179454922676086\n",
      "fps: 9.206151036659511\n",
      "TIMESTEP 168049 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.101122 / Loss  0.035044264048337936\n",
      "fps: 8.339024162330782\n",
      "TIMESTEP 168050 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.931367 / Loss  0.07968255132436752\n",
      "fps: 8.86218546698473\n",
      "TIMESTEP 168051 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.131541 / Loss  0.1334436982870102\n",
      "fps: 10.778891967043755\n",
      "TIMESTEP 168052 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.1637335 / Loss  0.0766153633594513\n",
      "fps: 8.907014030609536\n",
      "TIMESTEP 168053 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.860429 / Loss  0.07275394350290298\n",
      "fps: 9.973946914102815\n",
      "TIMESTEP 168054 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.231348 / Loss  2.87595796585083\n",
      "fps: 10.57184121711032\n",
      "TIMESTEP 168055 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.313777 / Loss  0.06906469911336899\n",
      "fps: 10.431671781811309\n",
      "TIMESTEP 168056 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.358964 / Loss  0.10758877545595169\n",
      "fps: 10.710082681769666\n",
      "TIMESTEP 168057 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.763898 / Loss  0.04879313334822655\n",
      "fps: 9.21648827586813\n",
      "TIMESTEP 168058 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.680855 / Loss  0.08071085065603256\n",
      "fps: 9.529910024538761\n",
      "TIMESTEP 168059 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.85752 / Loss  0.06798221170902252\n",
      "fps: 10.291331028543247\n",
      "TIMESTEP 168060 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.522442 / Loss  0.05281229317188263\n",
      "fps: 10.356459601870645\n",
      "TIMESTEP 168061 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.446311 / Loss  0.05329447239637375\n",
      "fps: 10.906675889256118\n",
      "TIMESTEP 168062 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.763597 / Loss  0.31575873494148254\n",
      "fps: 8.853486889599068\n",
      "TIMESTEP 168063 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.8115015 / Loss  1.0942126512527466\n",
      "fps: 10.652038318146262\n",
      "TIMESTEP 168064 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.97537 / Loss  2.173231363296509\n",
      "fps: 10.52166518243506\n",
      "TIMESTEP 168065 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.549172 / Loss  0.05005215108394623\n",
      "fps: 10.31514746099514\n",
      "TIMESTEP 168066 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.798591 / Loss  0.1136738657951355\n",
      "fps: 10.578213586748179\n",
      "TIMESTEP 168067 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.627013 / Loss  0.0776170864701271\n",
      "fps: 11.069802795490055\n",
      "TIMESTEP 168068 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.451448 / Loss  0.0150722935795784\n",
      "fps: 10.590286124044317\n",
      "TIMESTEP 168069 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.095185 / Loss  0.2822490334510803\n",
      "fps: 8.947180477191036\n",
      "TIMESTEP 168070 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.680997 / Loss  0.13219693303108215\n",
      "fps: 10.462324393358877\n",
      "TIMESTEP 168071 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.694348 / Loss  1.8086282014846802\n",
      "fps: 10.235402065478398\n",
      "TIMESTEP 168072 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.709203 / Loss  0.03761729970574379\n",
      "fps: 10.510380566476972\n",
      "TIMESTEP 168073 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.314562 / Loss  0.14672254025936127\n",
      "fps: 11.07027027027027\n",
      "TIMESTEP 168074 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.679487 / Loss  0.03691352531313896\n",
      "fps: 10.373877728696014\n",
      "TIMESTEP 168075 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.608955 / Loss  0.03027479350566864\n",
      "fps: 10.45072394796445\n",
      "TIMESTEP 168076 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.806489 / Loss  0.09167124330997467\n",
      "fps: 11.051077889433996\n",
      "TIMESTEP 168077 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.15997106 / Loss  0.05624416470527649\n",
      "fps: 9.914041983893805\n",
      "TIMESTEP 168078 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.003925 / Loss  0.05888519063591957\n",
      "fps: 10.157150779409164\n",
      "TIMESTEP 168079 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.840024 / Loss  0.05601197108626366\n",
      "fps: 8.901380951067175\n",
      "TIMESTEP 168080 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.522615 / Loss  0.07666318118572235\n",
      "fps: 8.747555179224289\n",
      "TIMESTEP 168081 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.509046 / Loss  0.0732913538813591\n",
      "fps: 7.031853967998498\n",
      "TIMESTEP 168082 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.417893 / Loss  0.2878282070159912\n",
      "fps: 9.133837828420857\n",
      "TIMESTEP 168083 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.379994 / Loss  0.055275656282901764\n",
      "fps: 8.800100709160338\n",
      "TIMESTEP 168084 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.691256 / Loss  0.059816982597112656\n",
      "fps: 10.351424389979046\n",
      "TIMESTEP 168085 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.845499 / Loss  0.08574989438056946\n",
      "fps: 10.793871049096458\n",
      "TIMESTEP 168086 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.825671 / Loss  0.10636024177074432\n",
      "fps: 10.214812108813716\n",
      "TIMESTEP 168087 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.015725 / Loss  0.1268550604581833\n",
      "fps: 8.868312774603872\n",
      "TIMESTEP 168088 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.335132 / Loss  0.08884580433368683\n",
      "fps: 9.273073776834472\n",
      "TIMESTEP 168089 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.792723 / Loss  0.06647174805402756\n",
      "fps: 8.914169611983311\n",
      "TIMESTEP 168090 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.909423 / Loss  0.024955105036497116\n",
      "fps: 10.361627700152177\n",
      "TIMESTEP 168091 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.902561 / Loss  0.09279153496026993\n",
      "fps: 10.977583169972702\n",
      "TIMESTEP 168092 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.371416 / Loss  0.06329180300235748\n",
      "fps: 10.52816217315237\n",
      "TIMESTEP 168093 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.183098 / Loss  0.436774879693985\n",
      "fps: 10.47832039252131\n",
      "TIMESTEP 168094 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.152079 / Loss  0.039949722588062286\n",
      "fps: 11.019286294146855\n",
      "TIMESTEP 168095 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.4520445 / Loss  0.06252619624137878\n",
      "fps: 9.551721075344727\n",
      "TIMESTEP 168096 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.657283 / Loss  0.04651527851819992\n",
      "fps: 10.591650021085805\n",
      "TIMESTEP 168097 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.636313 / Loss  0.03746788576245308\n",
      "fps: 10.586276697240297\n",
      "TIMESTEP 168098 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.637085 / Loss  0.058796633034944534\n",
      "fps: 10.855751138166562\n",
      "TIMESTEP 168099 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6395015 / Loss  0.034058719873428345\n",
      "fps: 10.65065882526212\n",
      "TIMESTEP 168100 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.303043 / Loss  0.07028435170650482\n",
      "fps: 10.372056332455458\n",
      "TIMESTEP 168101 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.695998 / Loss  0.05717996507883072\n",
      "fps: 10.384433886353902\n",
      "TIMESTEP 168102 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.587367 / Loss  0.062187835574150085\n",
      "fps: 9.199810489743635\n",
      "TIMESTEP 168103 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.976339 / Loss  0.055098310112953186\n",
      "fps: 10.707211910335515\n",
      "TIMESTEP 168104 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.2486051 / Loss  0.03961871564388275\n",
      "fps: 10.682042531516618\n",
      "TIMESTEP 168105 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.713192 / Loss  0.07231350243091583\n",
      "fps: 10.593923963669061\n",
      "TIMESTEP 168106 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.113848 / Loss  0.13088580965995789\n",
      "fps: 8.95455370314625\n",
      "TIMESTEP 168107 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.103232 / Loss  0.08384649455547333\n",
      "fps: 10.614003699701644\n",
      "TIMESTEP 168108 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  7.7009478 / Loss  1.0109089612960815\n",
      "fps: 10.64384774868738\n",
      "TIMESTEP 168109 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.499412 / Loss  0.045116014778614044\n",
      "fps: 10.584139577371669\n",
      "TIMESTEP 168110 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.563198 / Loss  0.10511764138936996\n",
      "fps: 10.162294176366261\n",
      "TIMESTEP 168111 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.219456 / Loss  0.16540421545505524\n",
      "fps: 10.8722691689564\n",
      "TIMESTEP 168112 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.172483 / Loss  0.10245074331760406\n",
      "fps: 10.737335777261231\n",
      "TIMESTEP 168113 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.453786 / Loss  0.05475413054227829\n",
      "fps: 10.829907381825976\n",
      "TIMESTEP 168114 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.255407 / Loss  0.41620150208473206\n",
      "fps: 8.99951293720323\n",
      "TIMESTEP 168115 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.547474 / Loss  0.06604229658842087\n",
      "fps: 10.5991711311028\n",
      "TIMESTEP 168116 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.655933 / Loss  0.030063385143876076\n",
      "fps: 9.96065896121229\n",
      "TIMESTEP 168117 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.943821 / Loss  0.061505820602178574\n",
      "fps: 7.880223275598066\n",
      "TIMESTEP 168118 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.56972 / Loss  0.13199838995933533\n",
      "fps: 10.651686648771234\n",
      "TIMESTEP 168119 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.418929 / Loss  5.849421501159668\n",
      "fps: 10.484606693263741\n",
      "TIMESTEP 168120 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.058023 / Loss  0.10080677270889282\n",
      "fps: 10.654635980287559\n",
      "TIMESTEP 168121 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.647565 / Loss  0.08230068534612656\n",
      "fps: 10.696889863684472\n",
      "TIMESTEP 168122 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.475445 / Loss  0.0710463747382164\n",
      "fps: 10.293578882268056\n",
      "TIMESTEP 168123 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.183012 / Loss  0.027241084724664688\n",
      "fps: 10.801710018027299\n",
      "TIMESTEP 168124 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.177925 / Loss  0.04281982034444809\n",
      "fps: 8.932622580390971\n",
      "TIMESTEP 168125 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.512737 / Loss  0.030300041660666466\n",
      "fps: 10.500802399437195\n",
      "TIMESTEP 168126 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.64806 / Loss  0.647922694683075\n",
      "fps: 9.421443123900742\n",
      "TIMESTEP 168127 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.467144 / Loss  0.06150319054722786\n",
      "fps: 8.818584545257673\n",
      "TIMESTEP 168128 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.008936 / Loss  0.05011248588562012\n",
      "fps: 9.145448757364452\n",
      "TIMESTEP 168129 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.213018 / Loss  0.1193767562508583\n",
      "fps: 10.857886929801627\n",
      "TIMESTEP 168130 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.769107 / Loss  0.058257341384887695\n",
      "fps: 10.72994676346966\n",
      "TIMESTEP 168131 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.639553 / Loss  0.07645021378993988\n",
      "fps: 10.496466395723639\n",
      "TIMESTEP 168132 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.428892 / Loss  0.16596971452236176\n",
      "fps: 10.77285662916731\n",
      "TIMESTEP 168133 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  17.624252 / Loss  0.05385565012693405\n",
      "fps: 10.774710807068562\n",
      "TIMESTEP 168134 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.81843 / Loss  0.08012570440769196\n",
      "fps: 10.37528910920969\n",
      "TIMESTEP 168135 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.920885 / Loss  0.031191661953926086\n",
      "fps: 9.19632086124297\n",
      "TIMESTEP 168136 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  1.3888301 / Loss  0.6867443323135376\n",
      "fps: 11.056933544579094\n",
      "TIMESTEP 168137 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.986169 / Loss  0.09177060425281525\n",
      "fps: 10.482405630198336\n",
      "TIMESTEP 168138 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.09623 / Loss  0.14837980270385742\n",
      "fps: 9.44590729538729\n",
      "TIMESTEP 168139 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.589008 / Loss  0.14629590511322021\n",
      "fps: 10.393826603690359\n",
      "TIMESTEP 168140 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.43035 / Loss  0.1127733588218689\n",
      "fps: 10.342745684053746\n",
      "TIMESTEP 168141 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.256192 / Loss  0.06964261829853058\n",
      "fps: 10.582991231943481\n",
      "TIMESTEP 168142 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.28297 / Loss  0.12287160009145737\n",
      "fps: 10.785017266605125\n",
      "TIMESTEP 168143 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.402248 / Loss  0.07642707228660583\n",
      "fps: 9.032381994258802\n",
      "TIMESTEP 168144 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.40594 / Loss  0.08687452971935272\n",
      "fps: 10.603914113004148\n",
      "TIMESTEP 168145 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.943082 / Loss  0.1139993667602539\n",
      "fps: 10.412456307594535\n",
      "TIMESTEP 168146 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.4951935 / Loss  0.03223288059234619\n",
      "fps: 9.83576356481894\n",
      "TIMESTEP 168147 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.303188 / Loss  0.05784289538860321\n",
      "fps: 10.830942125540991\n",
      "TIMESTEP 168148 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.208119 / Loss  0.12441986799240112\n",
      "fps: 9.322436460220263\n",
      "TIMESTEP 168149 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.253585 / Loss  0.12437364459037781\n",
      "fps: 9.740128790746388\n",
      "TIMESTEP 168150 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.561224 / Loss  3.595088005065918\n",
      "fps: 10.108973292938934\n",
      "TIMESTEP 168151 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.048067 / Loss  0.027337417006492615\n",
      "fps: 10.476043469681871\n",
      "TIMESTEP 168152 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.61129 / Loss  0.07847128063440323\n",
      "fps: 10.288175587835617\n",
      "TIMESTEP 168153 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.755655 / Loss  0.09986317902803421\n",
      "fps: 7.749835554274481\n",
      "TIMESTEP 168154 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.036489 / Loss  0.07519908249378204\n",
      "fps: 10.479446133704442\n",
      "TIMESTEP 168155 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.324982 / Loss  0.1899625062942505\n",
      "fps: 8.637292938278927\n",
      "TIMESTEP 168156 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.245447 / Loss  0.09461040049791336\n",
      "fps: 10.5978320741845\n",
      "TIMESTEP 168157 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.457409 / Loss  0.039052002131938934\n",
      "fps: 10.71845771703687\n",
      "TIMESTEP 168158 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.481721 / Loss  0.2835000157356262\n",
      "fps: 10.205740008516333\n",
      "TIMESTEP 168159 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.587726 / Loss  0.0820104330778122\n",
      "fps: 10.703086164571626\n",
      "TIMESTEP 168160 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.346706 / Loss  0.10812747478485107\n",
      "fps: 10.617066570814549\n",
      "TIMESTEP 168161 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.121829 / Loss  0.3434703052043915\n",
      "fps: 10.586143101964376\n",
      "TIMESTEP 168162 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.154922 / Loss  0.08711983263492584\n",
      "fps: 10.742973646532095\n",
      "TIMESTEP 168163 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.798815 / Loss  0.07158313691616058\n",
      "fps: 10.316492154967372\n",
      "TIMESTEP 168164 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.220909 / Loss  0.15082931518554688\n",
      "fps: 10.88375158612565\n",
      "TIMESTEP 168165 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.485454 / Loss  0.09755140542984009\n",
      "fps: 10.569816465441424\n",
      "TIMESTEP 168166 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.813177 / Loss  0.06154346838593483\n",
      "fps: 10.978732537777557\n",
      "TIMESTEP 168167 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.352492 / Loss  0.11266237497329712\n",
      "fps: 10.592666486515155\n",
      "TIMESTEP 168168 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.7814665 / Loss  0.06547874957323074\n",
      "fps: 9.060498312890724\n",
      "TIMESTEP 168169 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.887446 / Loss  0.9730292558670044\n",
      "fps: 10.577973483845422\n",
      "TIMESTEP 168170 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.272385 / Loss  0.10570424050092697\n",
      "fps: 8.94046728354404\n",
      "TIMESTEP 168171 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.039657 / Loss  0.042232491075992584\n",
      "fps: 9.057582962439884\n",
      "TIMESTEP 168172 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.62106 / Loss  0.059028249233961105\n",
      "fps: 9.465497669905103\n",
      "TIMESTEP 168173 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.093369 / Loss  0.05787975341081619\n",
      "fps: 8.977053881962652\n",
      "TIMESTEP 168174 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.5219555 / Loss  1.8922488689422607\n",
      "fps: 9.170864390807061\n",
      "TIMESTEP 168175 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.175253 / Loss  0.09539288282394409\n",
      "fps: 9.026880679054592\n",
      "TIMESTEP 168176 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  15.02534 / Loss  0.1144794300198555\n",
      "fps: 8.95470664466226\n",
      "TIMESTEP 168177 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.710931 / Loss  0.02821388468146324\n",
      "fps: 9.2538626670991\n",
      "TIMESTEP 168178 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.928219 / Loss  0.07538759708404541\n",
      "fps: 9.055021351375858\n",
      "TIMESTEP 168179 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.02748 / Loss  0.10165730863809586\n",
      "fps: 10.355615798452943\n",
      "TIMESTEP 168180 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.1542425 / Loss  0.046861544251441956\n",
      "fps: 10.778061014719185\n",
      "TIMESTEP 168181 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.440359 / Loss  0.1609119176864624\n",
      "fps: 9.058208919767017\n",
      "TIMESTEP 168182 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.6066265 / Loss  0.13539689779281616\n",
      "fps: 10.600081883109334\n",
      "TIMESTEP 168183 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.261588 / Loss  0.03653033450245857\n",
      "fps: 10.748507259969966\n",
      "TIMESTEP 168184 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  19.083551 / Loss  0.6137258410453796\n",
      "fps: 10.64784684865363\n",
      "TIMESTEP 168185 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.511689 / Loss  0.07969029992818832\n",
      "fps: 9.933930178579887\n",
      "TIMESTEP 168186 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.868045 / Loss  0.10992775857448578\n",
      "fps: 10.505747184017594\n",
      "TIMESTEP 168187 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.726722 / Loss  0.08555848896503448\n",
      "fps: 10.743909280230744\n",
      "TIMESTEP 168188 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.241268 / Loss  0.08354310691356659\n",
      "fps: 10.302706659428603\n",
      "TIMESTEP 168189 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.620522 / Loss  0.13760529458522797\n",
      "fps: 8.177433945784072\n",
      "TIMESTEP 168190 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.117611 / Loss  0.13170607388019562\n",
      "fps: 10.407547282174459\n",
      "TIMESTEP 168191 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.706577 / Loss  0.06920232623815536\n",
      "fps: 8.83494965665417\n",
      "TIMESTEP 168192 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.506016 / Loss  0.127951979637146\n",
      "fps: 10.162811265025647\n",
      "TIMESTEP 168193 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.497534 / Loss  0.10514310002326965\n",
      "fps: 10.936251541628533\n",
      "TIMESTEP 168194 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.777283 / Loss  0.7930912375450134\n",
      "fps: 10.231432174716973\n",
      "TIMESTEP 168195 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.672051 / Loss  0.07036765664815903\n",
      "fps: 10.517470172570299\n",
      "TIMESTEP 168196 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  19.01792 / Loss  0.04462842643260956\n",
      "fps: 10.58157617223963\n",
      "TIMESTEP 168197 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.072128 / Loss  0.10233291983604431\n",
      "fps: 10.639446809158292\n",
      "TIMESTEP 168198 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.676345 / Loss  0.058913737535476685\n",
      "fps: 10.512909589013628\n",
      "TIMESTEP 168199 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.885568 / Loss  0.9287549257278442\n",
      "fps: 10.480860197857501\n",
      "TIMESTEP 168200 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.325158 / Loss  0.08925814926624298\n",
      "fps: 10.607507669274094\n",
      "TIMESTEP 168201 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.1319 / Loss  0.056482747197151184\n",
      "fps: 10.606917515318727\n",
      "TIMESTEP 168202 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.221672 / Loss  0.08460170030593872\n",
      "fps: 10.702621875757536\n",
      "TIMESTEP 168203 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.40576 / Loss  0.07519908249378204\n",
      "fps: 9.185606317767407\n",
      "TIMESTEP 168204 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.995293 / Loss  0.11513081192970276\n",
      "fps: 8.966115499310595\n",
      "TIMESTEP 168205 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.042318 / Loss  0.14770910143852234\n",
      "fps: 9.399379694867244\n",
      "TIMESTEP 168206 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.551911 / Loss  0.45408716797828674\n",
      "fps: 8.79731359499634\n",
      "TIMESTEP 168207 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.680466 / Loss  0.1408492922782898\n",
      "fps: 9.3616588174899\n",
      "TIMESTEP 168208 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.420587 / Loss  0.2273360788822174\n",
      "fps: 10.392641928322233\n",
      "TIMESTEP 168209 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.566404 / Loss  0.10704819113016129\n",
      "fps: 10.429622556589159\n",
      "TIMESTEP 168210 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.611983 / Loss  0.0676778182387352\n",
      "fps: 10.298456816647228\n",
      "TIMESTEP 168211 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.1513815 / Loss  0.11314752697944641\n",
      "fps: 11.003271360251006\n",
      "TIMESTEP 168212 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.695093 / Loss  0.06546925753355026\n",
      "fps: 10.552212558587707\n",
      "TIMESTEP 168213 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.792133 / Loss  0.11074382811784744\n",
      "fps: 8.907014030609536\n",
      "TIMESTEP 168214 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.2341385 / Loss  0.08698330819606781\n",
      "fps: 9.140764987784866\n",
      "TIMESTEP 168215 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  15.208347 / Loss  1.2042511701583862\n",
      "fps: 9.00933302688642\n",
      "TIMESTEP 168216 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.649861 / Loss  0.11271607130765915\n",
      "fps: 9.238290533530979\n",
      "TIMESTEP 168217 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.71026 / Loss  0.15982887148857117\n",
      "fps: 9.127258800181052\n",
      "TIMESTEP 168218 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.98552 / Loss  0.1424548625946045\n",
      "fps: 8.864789006260278\n",
      "TIMESTEP 168219 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  15.172163 / Loss  0.14322006702423096\n",
      "fps: 8.914340123099942\n",
      "TIMESTEP 168220 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.986854 / Loss  0.11798496544361115\n",
      "fps: 10.63421362216543\n",
      "TIMESTEP 168221 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.859886 / Loss  0.16180500388145447\n",
      "fps: 8.720673817627624\n",
      "TIMESTEP 168222 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.792302 / Loss  0.055974364280700684\n",
      "fps: 10.851145186285189\n",
      "TIMESTEP 168223 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.062005 / Loss  0.0610753670334816\n",
      "fps: 10.459819647274758\n",
      "TIMESTEP 168224 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.227486 / Loss  0.08099282532930374\n",
      "fps: 10.161063224656115\n",
      "TIMESTEP 168225 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.397979 / Loss  0.224003404378891\n",
      "fps: 7.937128269759538\n",
      "TIMESTEP 168226 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.014534 / Loss  0.07283676415681839\n",
      "fps: 10.488014923208489\n",
      "TIMESTEP 168227 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.772006 / Loss  0.07586909830570221\n",
      "fps: 10.461228419356608\n",
      "TIMESTEP 168228 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.735689 / Loss  0.15207034349441528\n",
      "fps: 10.65055064485248\n",
      "TIMESTEP 168229 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.119498 / Loss  0.08656381815671921\n",
      "fps: 10.792843376160198\n",
      "TIMESTEP 168230 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.546322 / Loss  0.08093103766441345\n",
      "fps: 10.099066734727291\n",
      "TIMESTEP 168231 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.765356 / Loss  1.3733148574829102\n",
      "fps: 9.196421680406946\n",
      "TIMESTEP 168232 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  15.513773 / Loss  0.08776356279850006\n",
      "fps: 9.187497672625476\n",
      "TIMESTEP 168233 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  15.299778 / Loss  0.19533798098564148\n",
      "fps: 10.451401019149547\n",
      "TIMESTEP 168234 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.899549 / Loss  0.08589071035385132\n",
      "fps: 10.860585973407217\n",
      "TIMESTEP 168235 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.906639 / Loss  3.4020655155181885\n",
      "fps: 10.609976297503017\n",
      "TIMESTEP 168236 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.262327 / Loss  0.12454213201999664\n",
      "fps: 10.388317581089382\n",
      "TIMESTEP 168237 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.815321 / Loss  0.09484496712684631\n",
      "fps: 10.494076555670368\n",
      "TIMESTEP 168238 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.25211 / Loss  0.13379257917404175\n",
      "fps: 10.726489234648602\n",
      "TIMESTEP 168239 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.091428 / Loss  0.07185791432857513\n",
      "fps: 10.54531466456815\n",
      "TIMESTEP 168240 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.346678 / Loss  0.11920450627803802\n",
      "fps: 10.503326814096576\n",
      "TIMESTEP 168241 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.210124 / Loss  0.06587745249271393\n",
      "fps: 9.22066210723244\n",
      "TIMESTEP 168242 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.303237 / Loss  0.21885403990745544\n",
      "fps: 10.388755000185766\n",
      "TIMESTEP 168243 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.790114 / Loss  0.07570798695087433\n",
      "fps: 9.16725642634051\n",
      "TIMESTEP 168244 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.659603 / Loss  0.07714985311031342\n",
      "fps: 8.98713308949413\n",
      "TIMESTEP 168245 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  15.147661 / Loss  0.08264152705669403\n",
      "fps: 8.843294847899607\n",
      "TIMESTEP 168246 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.929804 / Loss  0.12165716290473938\n",
      "fps: 10.174694162710532\n",
      "TIMESTEP 168247 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.132601 / Loss  0.15698446333408356\n",
      "fps: 8.776622479833437\n",
      "TIMESTEP 168248 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD -1 / Q_MAX  15.593386 / Loss  0.08173079788684845\n",
      "fps: 9.798516545770987\n",
      "TIMESTEP 168249 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.683832 / Loss  0.050818800926208496\n",
      "fps: 9.933930178579887\n",
      "TIMESTEP 168250 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.549342 / Loss  0.039088986814022064\n",
      "fps: 10.625512047200809\n",
      "TIMESTEP 168251 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.289001 / Loss  0.6863583922386169\n",
      "fps: 9.873713202839017\n",
      "TIMESTEP 168252 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.671621 / Loss  0.21908047795295715\n",
      "fps: 10.866354050623073\n",
      "TIMESTEP 168253 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.017766 / Loss  0.13686597347259521\n",
      "fps: 10.561246509426123\n",
      "TIMESTEP 168254 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.67141 / Loss  0.05807831510901451\n",
      "fps: 9.922884383354232\n",
      "TIMESTEP 168255 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.626919 / Loss  0.07396728545427322\n",
      "fps: 4.539098457965519\n",
      "TIMESTEP 168256 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.129138 / Loss  0.05666498839855194\n",
      "fps: 10.403313738621426\n",
      "TIMESTEP 168257 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.916109 / Loss  3.085749387741089\n",
      "fps: 10.128844830292566\n",
      "TIMESTEP 168258 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.036481 / Loss  0.22136715054512024\n",
      "fps: 10.065741760681176\n",
      "TIMESTEP 168259 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.137909 / Loss  0.41290950775146484\n",
      "fps: 11.013325841103459\n",
      "TIMESTEP 168260 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.873635 / Loss  0.04533751681447029\n",
      "fps: 10.208969319329674\n",
      "TIMESTEP 168261 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.5455065 / Loss  0.11871889233589172\n",
      "fps: 7.791860566643074\n",
      "TIMESTEP 168262 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.154772 / Loss  0.10812264680862427\n",
      "fps: 10.826972023314765\n",
      "TIMESTEP 168263 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.612554 / Loss  0.17335030436515808\n",
      "fps: 10.503642451273294\n",
      "TIMESTEP 168264 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.928804 / Loss  0.20897464454174042\n",
      "fps: 9.428898355570043\n",
      "TIMESTEP 168265 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.921509 / Loss  0.7539875507354736\n",
      "fps: 10.334718095040976\n",
      "TIMESTEP 168266 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.228025 / Loss  1.0595262050628662\n",
      "fps: 10.559332146732357\n",
      "TIMESTEP 168267 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.018895 / Loss  0.10229188203811646\n",
      "fps: 10.468460868414944\n",
      "TIMESTEP 168268 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.946194 / Loss  0.15747401118278503\n",
      "fps: 10.942842532586122\n",
      "TIMESTEP 168269 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.67682 / Loss  0.16335931420326233\n",
      "fps: 10.553327680474236\n",
      "TIMESTEP 168270 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.703102 / Loss  0.12486650794744492\n",
      "fps: 10.498568253268989\n",
      "TIMESTEP 168271 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.509267 / Loss  0.08787532895803452\n",
      "fps: 10.748286907721088\n",
      "TIMESTEP 168272 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.326568 / Loss  0.1336936354637146\n",
      "fps: 8.777081633080126\n",
      "TIMESTEP 168273 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.206901 / Loss  0.13013452291488647\n",
      "fps: 8.925380375800652\n",
      "TIMESTEP 168274 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.9503 / Loss  0.14627690613269806\n",
      "fps: 9.395231940577338\n",
      "TIMESTEP 168275 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.23959 / Loss  0.21510887145996094\n",
      "fps: 8.959373871882123\n",
      "TIMESTEP 168276 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.317375 / Loss  6.864533424377441\n",
      "fps: 9.050781258429197\n",
      "TIMESTEP 168277 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  15.013493 / Loss  0.324729859828949\n",
      "fps: 10.203158030451569\n",
      "TIMESTEP 168278 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.433079 / Loss  0.2029528170824051\n",
      "fps: 10.241000097665788\n",
      "TIMESTEP 168279 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.717137 / Loss  0.10936054587364197\n",
      "fps: 10.436577627928388\n",
      "TIMESTEP 168280 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.229209 / Loss  0.0841171070933342\n",
      "fps: 10.96409610272148\n",
      "TIMESTEP 168281 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.316121 / Loss  0.19501273334026337\n",
      "fps: 9.820771040893499\n",
      "TIMESTEP 168282 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.943123 / Loss  0.1459585428237915\n",
      "fps: 10.174694162710532\n",
      "TIMESTEP 168283 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.68636 / Loss  0.14274732768535614\n",
      "fps: 9.152473432692517\n",
      "TIMESTEP 168284 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.700105 / Loss  0.21140095591545105\n",
      "fps: 8.361483348019027\n",
      "TIMESTEP 168285 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.002336 / Loss  0.10343404114246368\n",
      "fps: 8.94830668663569\n",
      "TIMESTEP 168286 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.365777 / Loss  0.4182952046394348\n",
      "fps: 9.383692262258993\n",
      "TIMESTEP 168287 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.844315 / Loss  0.15697290003299713\n",
      "fps: 8.684092946601048\n",
      "TIMESTEP 168288 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.119845 / Loss  0.06677284836769104\n",
      "fps: 10.329398726773467\n",
      "TIMESTEP 168289 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.366285 / Loss  0.09646691381931305\n",
      "fps: 10.330034726498042\n",
      "TIMESTEP 168290 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.020743 / Loss  0.13634082674980164\n",
      "fps: 9.572299399093048\n",
      "TIMESTEP 168291 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.090169 / Loss  0.1056397333741188\n",
      "fps: 10.3477979833865\n",
      "TIMESTEP 168292 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.679321 / Loss  0.22005443274974823\n",
      "fps: 9.255986494389212\n",
      "TIMESTEP 168293 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.467278 / Loss  5.635318279266357\n",
      "fps: 9.879178443565102\n",
      "TIMESTEP 168294 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.566987 / Loss  0.09841808676719666\n",
      "fps: 8.870450892479486\n",
      "TIMESTEP 168295 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  19.65963 / Loss  0.17162227630615234\n",
      "fps: 8.987325660876254\n",
      "TIMESTEP 168296 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.595874 / Loss  0.07411490380764008\n",
      "fps: 8.54217929944543\n",
      "TIMESTEP 168297 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.118996 / Loss  0.10869181156158447\n",
      "fps: 7.592792257868307\n",
      "TIMESTEP 168298 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.333966 / Loss  0.2852712869644165\n",
      "fps: 9.330607468839053\n",
      "TIMESTEP 168299 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.281417 / Loss  0.25540560483932495\n",
      "fps: 9.005599642722181\n",
      "TIMESTEP 168300 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.025257 / Loss  0.10652725398540497\n",
      "fps: 8.967093110761443\n",
      "TIMESTEP 168301 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.409683 / Loss  0.2652081847190857\n",
      "fps: 9.032771033481716\n",
      "TIMESTEP 168302 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.731209 / Loss  0.2788240313529968\n",
      "fps: 8.775245308282946\n",
      "TIMESTEP 168303 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  20.149855 / Loss  0.11602836847305298\n",
      "fps: 10.48867060609319\n",
      "TIMESTEP 168304 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.04068 / Loss  0.27355659008026123\n",
      "fps: 10.705408213010442\n",
      "TIMESTEP 168305 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.477454 / Loss  0.23084305226802826\n",
      "fps: 10.130165853140149\n",
      "TIMESTEP 168306 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.901348 / Loss  0.3174945116043091\n",
      "fps: 10.708797479504378\n",
      "TIMESTEP 168307 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.67135 / Loss  0.16948682069778442\n",
      "fps: 10.655312662745946\n",
      "TIMESTEP 168308 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.032124 / Loss  0.17087073624134064\n",
      "fps: 9.035631500486863\n",
      "TIMESTEP 168309 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.02112 / Loss  0.057622551918029785\n",
      "fps: 9.102735831448824\n",
      "TIMESTEP 168310 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.700744 / Loss  0.09723833948373795\n",
      "fps: 9.032031887609527\n",
      "TIMESTEP 168311 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.945217 / Loss  0.07004984468221664\n",
      "fps: 10.592559480966848\n",
      "TIMESTEP 168312 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.152304 / Loss  0.07891760766506195\n",
      "fps: 9.971006775228812\n",
      "TIMESTEP 168313 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.979249 / Loss  0.14812710881233215\n",
      "fps: 9.126662982030872\n",
      "TIMESTEP 168314 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.631518 / Loss  0.06919583678245544\n",
      "fps: 10.050064575491024\n",
      "TIMESTEP 168315 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.218012 / Loss  0.16322334110736847\n",
      "fps: 10.907867190608576\n",
      "TIMESTEP 168316 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.97896 / Loss  0.1941147744655609\n",
      "fps: 10.32675380823766\n",
      "TIMESTEP 168317 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.952889 / Loss  0.49730587005615234\n",
      "fps: 10.574959785793165\n",
      "TIMESTEP 168318 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.573039 / Loss  0.0763869658112526\n",
      "fps: 10.9923708935568\n",
      "TIMESTEP 168319 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.806628 / Loss  0.0888003408908844\n",
      "fps: 10.673045261730211\n",
      "TIMESTEP 168320 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.229767 / Loss  0.17031000554561615\n",
      "fps: 10.435045678004895\n",
      "TIMESTEP 168321 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.141417 / Loss  0.05656737834215164\n",
      "fps: 9.132167328196408\n",
      "TIMESTEP 168322 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.186954 / Loss  0.06005048751831055\n",
      "fps: 9.097779946857546\n",
      "TIMESTEP 168323 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.902897 / Loss  0.1499839723110199\n",
      "fps: 10.481069721299718\n",
      "TIMESTEP 168324 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.058039 / Loss  0.17359940707683563\n",
      "fps: 10.824401397727918\n",
      "TIMESTEP 168325 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.376397 / Loss  0.1389622986316681\n",
      "fps: 9.089676574866287\n",
      "TIMESTEP 168326 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.107248 / Loss  0.11086776852607727\n",
      "fps: 8.967802491730934\n",
      "TIMESTEP 168327 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.239 / Loss  0.1772136688232422\n",
      "fps: 8.982975560966938\n",
      "TIMESTEP 168328 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.117942 / Loss  0.10906478762626648\n",
      "fps: 8.97947544310735\n",
      "TIMESTEP 168329 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  15.257807 / Loss  0.12576045095920563\n",
      "fps: 10.356894342147825\n",
      "TIMESTEP 168330 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.160924 / Loss  0.08709840476512909\n",
      "fps: 8.888892656492724\n",
      "TIMESTEP 168331 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  15.471957 / Loss  0.23476096987724304\n",
      "fps: 9.024219904772766\n",
      "TIMESTEP 168332 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.503871 / Loss  0.15376734733581543\n",
      "fps: 9.892273076759796\n",
      "TIMESTEP 168333 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.101232 / Loss  0.12738962471485138\n",
      "fps: 8.445649919556686\n",
      "TIMESTEP 168334 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.263536 / Loss  0.19478347897529602\n",
      "fps: 10.52232507965179\n",
      "TIMESTEP 168335 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.188265 / Loss  0.3527061343193054\n",
      "fps: 10.52211390353672\n",
      "TIMESTEP 168336 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.82952 / Loss  0.12980447709560394\n",
      "fps: 10.4275222880214\n",
      "TIMESTEP 168337 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.53906 / Loss  0.14936980605125427\n",
      "fps: 11.04389062232579\n",
      "TIMESTEP 168338 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.314366 / Loss  0.07483560591936111\n",
      "fps: 10.474604546158341\n",
      "TIMESTEP 168339 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.505664 / Loss  0.08540242910385132\n",
      "fps: 10.572507423409071\n",
      "TIMESTEP 168340 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.9429455 / Loss  0.4196803569793701\n",
      "fps: 9.038006869594073\n",
      "TIMESTEP 168341 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.451258 / Loss  0.06333775818347931\n",
      "fps: 10.151496595840463\n",
      "TIMESTEP 168342 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.5921 / Loss  0.03180106729269028\n",
      "fps: 10.648495634534777\n",
      "TIMESTEP 168343 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.738832 / Loss  0.06438589096069336\n",
      "fps: 10.503642451273294\n",
      "TIMESTEP 168344 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.902057 / Loss  0.131026953458786\n",
      "fps: 10.65975383192154\n",
      "TIMESTEP 168345 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.157058 / Loss  0.06959870457649231\n",
      "fps: 10.121854042535734\n",
      "TIMESTEP 168346 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.409659 / Loss  0.09027133882045746\n",
      "fps: 10.698526954813861\n",
      "TIMESTEP 168347 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.88552 / Loss  0.5849691033363342\n",
      "fps: 10.732857205002162\n",
      "TIMESTEP 168348 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.196057 / Loss  0.11118385195732117\n",
      "fps: 10.450749987541736\n",
      "TIMESTEP 168349 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.377882 / Loss  0.164299875497818\n",
      "fps: 10.415145314765887\n",
      "TIMESTEP 168350 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.562685 / Loss  0.05358860641717911\n",
      "fps: 9.036935851886005\n",
      "TIMESTEP 168351 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.293824 / Loss  0.7381621599197388\n",
      "fps: 10.8722691689564\n",
      "TIMESTEP 168352 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.668444 / Loss  0.0616777166724205\n",
      "fps: 10.861682843203265\n",
      "TIMESTEP 168353 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.974022 / Loss  0.11665239930152893\n",
      "fps: 9.949978531049322\n",
      "TIMESTEP 168354 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.369209 / Loss  0.08216730505228043\n",
      "fps: 9.593975950464452\n",
      "TIMESTEP 168355 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.158577 / Loss  0.07799175381660461\n",
      "fps: 9.667168351883394\n",
      "TIMESTEP 168356 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.010118 / Loss  0.14807914197444916\n",
      "fps: 10.002084212685082\n",
      "TIMESTEP 168357 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.648211 / Loss  0.20228907465934753\n",
      "fps: 10.32705892201592\n",
      "TIMESTEP 168358 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.376694 / Loss  0.14454615116119385\n",
      "fps: 10.586276697240297\n",
      "TIMESTEP 168359 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.9686575 / Loss  0.12057185173034668\n",
      "fps: 10.817115283935143\n",
      "TIMESTEP 168360 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.700015 / Loss  0.14544714987277985\n",
      "fps: 10.499041287228344\n",
      "TIMESTEP 168361 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.821819 / Loss  0.09322940558195114\n",
      "fps: 10.557418477918874\n",
      "TIMESTEP 168362 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.62685 / Loss  1.1539374589920044\n",
      "fps: 9.123010331702012\n",
      "TIMESTEP 168363 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.968594 / Loss  0.06937864422798157\n",
      "fps: 10.590526786232807\n",
      "TIMESTEP 168364 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.381935 / Loss  0.17569877207279205\n",
      "fps: 10.747130206625123\n",
      "TIMESTEP 168365 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.511703 / Loss  0.06913433969020844\n",
      "fps: 9.932165902982511\n",
      "TIMESTEP 168366 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.689166 / Loss  0.02059658244252205\n",
      "fps: 10.933999301359222\n",
      "TIMESTEP 168367 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.147085 / Loss  0.10895460844039917\n",
      "fps: 10.722047113258432\n",
      "TIMESTEP 168368 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.130211 / Loss  0.06762515008449554\n",
      "fps: 10.589751358338887\n",
      "TIMESTEP 168369 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.690196 / Loss  0.12494447082281113\n",
      "fps: 7.3980791787563165\n",
      "TIMESTEP 168370 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.746085 / Loss  0.18302007019519806\n",
      "fps: 9.073022369414407\n",
      "TIMESTEP 168371 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.142657 / Loss  0.12101242691278458\n",
      "fps: 10.613117408906882\n",
      "TIMESTEP 168372 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.527587 / Loss  0.08634953200817108\n",
      "fps: 9.992409749636092\n",
      "TIMESTEP 168373 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.893664 / Loss  0.8055463433265686\n",
      "fps: 11.055826029654035\n",
      "TIMESTEP 168374 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.744349 / Loss  0.0923246443271637\n",
      "fps: 10.349406568460532\n",
      "TIMESTEP 168375 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.203838 / Loss  0.18151092529296875\n",
      "fps: 10.555771152166747\n",
      "TIMESTEP 168376 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.925671 / Loss  0.10624581575393677\n",
      "fps: 10.816417895051732\n",
      "TIMESTEP 168377 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.944622 / Loss  0.048973340541124344\n",
      "fps: 8.926159156737016\n",
      "TIMESTEP 168378 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.239885 / Loss  0.034761942923069\n",
      "fps: 10.927532833631643\n",
      "TIMESTEP 168379 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.001661 / Loss  0.10215630382299423\n",
      "fps: 8.927850148999575\n",
      "TIMESTEP 168380 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.378509 / Loss  0.08323249220848083\n",
      "fps: 8.990870447817503\n",
      "TIMESTEP 168381 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.085986 / Loss  0.11935249716043472\n",
      "fps: 9.271802852519608\n",
      "TIMESTEP 168382 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.824471 / Loss  0.07427436113357544\n",
      "fps: 9.337067295919503\n",
      "TIMESTEP 168383 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.016437 / Loss  0.1361919790506363\n",
      "fps: 10.298557962634217\n",
      "TIMESTEP 168384 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.249961 / Loss  0.0783316045999527\n",
      "fps: 11.138090091429815\n",
      "TIMESTEP 168385 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.575598 / Loss  0.0918373167514801\n",
      "fps: 10.59074071736084\n",
      "TIMESTEP 168386 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.599581 / Loss  0.12181206047534943\n",
      "fps: 10.65609772208757\n",
      "TIMESTEP 168387 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.779293 / Loss  0.18897712230682373\n",
      "fps: 9.032771033481716\n",
      "TIMESTEP 168388 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.757437 / Loss  0.07688240706920624\n",
      "fps: 8.893001244590694\n",
      "TIMESTEP 168389 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.701681 / Loss  0.10049966722726822\n",
      "fps: 9.05142580915263\n",
      "TIMESTEP 168390 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.5485325 / Loss  0.05916595458984375\n",
      "fps: 8.398484617910663\n",
      "TIMESTEP 168391 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.391462 / Loss  0.050393763929605484\n",
      "fps: 9.204696381153028\n",
      "TIMESTEP 168392 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.7572775 / Loss  0.13484634459018707\n",
      "fps: 9.939368087793758\n",
      "TIMESTEP 168393 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.08423 / Loss  0.04750123247504234\n",
      "fps: 10.795065617608529\n",
      "TIMESTEP 168394 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.813962 / Loss  0.05496309697628021\n",
      "fps: 10.545844951611809\n",
      "TIMESTEP 168395 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.591864 / Loss  0.11568926274776459\n",
      "fps: 9.13475288516614\n",
      "TIMESTEP 168396 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.702015 / Loss  0.06454575806856155\n",
      "fps: 10.724322555241343\n",
      "TIMESTEP 168397 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.074583 / Loss  0.16243278980255127\n",
      "fps: 9.169260500490784\n",
      "TIMESTEP 168398 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.706707 / Loss  0.06379660964012146\n",
      "fps: 8.866025754847001\n",
      "TIMESTEP 168399 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.648462 / Loss  0.10993145406246185\n",
      "fps: 9.326105421378669\n",
      "TIMESTEP 168400 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.598088 / Loss  0.1883375346660614\n",
      "fps: 9.193458519552767\n",
      "TIMESTEP 168401 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.805508 / Loss  0.038348548114299774\n",
      "fps: 10.072413337655945\n",
      "TIMESTEP 168402 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.75794 / Loss  0.08160191029310226\n",
      "fps: 10.890420811295721\n",
      "TIMESTEP 168403 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.573989 / Loss  0.20003116130828857\n",
      "fps: 9.129006982291793\n",
      "TIMESTEP 168404 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.414678 / Loss  0.1465657502412796\n",
      "fps: 9.099576078137\n",
      "TIMESTEP 168405 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.144257 / Loss  0.03847070038318634\n",
      "fps: 7.5470513932423335\n",
      "TIMESTEP 168406 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.82419 / Loss  0.06711738556623459\n",
      "fps: 9.227802846463042\n",
      "TIMESTEP 168407 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.389239 / Loss  0.11553386598825455\n",
      "fps: 8.919743017733989\n",
      "TIMESTEP 168408 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  24.524673 / Loss  0.1557943969964981\n",
      "fps: 11.002174568824184\n",
      "TIMESTEP 168409 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.902791 / Loss  0.15678012371063232\n",
      "fps: 8.915458079765672\n",
      "TIMESTEP 168410 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.956161 / Loss  0.1381778120994568\n",
      "fps: 9.29213836617322\n",
      "TIMESTEP 168411 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.767338 / Loss  0.15436384081840515\n",
      "fps: 9.126404818322856\n",
      "TIMESTEP 168412 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  19.913683 / Loss  0.03198237717151642\n",
      "fps: 9.384196136515166\n",
      "TIMESTEP 168413 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.46114945 / Loss  0.20713815093040466\n",
      "fps: 10.105490396384068\n",
      "TIMESTEP 168414 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.750525 / Loss  0.17585983872413635\n",
      "fps: 9.16042911556068\n",
      "TIMESTEP 168415 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  15.39798 / Loss  0.13514810800552368\n",
      "fps: 8.761094702365783\n",
      "TIMESTEP 168416 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.386177 / Loss  0.052085164934396744\n",
      "fps: 9.189812623792747\n",
      "TIMESTEP 168417 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.470601 / Loss  0.12268652021884918\n",
      "fps: 8.860556691622586\n",
      "TIMESTEP 168418 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.745631 / Loss  0.07132302224636078\n",
      "fps: 9.101906183813062\n",
      "TIMESTEP 168419 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.538367 / Loss  0.15172626078128815\n",
      "fps: 10.23195632339811\n",
      "TIMESTEP 168420 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.125231 / Loss  0.12011285871267319\n",
      "fps: 10.877372607294106\n",
      "TIMESTEP 168421 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.5979805 / Loss  0.06047750636935234\n",
      "fps: 9.19531279116928\n",
      "TIMESTEP 168422 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.731772 / Loss  0.1697070449590683\n",
      "fps: 9.061418309478801\n",
      "TIMESTEP 168423 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.725052 / Loss  0.05969496816396713\n",
      "fps: 8.997813994297935\n",
      "TIMESTEP 168424 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  15.998344 / Loss  0.11813680827617645\n",
      "fps: 11.057545687500658\n",
      "TIMESTEP 168425 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.853245 / Loss  0.19485293328762054\n",
      "fps: 10.588949311036046\n",
      "TIMESTEP 168426 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.62544 / Loss  0.06279618293046951\n",
      "fps: 7.9761303928634595\n",
      "TIMESTEP 168427 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.990644 / Loss  0.1445307433605194\n",
      "fps: 8.971274324850382\n",
      "TIMESTEP 168428 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.95031 / Loss  0.3542986512184143\n",
      "fps: 9.947972601180199\n",
      "TIMESTEP 168429 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.083618 / Loss  0.18887728452682495\n",
      "fps: 10.290422063185579\n",
      "TIMESTEP 168430 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.518498 / Loss  0.13064166903495789\n",
      "fps: 10.019933300843773\n",
      "TIMESTEP 168431 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.565425 / Loss  0.0948428362607956\n",
      "fps: 10.496807890304545\n",
      "TIMESTEP 168432 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.134586 / Loss  0.22179406881332397\n",
      "fps: 10.555877415734013\n",
      "TIMESTEP 168433 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.04981 / Loss  0.07202507555484772\n",
      "fps: 10.37634147910286\n",
      "TIMESTEP 168434 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.560818 / Loss  0.05173424631357193\n",
      "fps: 8.983648973402273\n",
      "TIMESTEP 168435 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  16.86667 / Loss  0.20298491418361664\n",
      "fps: 9.9434209621708\n",
      "TIMESTEP 168436 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.036383 / Loss  0.20548740029335022\n",
      "fps: 10.470028781755412\n",
      "TIMESTEP 168437 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.402163 / Loss  0.09051686525344849\n",
      "fps: 6.5358714486954135\n",
      "TIMESTEP 168438 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.274559 / Loss  0.2610895037651062\n",
      "fps: 7.53062844051522\n",
      "TIMESTEP 168439 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.648298 / Loss  0.06579001247882843\n",
      "fps: 9.862684882545206\n",
      "TIMESTEP 168440 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.027117 / Loss  0.09407199174165726\n",
      "fps: 9.295309688228567\n",
      "TIMESTEP 168441 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.73318 / Loss  5.799019813537598\n",
      "fps: 7.234165414778774\n",
      "TIMESTEP 168442 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  17.02939 / Loss  0.3036068081855774\n",
      "fps: 10.655989431162826\n",
      "TIMESTEP 168443 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.03687 / Loss  0.20270231366157532\n",
      "fps: 8.690606578606578\n",
      "TIMESTEP 168444 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  16.178785 / Loss  0.045245423913002014\n",
      "fps: 10.464987000803406\n",
      "TIMESTEP 168445 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.03138 / Loss  0.10241192579269409\n",
      "fps: 10.196807954586895\n",
      "TIMESTEP 168446 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.068302 / Loss  0.28163641691207886\n",
      "fps: 10.283912507263683\n",
      "TIMESTEP 168447 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.083934 / Loss  0.16282501816749573\n",
      "fps: 10.329627677652285\n",
      "TIMESTEP 168448 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.028353 / Loss  0.36689165234565735\n",
      "fps: 10.908235979485472\n",
      "TIMESTEP 168449 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.702235 / Loss  0.1213512197136879\n",
      "fps: 10.273584790122005\n",
      "TIMESTEP 168450 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.558142 / Loss  0.16229018568992615\n",
      "fps: 10.57978786464705\n",
      "TIMESTEP 168451 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.498331 / Loss  0.08095455914735794\n",
      "fps: 10.495284470657122\n",
      "TIMESTEP 168452 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.473724 / Loss  0.11010559648275375\n",
      "fps: 10.22078611984307\n",
      "TIMESTEP 168453 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.114779 / Loss  0.05863380432128906\n",
      "fps: 9.439763415353246\n",
      "TIMESTEP 168454 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.805408 / Loss  0.117047980427742\n",
      "fps: 9.237029125144524\n",
      "TIMESTEP 168455 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  15.262359 / Loss  0.09710662066936493\n",
      "fps: 9.224839720679606\n",
      "TIMESTEP 168456 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  15.383602 / Loss  0.0882178246974945\n",
      "fps: 10.46608376252645\n",
      "TIMESTEP 168457 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.930809 / Loss  0.08141544461250305\n",
      "fps: 10.543406072702501\n",
      "TIMESTEP 168458 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.694918 / Loss  0.6309235692024231\n",
      "fps: 10.660973092779837\n",
      "TIMESTEP 168459 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.733696 / Loss  0.07462644577026367\n",
      "fps: 9.993290637389448\n",
      "TIMESTEP 168460 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.412251 / Loss  1.8007875680923462\n",
      "fps: 10.804743025984632\n",
      "TIMESTEP 168461 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.128876 / Loss  0.06916557252407074\n",
      "fps: 10.213667887477596\n",
      "TIMESTEP 168462 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.594529 / Loss  0.055077388882637024\n",
      "fps: 10.852661348540792\n",
      "TIMESTEP 168463 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.947556 / Loss  0.10122793167829514\n",
      "fps: 10.875482930826156\n"
     ]
    }
   ],
   "source": [
    "playGame(observe=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
