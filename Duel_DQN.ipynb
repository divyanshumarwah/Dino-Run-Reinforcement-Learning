{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2  #opencv\n",
    "from IPython.display import clear_output\n",
    "from random import randint\n",
    "import io\n",
    "from io import BytesIO\n",
    "import time\n",
    "import os\n",
    "\n",
    "#keras imports\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import SGD , Adam\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "import random\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "import base64\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path variables\n",
    "game_url = \"chrome://dino\"\n",
    "#chromedriver_path = \"./chrome_driver/chromedriver\"\n",
    "chromedriver_path = \"./chrome_driver/chromedriver\"\n",
    "loss_file_path = \"./objects_duel/loss_df.csv\"\n",
    "actions_file_path = \"./objects_duel/actions_df.csv\"\n",
    "q_value_file_path = \"./objects_duel/q_values.csv\"\n",
    "scores_file_path = \"./objects_duel/scores_df.csv\"\n",
    "\n",
    "#scripts\n",
    "#create id for canvas for faster selection from DOM\n",
    "init_script = \"document.getElementsByClassName('runner-canvas')[0].id = 'runner-canvas'\"\n",
    "\n",
    "#get image from canvas\n",
    "getbase64Script = \"canvasRunner = document.getElementById('runner-canvas'); \\\n",
    "return canvasRunner.toDataURL().substring(22)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Game class: Selenium interfacing between the python and browser\n",
    "* __init__():  Launch the broswer window using the attributes in chrome_options\n",
    "* crashed() : return true if the agent as crashed on an obstacles. Gets javascript variable from game decribing the state\n",
    "* get_playing(): true if game in progress, false is crashed or paused\n",
    "* restart() : sends a signal to browser-javascript to restart the game\n",
    "* press_up(): sends a single to press up get to the browser\n",
    "* get_score(): gets current game score from javascript variables.\n",
    "* pause(): pause the game\n",
    "* resume(): resume a paused game if not crashed\n",
    "* end(): close the browser and end the game\n",
    "'''\n",
    "class Game:\n",
    "    def __init__(self,custom_config=True):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"disable-infobars\")\n",
    "        chrome_options.add_argument(\"--mute-audio\")\n",
    "        self._driver = webdriver.Chrome(executable_path = chromedriver_path,options=chrome_options)\n",
    "        self._driver.set_window_position(x=-10,y=0)\n",
    "        self._driver.get('chrome://dino')\n",
    "        self._driver.execute_script(\"Runner.config.ACCELERATION=0\")\n",
    "        self._driver.execute_script(init_script)\n",
    "    def crashed(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.crashed\")\n",
    "    def get_playing(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.playing\")\n",
    "    def restart(self):\n",
    "        self._driver.execute_script(\"Runner.instance_.restart()\")\n",
    "    def press_up(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ARROW_UP)\n",
    "    def get_score(self):\n",
    "        score_array = self._driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = ''.join(score_array) # the javascript object is of type array with score in the formate[1,0,0] which is 100.\n",
    "        return int(score)\n",
    "    def pause(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.stop()\")\n",
    "    def resume(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.play()\")\n",
    "    def end(self):\n",
    "        self._driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dino_Agent:\n",
    "    def __init__(self,game): #takes game as input for taking actions\n",
    "        self._game = game; \n",
    "        self.jump(); #to start the game, we need to jump once\n",
    "    def running(self):\n",
    "        return self._game.get_playing()\n",
    "    def is_crashed(self):\n",
    "        return self._game.crashed()\n",
    "    def jump(self):\n",
    "        self._game.press_up()\n",
    "    def duck(self):\n",
    "        self._game.press_down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game_state:\n",
    "    def __init__(self,agent,game):\n",
    "        self._agent = agent\n",
    "        self._game = game\n",
    "        self._display = show_img() #display the processed image on screen using openCV, implemented using python coroutine \n",
    "        self._display.__next__() # initiliaze the display coroutine \n",
    "    def get_state(self,actions):\n",
    "        actions_df.loc[len(actions_df)] = actions[1] # storing actions in a dataframe\n",
    "        score = self._game.get_score() \n",
    "        reward = 0.1\n",
    "        game_over = False #game over\n",
    "        if actions[1] == 1:\n",
    "            self._agent.jump()\n",
    "        image = grab_screen(self._game._driver) \n",
    "        self._display.send(image) #display the image on screen\n",
    "        if self._agent.is_crashed():\n",
    "            scores_df.loc[len(loss_df)] = score # log the score when game is over\n",
    "            self._game.restart()\n",
    "            reward = -1\n",
    "            game_over = True\n",
    "        return image, reward, game_over #return the Experience tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, name):\n",
    "    with open('objects_duel/'+ name + '.pkl', 'wb') as f: #dump files into objects folder\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "def load_object(name):\n",
    "    with open('objects_duel/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def grab_screen(_driver):\n",
    "    image_b64 = _driver.execute_script(getbase64Script)\n",
    "    screen = np.array(Image.open(BytesIO(base64.b64decode(image_b64))))\n",
    "    image = img_process(screen)#processing image as required\n",
    "    return image\n",
    "\n",
    "def img_process(image):\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #RGB to Grey Scale\n",
    "    image = image[:300, :500] #Crop Region of Interest(ROI)\n",
    "    image = cv2.resize(image, (80,80))\n",
    "    return  image\n",
    "\n",
    "def show_img(graphs = False):\n",
    "    \"\"\"\n",
    "    Show images in new window\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        screen = (yield)\n",
    "        window_title = \"logs\" if graphs else \"game_play\"\n",
    "        cv2.namedWindow(window_title, cv2.WINDOW_NORMAL)        \n",
    "        imS = cv2.resize(screen, (800, 400)) \n",
    "        cv2.imshow(window_title, screen)\n",
    "        if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize log structures from file if exists else create new\n",
    "loss_df = pd.read_csv(loss_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns =['loss'])\n",
    "scores_df = pd.read_csv(scores_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns = ['scores'])\n",
    "actions_df = pd.read_csv(actions_file_path) if os.path.isfile(actions_file_path) else pd.DataFrame(columns = ['actions'])\n",
    "q_values_df =pd.read_csv(actions_file_path) if os.path.isfile(q_value_file_path) else pd.DataFrame(columns = ['qvalues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game parameters\n",
    "ACTIONS = 2 # possible actions: jump, do nothing\n",
    "GAMMA = 0.99 # decay rate of past observations original 0.99\n",
    "OBSERVATION = 100 # timesteps to observe before training\n",
    "EXPLORE = 100000  # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.0001 # final value of epsilon\n",
    "INITIAL_EPSILON = 0.1 # starting value of epsilon\n",
    "REPLAY_MEMORY = 50000 # number of previous transitions to remember\n",
    "BATCH_SIZE = 16 # size of minibatch\n",
    "FRAME_PER_ACTION = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "img_rows , img_cols = 80,80\n",
    "img_channels = 4 #We stack 4 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training variables saved as checkpoints to filesystem to resume training from the same step\n",
    "def init_cache():\n",
    "    \"\"\"initial variable caching, done only once\"\"\"\n",
    "    save_object(INITIAL_EPSILON,\"epsilon\")\n",
    "    t = 0\n",
    "    save_object(t,\"time\")\n",
    "    D = deque()\n",
    "    save_object(D,\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Call only once to init file structure\n",
    "'''\n",
    "init_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    print(\"Now we build the model\")\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (8, 8), padding='same',strides=(4, 4),input_shape=(img_cols,img_rows,img_channels)))  #80*80*4\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (4, 4),strides=(2, 2),  padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3),strides=(1, 1),  padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu')) # last layer does not need activation for dueling \n",
    "    #model.add(Dense(ACTIONS))\n",
    "    #model.add(Dense(1))\n",
    "    \n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    model.compile(loss='mse',optimizer=adam)\n",
    "    #create model file if not present\n",
    "    if not os.path.isfile(loss_file_path):\n",
    "        model.save_weights('model_duel.h5')\n",
    "    print(\"We finish building the model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(model):\n",
    "    #model = build_model()\n",
    "    model.add(Dense(1))\n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    model.compile(loss = 'mse',optimizer = adam)\n",
    "    print(\"We finish building the value model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_advantage(model):\n",
    "    #model = build_model()\n",
    "    #model.add(Dense(1))\n",
    "    model.add(Dense(ACTIONS))\n",
    "    a = model\n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    a.compile(loss='mse',optimizer = adam)\n",
    "    print(\"We finish building the advantage model\")\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_q(model,state):\n",
    "    V = get_value(model)\n",
    "    A = get_advantage(model)\n",
    "    v_pred = V.predict(state)\n",
    "    a_pred = A.predict(state)\n",
    "    Q = (v_pred + (a_pred - np.mean(a_pred, 1)))\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "main training module\n",
    "Parameters:\n",
    "* model => Keras Model to be trained\n",
    "* game_state => Game State module with access to game environment and dino\n",
    "* observe => flag to indicate whether the model is to be trained(weight updates), else just play\n",
    "'''\n",
    "def train_Network(q_eval,q_target,game_state,observe=False):\n",
    "    last_time = time.time()\n",
    "    # store the previous observations in replay memory\n",
    "    D = load_object(\"D\") #load from file system\n",
    "    # get the first state by doing nothing\n",
    "    do_nothing = np.zeros(ACTIONS)\n",
    "    do_nothing[0] =1 #0 => do nothing,\n",
    "                     #1=> jump\n",
    "    \n",
    "    x_t, r_0, terminal = game_state.get_state(do_nothing) # get next step after performing the action\n",
    "    \n",
    "\n",
    "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2) # stack 4 images to create placeholder input\n",
    "    \n",
    "\n",
    "    \n",
    "    s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])  #1*20*40*4\n",
    "    \n",
    "    initial_state = s_t \n",
    "\n",
    "    if observe :\n",
    "        OBSERVE = 999999999    #We keep observe, never train\n",
    "        epsilon = FINAL_EPSILON\n",
    "        print (\"Now we load weight\")\n",
    "        q_eval.load_weights(\"model_duel.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        q_eval.compile(loss='mse',optimizer=adam)\n",
    "        print (\"Weight load successfully\")    \n",
    "    else:                       #We go to training mode\n",
    "        OBSERVE = OBSERVATION\n",
    "        epsilon = load_object(\"epsilon\") \n",
    "        q_eval.load_weights(\"model_duel.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        q_eval.compile(loss='mse',optimizer=adam)\n",
    "\n",
    "    t = load_object(\"time\") # resume from the previous time step stored in file system\n",
    "    while (True): #endless running\n",
    "        \n",
    "        loss = 0\n",
    "        Q_sa = 0\n",
    "\n",
    "        action_index = 0\n",
    "        r_t = 0 #reward at 4\n",
    "        a_t = np.zeros([ACTIONS]) # action at t\n",
    "        \n",
    "        #choose an action epsilon greedy\n",
    "        if t % FRAME_PER_ACTION == 0: #parameter to skip frames for actions\n",
    "            if  random.random() <= epsilon: #randomly explore an action\n",
    "                print(\"----------Random Action----------\")\n",
    "                action_index = random.randrange(ACTIONS)\n",
    "                a_t[action_index] = 1\n",
    "            else: # predict the output\n",
    "                q = calc_q(q_eval,s_t)       #input a stack of 4 images, get the prediction\n",
    "                max_Q = np.argmax(q)         # chosing index with maximum q value\n",
    "                action_index = max_Q \n",
    "                a_t[action_index] = 1        # o=> do nothing, 1=> jump\n",
    "                \n",
    "        \n",
    "        #run the selected action and observed next state and reward\n",
    "        x_t1, r_t, terminal = game_state.get_state(a_t)\n",
    "        print('fps: {0}'.format(1 / (time.time()-last_time))) # helpful for measuring frame rate\n",
    "        last_time = time.time()\n",
    "        x_t1 = x_t1.reshape(1, x_t1.shape[0], x_t1.shape[1], 1) #1x20x40x1\n",
    "        s_t1 = np.append(x_t1, s_t[:, :, :, :3], axis=3) # append the new image to input stack and remove the first one\n",
    "        \n",
    "        \n",
    "        # store the transition in D\n",
    "        D.append((s_t, action_index, r_t, s_t1, terminal))\n",
    "        if len(D) > REPLAY_MEMORY:\n",
    "            D.popleft()\n",
    "\n",
    "        #only train if done observing\n",
    "        if t > OBSERVE: \n",
    "            \n",
    "            #sample a minibatch to train on\n",
    "            minibatch = random.sample(D, BATCH_SIZE)\n",
    "            inputs = np.zeros((BATCH_SIZE, s_t.shape[1], s_t.shape[2], s_t.shape[3]))   #32, 20, 40, 4\n",
    "            targets = np.zeros((inputs.shape[0], ACTIONS))                         #32, 2\n",
    "\n",
    "            #Now we do the experience replay\n",
    "            for i in range(0, len(minibatch)):\n",
    "                state_t = minibatch[i][0]    # 4D stack of images\n",
    "                action_t = minibatch[i][1]   #This is action index\n",
    "                reward_t = minibatch[i][2]   #reward at state_t due to action_t\n",
    "                state_t1 = minibatch[i][3]   #next state\n",
    "                terminal = minibatch[i][4]   #wheather the agent died or survided due the action\n",
    "                \n",
    "\n",
    "                inputs[i:i + 1] = state_t    \n",
    "                \n",
    "                #q_next = q_target.predict(state_t1)\n",
    "                #q_eval = q_eval.predict(state_t1)\n",
    "                #q_pred = q_eval.predict(state_t)\n",
    "                \n",
    "                #targets[i] = q_pred\n",
    "                Q_sa = calc_q(q_target,state_t1)      #predict q values for next step\n",
    "                #old_q = q_eval.predict(state_t1)\n",
    "                targets[i] = q_target.predict(state_t)  # predicted q values\n",
    "                #max_Actions = np.argmax(old_q)\n",
    "                q_eval = q_target\n",
    "                #q_target  = targets[i]\n",
    "\n",
    "                if terminal:\n",
    "                    targets[i, action_t] = reward_t # if terminated, only equals reward\n",
    "                else:\n",
    "                    #targets[i, action_t] = reward_t + GAMMA * np.max(Q_sa)\n",
    "                    targets[i, action_t] = reward_t + GAMMA * np.max(Q_sa)\n",
    "\n",
    "            loss += q_target.train_on_batch(inputs, targets)\n",
    "            loss_df.loc[len(loss_df)] = loss\n",
    "            q_values_df.loc[len(q_values_df)] = np.max(Q_sa)\n",
    "        s_t = initial_state if terminal else s_t1 #reset game to initial frame if terminate\n",
    "        t = t + 1\n",
    "        \n",
    "        #We reduced the epsilon (exploration parameter) gradually\n",
    "        if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE \n",
    "            q_target.set_weights(q_eval.get_weights())\n",
    "\n",
    "        # save progress every 1000 iterations\n",
    "        if t % 1000 == 0:\n",
    "            print(\"Now we save model\")\n",
    "            game_state._game.pause() #pause game while saving to filesystem\n",
    "            q_target.save_weights(\"model_duel.h5\", overwrite=True)\n",
    "            save_object(D,\"D\") #saving episodes\n",
    "            save_object(t,\"time\") #caching time steps\n",
    "            save_object(epsilon,\"epsilon\") #cache epsilon to avoid repeated randomness in actions\n",
    "            loss_df.to_csv(\"./objects_duel/loss_df.csv\",index=False)\n",
    "            scores_df.to_csv(\"./objects_duel/scores_df.csv\",index=False)\n",
    "            actions_df.to_csv(\"./objects_duel/actions_df.csv\",index=False)\n",
    "            q_values_df.to_csv(q_value_file_path,index=False)\n",
    "            with open(\"model_duel.json\", \"w\") as outfile:\n",
    "                json.dump(q_target.to_json(), outfile)\n",
    "            clear_output()\n",
    "            game_state._game.resume()\n",
    "        # print info\n",
    "        state = \"\"\n",
    "        if t <= OBSERVE:\n",
    "            state = \"observe\"\n",
    "        elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "            state = \"explore\"\n",
    "        else:\n",
    "            state = \"train\"\n",
    "\n",
    "        print(\"TIMESTEP\", t, \"/ STATE\", state, \"/ EPSILON\", epsilon, \"/ ACTION\", action_index, \"/ REWARD\", r_t, \"/ Q_MAX \", np.max(Q_sa), \"/ Loss \", loss)\n",
    "\n",
    "    print(\"Episode finished!\")\n",
    "    print(\"************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function\n",
    "def play_Game(observe=False):\n",
    "    game = Game()\n",
    "    dino = Dino_Agent(game)\n",
    "    game_state = Game_state(dino,game)  \n",
    "    q_eval = build_model()\n",
    "    q_target = build_model()\n",
    "    '''v = get_value()\n",
    "    a = get_advantage()'''\n",
    "    try:\n",
    "        train_Network(q_eval,q_target,game_state,observe=observe)\n",
    "    except StopIteration:\n",
    "        game.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we build the model\n",
      "We finish building the model\n",
      "Now we build the model\n",
      "We finish building the model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "WARNING:tensorflow:From /Users/divyanshumarwah/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "fps: 2.13442655819911\n",
      "TIMESTEP 1 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 3.032343374621979\n",
      "TIMESTEP 2 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 3.7459644936169605\n",
      "TIMESTEP 3 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 3.71686193399282\n",
      "TIMESTEP 4 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 3.5779212027222305\n",
      "TIMESTEP 5 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 3.207360642098566\n",
      "TIMESTEP 6 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 3.0887073731836567\n",
      "TIMESTEP 7 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 3.1853433185165607\n",
      "TIMESTEP 8 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 2.930780185057598\n",
      "TIMESTEP 9 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 2.8668338067754626\n",
      "TIMESTEP 10 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 2.695614898201961\n",
      "TIMESTEP 11 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 2.200109420496253\n",
      "TIMESTEP 12 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 2.5478083390028186\n",
      "TIMESTEP 13 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 2.4606344621081546\n",
      "TIMESTEP 14 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 2.313469494918072\n",
      "TIMESTEP 15 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 2.257469589072357\n",
      "TIMESTEP 16 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 2.2210217124350726\n",
      "TIMESTEP 17 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 2.255431410064066\n",
      "TIMESTEP 18 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 2.11723610166035\n",
      "TIMESTEP 19 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 2.0864070039297617\n",
      "TIMESTEP 20 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 20.998818464003204\n",
      "TIMESTEP 21 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 30.171375956724408\n",
      "TIMESTEP 22 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.9607770172824777\n",
      "TIMESTEP 23 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.8806539394692134\n",
      "TIMESTEP 24 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.5751923311645026\n",
      "TIMESTEP 25 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.8092309815897993\n",
      "TIMESTEP 26 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.74100143080519\n",
      "TIMESTEP 27 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.8148329557392853\n",
      "TIMESTEP 28 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.7199773146760349\n",
      "TIMESTEP 29 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.6270008254665749\n",
      "TIMESTEP 30 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.5978264430633682\n",
      "TIMESTEP 31 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.6654895783408337\n",
      "TIMESTEP 32 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.5576787737641138\n",
      "TIMESTEP 33 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.5038382024663455\n",
      "TIMESTEP 34 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.4996780252309512\n",
      "TIMESTEP 35 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.5137022712188968\n",
      "TIMESTEP 36 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.4570744801514914\n",
      "TIMESTEP 37 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.2701009799417928\n",
      "TIMESTEP 38 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.4270611611638857\n",
      "TIMESTEP 39 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.390397142765271\n",
      "TIMESTEP 40 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.3416586484328619\n",
      "TIMESTEP 41 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.342081938499089\n",
      "TIMESTEP 42 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.3180698872085466\n",
      "TIMESTEP 43 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.2662890818409072\n",
      "TIMESTEP 44 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.260719471774585\n",
      "TIMESTEP 45 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.2493708173015488\n",
      "TIMESTEP 46 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.2181575381176677\n",
      "TIMESTEP 47 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.2008332503060557\n",
      "TIMESTEP 48 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.1659712303412986\n",
      "TIMESTEP 49 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.1305654546988517\n",
      "TIMESTEP 50 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.1000639428113121\n",
      "TIMESTEP 51 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.1123135107124682\n",
      "TIMESTEP 52 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.0820963697704724\n",
      "TIMESTEP 53 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.0551984253172912\n",
      "TIMESTEP 54 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.9493529521740961\n",
      "TIMESTEP 55 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 20.137427742889518\n",
      "TIMESTEP 56 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.0604801548583234\n",
      "TIMESTEP 57 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.015868833082856\n",
      "TIMESTEP 58 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.0133509090504957\n",
      "TIMESTEP 59 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 1.0258852143575363\n",
      "TIMESTEP 60 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.9932104752667313\n",
      "TIMESTEP 61 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.9918787243008755\n",
      "TIMESTEP 62 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.97580963180397\n",
      "TIMESTEP 63 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.9586807461076703\n",
      "TIMESTEP 64 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.9476462277760418\n",
      "TIMESTEP 65 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.9161567628503298\n",
      "TIMESTEP 66 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.9085146169493493\n",
      "TIMESTEP 67 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.9007978592030857\n",
      "TIMESTEP 68 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.8964814265033624\n",
      "TIMESTEP 69 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.8872608810619281\n",
      "TIMESTEP 70 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.8554889384975775\n",
      "TIMESTEP 71 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 21.48776351853275\n",
      "TIMESTEP 72 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.8675585973293377\n",
      "TIMESTEP 73 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.8449363996755067\n",
      "TIMESTEP 74 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.8550238284433619\n",
      "TIMESTEP 75 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 21.05045922208281\n",
      "TIMESTEP 76 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.8312310960158894\n",
      "TIMESTEP 77 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.7305574163621156\n",
      "TIMESTEP 78 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 29.029941445993273\n",
      "TIMESTEP 79 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.804347997013734\n",
      "TIMESTEP 80 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.7765765638996204\n",
      "TIMESTEP 81 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 18.793368581414104\n",
      "TIMESTEP 82 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.7501831501831502\n",
      "TIMESTEP 83 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "fps: 20.465809838881245\n",
      "TIMESTEP 84 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.7743581591846086\n",
      "TIMESTEP 85 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.7769458313134638\n",
      "TIMESTEP 86 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.7002625877852604\n",
      "TIMESTEP 87 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.6925599943991577\n",
      "TIMESTEP 88 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.723662925194481\n",
      "TIMESTEP 89 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.7273654267724953\n",
      "TIMESTEP 90 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.7379415386461391\n",
      "TIMESTEP 91 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.7353698480941907\n",
      "TIMESTEP 92 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.7067841813819847\n",
      "TIMESTEP 93 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.7113569039866681\n",
      "TIMESTEP 94 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.6581346545702522\n",
      "TIMESTEP 95 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.6740701872522542\n",
      "TIMESTEP 96 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.6759310097538768\n",
      "TIMESTEP 97 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.6838082391127245\n",
      "TIMESTEP 98 / STATE observe / EPSILON 0.1 / ACTION 1 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.6810499489736684\n",
      "TIMESTEP 99 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.6748630138639382\n",
      "TIMESTEP 100 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.6709820343743786\n",
      "TIMESTEP 101 / STATE explore / EPSILON 0.099999001 / ACTION 0 / REWARD 0.1 / Q_MAX  0 / Loss  0\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.4456389147810817\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 102 / STATE explore / EPSILON 0.099998002 / ACTION 0 / REWARD 0.1 / Q_MAX  -4.1815042e-08 / Loss  13.587540626525879\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.03399571377054715\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 103 / STATE explore / EPSILON 0.099997003 / ACTION 0 / REWARD 0.1 / Q_MAX  5.234189e-07 / Loss  0.0050001684576272964\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.022736657189517888\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 104 / STATE explore / EPSILON 0.099996004 / ACTION 0 / REWARD 0.1 / Q_MAX  2.2848536e-09 / Loss  0.005030371248722076\n",
      "----------Random Action----------\n",
      "fps: 0.01648743048171369\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 105 / STATE explore / EPSILON 0.099995005 / ACTION 0 / REWARD 0.1 / Q_MAX  2.2999753e-12 / Loss  0.005005534738302231\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.010960030495211192\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 106 / STATE explore / EPSILON 0.099994006 / ACTION 0 / REWARD 0.1 / Q_MAX  -2.9327538e-09 / Loss  0.0050039514899253845\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.007930653867521585\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 107 / STATE explore / EPSILON 0.099993007 / ACTION 0 / REWARD 0.1 / Q_MAX  5.135137e-10 / Loss  0.005000980570912361\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.0060766926884221915\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 108 / STATE explore / EPSILON 0.099992008 / ACTION 0 / REWARD 0.1 / Q_MAX  1.1641099e-13 / Loss  0.005000055767595768\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.004728464901134435\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 109 / STATE explore / EPSILON 0.09999100899999999 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.5212414e-07 / Loss  0.005034320987761021\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.0037799982210782795\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 110 / STATE explore / EPSILON 0.09999000999999999 / ACTION 1 / REWARD 0.1 / Q_MAX  5.4073857e-10 / Loss  0.005000635050237179\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.0030840834850242795\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 111 / STATE explore / EPSILON 0.09998901099999999 / ACTION 0 / REWARD 0.1 / Q_MAX  1.9768687e-07 / Loss  0.005001113750040531\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.0025518551260580824\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 112 / STATE explore / EPSILON 0.09998801199999999 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.00010715713 / Loss  0.005050328094512224\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.002161563507986883\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 113 / STATE explore / EPSILON 0.09998701299999999 / ACTION 0 / REWARD 0.1 / Q_MAX  3.7532743e-08 / Loss  0.005045838188380003\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.0017860557601716064\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 114 / STATE explore / EPSILON 0.09998601399999998 / ACTION 1 / REWARD 0.1 / Q_MAX  6.8086425e-09 / Loss  0.005003067199140787\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.0014887124471467611\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 115 / STATE explore / EPSILON 0.09998501499999998 / ACTION 1 / REWARD 0.1 / Q_MAX  3.2146577e-09 / Loss  0.005004649981856346\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.0013567519777703716\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 116 / STATE explore / EPSILON 0.09998401599999998 / ACTION 0 / REWARD 0.1 / Q_MAX  8.731938e-09 / Loss  0.00500138383358717\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.0011509071425091948\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 117 / STATE explore / EPSILON 0.09998301699999998 / ACTION 1 / REWARD 0.1 / Q_MAX  -2.7505373e-11 / Loss  0.00500604510307312\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.0010404481715694685\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 118 / STATE explore / EPSILON 0.09998201799999998 / ACTION 1 / REWARD 0.1 / Q_MAX  1.6053384e-08 / Loss  0.005012139678001404\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.0008710225563759191\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 119 / STATE explore / EPSILON 0.09998101899999998 / ACTION 1 / REWARD 0.1 / Q_MAX  4.4013383e-08 / Loss  0.005011935718357563\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.000790686302376469\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 120 / STATE explore / EPSILON 0.09998001999999998 / ACTION 1 / REWARD 0.1 / Q_MAX  5.5634956e-13 / Loss  0.005013170652091503\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.0006380131966677077\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 121 / STATE explore / EPSILON 0.09997902099999997 / ACTION 0 / REWARD 0.1 / Q_MAX  1.05219264e-10 / Loss  0.005000910721719265\n",
      "----------Random Action----------\n",
      "fps: 0.000595661717803355\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 122 / STATE explore / EPSILON 0.09997802199999997 / ACTION 0 / REWARD 0.1 / Q_MAX  1.4887191e-10 / Loss  0.0050066085532307625\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.0004316258337560288\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "TIMESTEP 123 / STATE explore / EPSILON 0.09997702299999997 / ACTION 0 / REWARD 0.1 / Q_MAX  2.9870502e-13 / Loss  0.004999965894967318\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "fps: 0.0003746957467497235\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n",
      "We finish building the value model\n",
      "We finish building the advantage model\n"
     ]
    }
   ],
   "source": [
    "play_Game(observe=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
