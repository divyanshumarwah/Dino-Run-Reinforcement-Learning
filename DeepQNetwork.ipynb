{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2  #opencv\n",
    "from IPython.display import clear_output\n",
    "from random import randint\n",
    "import io\n",
    "from io import BytesIO\n",
    "import time\n",
    "import os\n",
    "\n",
    "#keras imports\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import SGD , Adam\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "import random\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "import base64\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path variables\n",
    "game_url = \"chrome://dino\"\n",
    "chromedriver_path = \"./chrome_driver/chromedriver\"\n",
    "loss_file_path = \"./objects_dqn/loss_df.csv\"\n",
    "actions_file_path = \"./objects_dqn/actions_df.csv\"\n",
    "q_value_file_path = \"./objects_dqn/q_values.csv\"\n",
    "scores_file_path = \"./objects_dqn/scores_df.csv\"\n",
    "\n",
    "#scripts\n",
    "#create id for canvas for faster selection from DOM\n",
    "init_script = \"document.getElementsByClassName('runner-canvas')[0].id = 'runner-canvas'\"\n",
    "\n",
    "#get image from canvas\n",
    "getbase64Script = \"canvasRunner = document.getElementById('runner-canvas'); \\\n",
    "return canvasRunner.toDataURL().substring(22)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Game class: Selenium interfacing between the python and browser\n",
    "* __init__():  Launch the broswer window using the attributes in chrome_options\n",
    "* crashed() : return true if the agent as crashed on an obstacles. Gets javascript variable from game decribing the state\n",
    "* get_playing(): true if game in progress, false is crashed or paused\n",
    "* restart() : sends a signal to browser-javascript to restart the game\n",
    "* press_up(): sends a single to press up get to the browser\n",
    "* get_score(): gets current game score from javascript variables.\n",
    "* pause(): pause the game\n",
    "* resume(): resume a paused game if not crashed\n",
    "* end(): close the browser and end the game\n",
    "'''\n",
    "class Game:\n",
    "    def __init__(self,custom_config=True):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"disable-infobars\")\n",
    "        chrome_options.add_argument(\"--mute-audio\")\n",
    "        self._driver = webdriver.Chrome(executable_path = chromedriver_path,chrome_options=chrome_options)\n",
    "        self._driver.set_window_position(x=-10,y=0)\n",
    "        self._driver.get('chrome://dino')\n",
    "        self._driver.execute_script(\"Runner.config.ACCELERATION=0\")\n",
    "        self._driver.execute_script(init_script)\n",
    "    def crashed(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.crashed\")\n",
    "    def get_playing(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.playing\")\n",
    "    def restart(self):\n",
    "        self._driver.execute_script(\"Runner.instance_.restart()\")\n",
    "    def press_up(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ARROW_UP)\n",
    "    def get_score(self):\n",
    "        score_array = self._driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = ''.join(score_array) # the javascript object is of type array with score in the formate[1,0,0] which is 100.\n",
    "        return int(score)\n",
    "    def pause(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.stop()\")\n",
    "    def resume(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.play()\")\n",
    "    def end(self):\n",
    "        self._driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dino_Agent:\n",
    "    def __init__(self,game): #takes game as input for taking actions\n",
    "        self._game = game; \n",
    "        self.jump(); #to start the game, we need to jump once\n",
    "    def running(self):\n",
    "        return self._game.get_playing()\n",
    "    def is_crashed(self):\n",
    "        return self._game.crashed()\n",
    "    def jump(self):\n",
    "        self._game.press_up()\n",
    "    def duck(self):\n",
    "        self._game.press_down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game_state:\n",
    "    def __init__(self,agent,game):\n",
    "        self._agent = agent\n",
    "        self._game = game\n",
    "        self._display = show_img() #display the processed image on screen using openCV, implemented using python coroutine \n",
    "        self._display.__next__() # initiliaze the display coroutine \n",
    "    def get_state(self,actions):\n",
    "        actions_df.loc[len(actions_df)] = actions[1] # storing actions in a dataframe\n",
    "        score = self._game.get_score() \n",
    "        reward = 0.1\n",
    "        game_over = False #game over\n",
    "        if actions[1] == 1:\n",
    "            self._agent.jump()\n",
    "        image = grab_screen(self._game._driver) \n",
    "        self._display.send(image) #display the image on screen\n",
    "        if self._agent.is_crashed():\n",
    "            scores_df.loc[len(loss_df)] = score # log the score when game is over\n",
    "            self._game.restart()\n",
    "            reward = -1\n",
    "            game_over = True\n",
    "        return image, reward, game_over #return the Experience tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, name):\n",
    "    with open('objects_dqn/'+ name + '.pkl', 'wb') as f: #dump files into objects folder\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "def load_object(name):\n",
    "    with open('objects_dqn/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def grab_screen(_driver):\n",
    "    image_b64 = _driver.execute_script(getbase64Script)\n",
    "    screen = np.array(Image.open(BytesIO(base64.b64decode(image_b64))))\n",
    "    image = img_process(screen)#processing image as required\n",
    "    return image\n",
    "\n",
    "def img_process(image):\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #RGB to Grey Scale\n",
    "    image = image[:300, :500] #Crop Region of Interest(ROI)\n",
    "    image = cv2.resize(image, (80,80))\n",
    "    return  image\n",
    "\n",
    "def show_img(graphs = False):\n",
    "    \"\"\"\n",
    "    Show images in new window\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        screen = (yield)\n",
    "        window_title = \"logs\" if graphs else \"game_play\"\n",
    "        cv2.namedWindow(window_title, cv2.WINDOW_NORMAL)        \n",
    "        imS = cv2.resize(screen, (800, 400)) \n",
    "        cv2.imshow(window_title, screen)\n",
    "        if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize log structures from file if exists else create new\n",
    "loss_df = pd.read_csv(loss_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns =['loss'])\n",
    "scores_df = pd.read_csv(scores_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns = ['scores'])\n",
    "actions_df = pd.read_csv(actions_file_path) if os.path.isfile(actions_file_path) else pd.DataFrame(columns = ['actions'])\n",
    "q_values_df =pd.read_csv(actions_file_path) if os.path.isfile(q_value_file_path) else pd.DataFrame(columns = ['qvalues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game parameters\n",
    "ACTIONS = 2 # possible actions: jump, do nothing\n",
    "GAMMA = 0.99 # decay rate of past observations original 0.99\n",
    "OBSERVATION = 100 # timesteps to observe before training\n",
    "EXPLORE = 100000  # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.0001 # final value of epsilon\n",
    "INITIAL_EPSILON = 0.1 # starting value of epsilon\n",
    "REPLAY_MEMORY = 50000 # number of previous transitions to remember\n",
    "BATCH_SIZE = 16 # size of minibatch\n",
    "FRAME_PER_ACTION = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "img_rows , img_cols = 80,80\n",
    "img_channels = 4 #We stack 4 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training variables saved as checkpoints to filesystem to resume training from the same step\n",
    "def init_cache():\n",
    "    \"\"\"initial variable caching, done only once\"\"\"\n",
    "    save_object(INITIAL_EPSILON,\"epsilon\")\n",
    "    t = 0\n",
    "    save_object(t,\"time\")\n",
    "    D = deque()\n",
    "    save_object(D,\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Call only once to init file structure\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Call only once to init file structure\n",
    "'''\n",
    "#init_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    print(\"Now we build the model\")\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (8, 8), padding='same',strides=(4, 4),input_shape=(img_cols,img_rows,img_channels)))  #80*80*4\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (4, 4),strides=(2, 2),  padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3),strides=(1, 1),  padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(ACTIONS))\n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    model.compile(loss='mse',optimizer=adam)\n",
    "    \n",
    "    #create model file if not present\n",
    "    if not os.path.isfile(loss_file_path):\n",
    "        model.save_weights('model_dqn.h5')\n",
    "    print(\"We finish building the model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "main training module\n",
    "Parameters:\n",
    "* model => Keras Model to be trained\n",
    "* game_state => Game State module with access to game environment and dino\n",
    "* observe => flag to indicate whether the model is to be trained(weight updates), else just play\n",
    "'''\n",
    "def train_Network(model,game_state,observe=False):\n",
    "    last_time = time.time()\n",
    "    # store the previous observations in replay memory\n",
    "    D = load_object(\"D\") #load from file system\n",
    "    # get the first state by doing nothing\n",
    "    do_nothing = np.zeros(ACTIONS)\n",
    "    do_nothing[0] =1 #0 => do nothing,\n",
    "                     #1=> jump\n",
    "    \n",
    "    x_t, r_0, terminal = game_state.get_state(do_nothing) # get next step after performing the action\n",
    "    \n",
    "\n",
    "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2) # stack 4 images to create placeholder input\n",
    "    \n",
    "\n",
    "    \n",
    "    s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])  #1*20*40*4\n",
    "    \n",
    "    initial_state = s_t \n",
    "\n",
    "    if observe :\n",
    "        OBSERVE = 999999999    #We keep observe, never train\n",
    "        epsilon = FINAL_EPSILON\n",
    "        print (\"Now we load weight\")\n",
    "        model.load_weights(\"model_dqn.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "        print (\"Weight load successfully\")    \n",
    "    else:                       #We go to training mode\n",
    "        OBSERVE = OBSERVATION\n",
    "        epsilon = load_object(\"epsilon\") \n",
    "        model.load_weights(\"model_dqn.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "\n",
    "    t = load_object(\"time\") # resume from the previous time step stored in file system\n",
    "    while (True): #endless running\n",
    "        \n",
    "        loss = 0\n",
    "        Q_sa = 0\n",
    "        action_index = 0\n",
    "        r_t = 0 #reward at 4\n",
    "        a_t = np.zeros([ACTIONS]) # action at t\n",
    "        \n",
    "        #choose an action epsilon greedy\n",
    "        if t % FRAME_PER_ACTION == 0: #parameter to skip frames for actions\n",
    "            if  random.random() <= epsilon: #randomly explore an action\n",
    "                print(\"----------Random Action----------\")\n",
    "                action_index = random.randrange(ACTIONS)\n",
    "                a_t[action_index] = 1\n",
    "            else: # predict the output\n",
    "                q = model.predict(s_t)       #input a stack of 4 images, get the prediction\n",
    "                max_Q = np.argmax(q)         # chosing index with maximum q value\n",
    "                action_index = max_Q \n",
    "                a_t[action_index] = 1        # o=> do nothing, 1=> jump\n",
    "                \n",
    "        #We reduced the epsilon (exploration parameter) gradually\n",
    "        if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE \n",
    "\n",
    "        #run the selected action and observed next state and reward\n",
    "        x_t1, r_t, terminal = game_state.get_state(a_t)\n",
    "        print('fps: {0}'.format(1 / (time.time()-last_time))) # helpful for measuring frame rate\n",
    "        last_time = time.time()\n",
    "        x_t1 = x_t1.reshape(1, x_t1.shape[0], x_t1.shape[1], 1) #1x20x40x1\n",
    "        s_t1 = np.append(x_t1, s_t[:, :, :, :3], axis=3) # append the new image to input stack and remove the first one\n",
    "        \n",
    "        \n",
    "        # store the transition in D\n",
    "        D.append((s_t, action_index, r_t, s_t1, terminal))\n",
    "        if len(D) > REPLAY_MEMORY:\n",
    "            D.popleft()\n",
    "\n",
    "        #only train if done observing\n",
    "        if t > OBSERVE: \n",
    "            \n",
    "            #sample a minibatch to train on\n",
    "            minibatch = random.sample(D, BATCH_SIZE)\n",
    "            inputs = np.zeros((BATCH_SIZE, s_t.shape[1], s_t.shape[2], s_t.shape[3]))   #32, 20, 40, 4\n",
    "            targets = np.zeros((inputs.shape[0], ACTIONS))                         #32, 2\n",
    "\n",
    "            #Now we do the experience replay\n",
    "            for i in range(0, len(minibatch)):\n",
    "                state_t = minibatch[i][0]    # 4D stack of images\n",
    "                action_t = minibatch[i][1]   #This is action index\n",
    "                reward_t = minibatch[i][2]   #reward at state_t due to action_t\n",
    "                state_t1 = minibatch[i][3]   #next state\n",
    "                terminal = minibatch[i][4]   #wheather the agent died or survided due the action\n",
    "                \n",
    "\n",
    "                inputs[i:i + 1] = state_t    \n",
    "\n",
    "                targets[i] = model.predict(state_t)  # predicted q values\n",
    "                Q_sa = model.predict(state_t1)      #predict q values for next step\n",
    "                \n",
    "                if terminal:\n",
    "                    targets[i, action_t] = reward_t # if terminated, only equals reward\n",
    "                else:\n",
    "                    targets[i, action_t] = reward_t + GAMMA * np.max(Q_sa)\n",
    "\n",
    "            loss += model.train_on_batch(inputs, targets)\n",
    "            loss_df.loc[len(loss_df)] = loss\n",
    "            q_values_df.loc[len(q_values_df)] = np.max(Q_sa)\n",
    "        s_t = initial_state if terminal else s_t1 #reset game to initial frame if terminate\n",
    "        t = t + 1\n",
    "        \n",
    "        # save progress every 1000 iterations\n",
    "        if t % 1000 == 0:\n",
    "            print(\"Now we save model\")\n",
    "            game_state._game.pause() #pause game while saving to filesystem\n",
    "            model.save_weights(\"model_dqn.h5\", overwrite=True)\n",
    "            save_object(D,\"D\") #saving episodes\n",
    "            save_object(t,\"time\") #caching time steps\n",
    "            save_object(epsilon,\"epsilon\") #cache epsilon to avoid repeated randomness in actions\n",
    "            loss_df.to_csv(\"./objects_dqn/loss_df.csv\",index=False)\n",
    "            scores_df.to_csv(\"./objects_dqn/scores_df.csv\",index=False)\n",
    "            actions_df.to_csv(\"./objects_dqn/actions_df.csv\",index=False)\n",
    "            q_values_df.to_csv(q_value_file_path,index=False)\n",
    "            with open(\"model_dqn.json\", \"w\") as outfile:\n",
    "                json.dump(model.to_json(), outfile)\n",
    "            clear_output()\n",
    "            game_state._game.resume()\n",
    "        # print info\n",
    "        state = \"\"\n",
    "        if t <= OBSERVE:\n",
    "            state = \"observe\"\n",
    "        elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "            state = \"explore\"\n",
    "        else:\n",
    "            state = \"train\"\n",
    "\n",
    "        print(\"TIMESTEP\", t, \"/ STATE\", state, \"/ EPSILON\", epsilon, \"/ ACTION\", action_index, \"/ REWARD\", r_t, \"/ Q_MAX \", np.max(Q_sa), \"/ Loss \", loss)\n",
    "\n",
    "    print(\"Episode finished!\")\n",
    "    print(\"************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function\n",
    "def play_Game(observe=False):\n",
    "    game = Game()\n",
    "    dino = Dino_Agent(game)\n",
    "    game_state = Game_state(dino,game)    \n",
    "    model = build_model()\n",
    "    try:\n",
    "        train_Network(model,game_state,observe=observe)\n",
    "    except StopIteration:\n",
    "        game.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 231000 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.386883 / Loss  0.06450600922107697\n",
      "fps: 0.17405090001529577\n",
      "TIMESTEP 231001 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.30104 / Loss  0.06660329550504684\n",
      "fps: 8.99304879565346\n",
      "TIMESTEP 231002 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.351387 / Loss  1.7708439826965332\n",
      "fps: 8.63014859898849\n",
      "TIMESTEP 231003 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.880171 / Loss  0.04630035161972046\n",
      "fps: 7.427543315341352\n",
      "TIMESTEP 231004 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.893881 / Loss  0.031229864805936813\n",
      "fps: 7.513765280823194\n",
      "TIMESTEP 231005 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.003658 / Loss  0.04674144834280014\n",
      "fps: 7.693782502224138\n",
      "TIMESTEP 231006 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.859156 / Loss  0.0810311883687973\n",
      "fps: 6.670712699836504\n",
      "TIMESTEP 231007 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.996147 / Loss  0.08513107895851135\n",
      "fps: 6.198237605531608\n",
      "TIMESTEP 231008 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.018582 / Loss  0.08169911056756973\n",
      "fps: 7.6227641330779266\n",
      "TIMESTEP 231009 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.802663 / Loss  0.051843494176864624\n",
      "fps: 7.5125271355595835\n",
      "TIMESTEP 231010 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.179248 / Loss  0.036135558038949966\n",
      "fps: 7.318663332734249\n",
      "TIMESTEP 231011 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.084724 / Loss  0.035548288375139236\n",
      "fps: 6.614630299876201\n",
      "TIMESTEP 231012 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.543098 / Loss  0.037337757647037506\n",
      "fps: 6.395374439263594\n",
      "TIMESTEP 231013 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.015834 / Loss  0.1528681069612503\n",
      "fps: 7.512540591466702\n",
      "TIMESTEP 231014 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.599348 / Loss  0.06962387263774872\n",
      "fps: 7.01947369478046\n",
      "TIMESTEP 231015 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.30973 / Loss  0.03012179769575596\n",
      "fps: 7.631779673352936\n",
      "TIMESTEP 231016 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.245784 / Loss  0.06043125316500664\n",
      "fps: 9.223723968068963\n",
      "TIMESTEP 231017 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.427947 / Loss  0.07605057209730148\n",
      "fps: 8.727914400223073\n",
      "TIMESTEP 231018 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.113569 / Loss  0.1092827320098877\n",
      "fps: 7.725042315208243\n",
      "TIMESTEP 231019 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.070803 / Loss  0.08614560216665268\n",
      "fps: 9.09874700635174\n",
      "TIMESTEP 231020 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.311395 / Loss  0.023358521983027458\n",
      "fps: 8.805218088646207\n",
      "TIMESTEP 231021 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.127808 / Loss  0.05891973897814751\n",
      "fps: 8.899567784796295\n",
      "TIMESTEP 231022 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.5451 / Loss  0.03197985887527466\n",
      "fps: 9.375658584454166\n",
      "TIMESTEP 231023 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.647603 / Loss  0.1352061629295349\n",
      "fps: 8.053795608944942\n",
      "TIMESTEP 231024 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.457241 / Loss  0.03631535917520523\n",
      "fps: 7.834651155405872\n",
      "TIMESTEP 231025 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.275717 / Loss  2.1377766132354736\n",
      "fps: 8.550590384239024\n",
      "TIMESTEP 231026 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.187467 / Loss  0.059940155595541\n",
      "fps: 9.293682570844236\n",
      "TIMESTEP 231027 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.097803 / Loss  0.19871361553668976\n",
      "fps: 8.468687912904425\n",
      "TIMESTEP 231028 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.342382 / Loss  0.0745263397693634\n",
      "fps: 8.41808814468268\n",
      "TIMESTEP 231029 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.872654 / Loss  0.03420701622962952\n",
      "fps: 8.457434602797566\n",
      "TIMESTEP 231030 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.637107 / Loss  0.6249139308929443\n",
      "fps: 7.93140981275363\n",
      "TIMESTEP 231031 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.852607 / Loss  0.039381980895996094\n",
      "fps: 7.612553813986918\n",
      "TIMESTEP 231032 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.118199 / Loss  0.12563736736774445\n",
      "fps: 7.763419803244704\n",
      "TIMESTEP 231033 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.938541 / Loss  0.11966782063245773\n",
      "fps: 7.554759027138604\n",
      "TIMESTEP 231034 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.330854 / Loss  0.023076342418789864\n",
      "fps: 8.280693995846134\n",
      "TIMESTEP 231035 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.220818 / Loss  0.07615657150745392\n",
      "fps: 8.47392346140947\n",
      "TIMESTEP 231036 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.854332 / Loss  0.02330537512898445\n",
      "fps: 5.407776628855372\n",
      "TIMESTEP 231037 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.647272 / Loss  0.04434886947274208\n",
      "fps: 7.137406385762978\n",
      "TIMESTEP 231038 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.857602 / Loss  0.062278665602207184\n",
      "fps: 7.82706317926669\n",
      "TIMESTEP 231039 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.975637 / Loss  0.09064854681491852\n",
      "fps: 8.552072310135939\n",
      "TIMESTEP 231040 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.946512 / Loss  0.0169542133808136\n",
      "fps: 8.62379616912436\n",
      "TIMESTEP 231041 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.521661 / Loss  0.03904920816421509\n",
      "fps: 8.723104151805119\n",
      "TIMESTEP 231042 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.721465 / Loss  0.11596976220607758\n",
      "fps: 9.207242330049347\n",
      "TIMESTEP 231043 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.234275 / Loss  0.03267442062497139\n",
      "fps: 9.057895930289058\n",
      "TIMESTEP 231044 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.916785 / Loss  0.09441137313842773\n",
      "fps: 8.974480003594667\n",
      "TIMESTEP 231045 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.250227 / Loss  0.04044351354241371\n",
      "fps: 9.269221079430185\n",
      "TIMESTEP 231046 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.269727 / Loss  0.04066398739814758\n",
      "fps: 7.5934245781736545\n",
      "TIMESTEP 231047 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.161994 / Loss  2.3634936809539795\n",
      "fps: 9.224636836491197\n",
      "TIMESTEP 231048 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.143558 / Loss  0.06622269749641418\n",
      "fps: 9.112366849378757\n",
      "TIMESTEP 231049 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.324151 / Loss  0.03872554376721382\n",
      "fps: 9.279372039566109\n",
      "TIMESTEP 231050 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.208819 / Loss  0.050465766340494156\n",
      "fps: 8.987210117056676\n",
      "TIMESTEP 231051 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.66306 / Loss  3.751152276992798\n",
      "fps: 9.379810046895651\n",
      "TIMESTEP 231052 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.300745 / Loss  0.024052361026406288\n",
      "fps: 9.387745783766242\n",
      "TIMESTEP 231053 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.384779 / Loss  0.05081529915332794\n",
      "fps: 8.764316729562902\n",
      "TIMESTEP 231054 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.498931 / Loss  0.05314214527606964\n",
      "fps: 9.405218015270599\n",
      "TIMESTEP 231055 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.195555 / Loss  0.020697109401226044\n",
      "fps: 8.180017552413457\n",
      "TIMESTEP 231056 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.811534 / Loss  0.1153021976351738\n",
      "fps: 8.96828186673851\n",
      "TIMESTEP 231057 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.662345 / Loss  0.013324114494025707\n",
      "fps: 8.99191129652934\n",
      "TIMESTEP 231058 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.507288 / Loss  0.6639330387115479\n",
      "fps: 9.276601391610527\n",
      "TIMESTEP 231059 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.019232 / Loss  0.016030844300985336\n",
      "fps: 9.089006869352287\n",
      "TIMESTEP 231060 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.352081 / Loss  0.024812541902065277\n",
      "fps: 7.980349290972432\n",
      "TIMESTEP 231061 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.158507 / Loss  0.06286674737930298\n",
      "fps: 8.9807828602384\n",
      "TIMESTEP 231062 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.372614 / Loss  0.03468761965632439\n",
      "fps: 7.364849702284272\n",
      "TIMESTEP 231063 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.064972 / Loss  0.02437308430671692\n",
      "fps: 8.410846277557862\n",
      "TIMESTEP 231064 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.895309 / Loss  0.08443743735551834\n",
      "fps: 7.5824289854129265\n",
      "TIMESTEP 231065 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.79655 / Loss  0.4587010145187378\n",
      "fps: 8.335146371175282\n",
      "TIMESTEP 231066 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.063955 / Loss  0.03056512027978897\n",
      "fps: 8.690156428053454\n",
      "TIMESTEP 231067 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.764329 / Loss  0.06290175020694733\n",
      "fps: 8.995170325381098\n",
      "TIMESTEP 231068 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.709518 / Loss  0.024040859192609787\n",
      "fps: 8.584278033495496\n",
      "TIMESTEP 231069 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.230869 / Loss  0.05387089401483536\n",
      "fps: 7.152267107753696\n",
      "TIMESTEP 231070 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.3633995 / Loss  0.02926286682486534\n",
      "fps: 7.209234852078736\n",
      "TIMESTEP 231071 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.781736 / Loss  0.05778560787439346\n",
      "fps: 7.918158529149133\n",
      "TIMESTEP 231072 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.648042 / Loss  0.046822257339954376\n",
      "fps: 5.280696387001414\n",
      "TIMESTEP 231073 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.550642 / Loss  0.03354162350296974\n",
      "fps: 8.886595011239859\n",
      "TIMESTEP 231074 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.835703 / Loss  0.022620446979999542\n",
      "fps: 8.960101173017396\n",
      "TIMESTEP 231075 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.495806 / Loss  0.06730646640062332\n",
      "fps: 9.142338996202957\n",
      "TIMESTEP 231076 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.585187 / Loss  0.026844920590519905\n",
      "fps: 9.212156353708865\n",
      "TIMESTEP 231077 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.506159 / Loss  0.03958580270409584\n",
      "fps: 9.398853127233858\n",
      "TIMESTEP 231078 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.33053 / Loss  0.028082048520445824\n",
      "fps: 7.605831077197036\n",
      "TIMESTEP 231079 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.63578 / Loss  0.18354786932468414\n",
      "fps: 8.783312496989724\n",
      "TIMESTEP 231080 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.856856 / Loss  0.06227818876504898\n",
      "fps: 9.417360456239615\n",
      "TIMESTEP 231081 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.420712 / Loss  0.051162783056497574\n",
      "fps: 9.405049297811702\n",
      "TIMESTEP 231082 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.125188 / Loss  0.0749569833278656\n",
      "fps: 8.49919958500002\n",
      "TIMESTEP 231083 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.283516 / Loss  0.05641734227538109\n",
      "fps: 7.411806077099109\n",
      "TIMESTEP 231084 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.195794 / Loss  0.13284271955490112\n",
      "fps: 8.883376539758382\n",
      "TIMESTEP 231085 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.708013 / Loss  0.13952623307704926\n",
      "fps: 9.102656810872046\n",
      "TIMESTEP 231086 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.833664 / Loss  0.43256473541259766\n",
      "fps: 9.125769400645328\n",
      "TIMESTEP 231087 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.6501 / Loss  0.03487033396959305\n",
      "fps: 9.260196185358293\n",
      "TIMESTEP 231088 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.906085 / Loss  0.09623681008815765\n",
      "fps: 7.973022191300645\n",
      "TIMESTEP 231089 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.810685 / Loss  0.0717054009437561\n",
      "fps: 8.906862713869193\n",
      "TIMESTEP 231090 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.973701 / Loss  0.06303203850984573\n",
      "fps: 9.563329092393213\n",
      "TIMESTEP 231091 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.035045 / Loss  0.38020825386047363\n",
      "fps: 8.862971986670583\n",
      "TIMESTEP 231092 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.64296 / Loss  0.06450401246547699\n",
      "fps: 8.711780198233676\n",
      "TIMESTEP 231093 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.048594 / Loss  3.5315473079681396\n",
      "fps: 8.935972030772968\n",
      "TIMESTEP 231094 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.719833 / Loss  0.03822004795074463\n",
      "fps: 8.985939331095224\n",
      "TIMESTEP 231095 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.501302 / Loss  0.05562993139028549\n",
      "fps: 8.591522580301563\n",
      "TIMESTEP 231096 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.976366 / Loss  0.054168976843357086\n",
      "fps: 8.81732392382418\n",
      "TIMESTEP 231097 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.882572 / Loss  0.07628443837165833\n",
      "fps: 7.491420498284457\n",
      "TIMESTEP 231098 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.873797 / Loss  0.06525769829750061\n",
      "fps: 7.2871419239162165\n",
      "TIMESTEP 231099 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.529779 / Loss  0.07210604846477509\n",
      "fps: 7.790283097016728\n",
      "TIMESTEP 231100 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.426379 / Loss  0.08805110305547714\n",
      "fps: 7.564241800137423\n",
      "TIMESTEP 231101 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.9304695 / Loss  0.07109913975000381\n",
      "fps: 7.192125930244521\n",
      "TIMESTEP 231102 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.893715 / Loss  0.06334230303764343\n",
      "fps: 9.189550875178837\n",
      "TIMESTEP 231103 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.425056 / Loss  0.5209677815437317\n",
      "fps: 8.949108567819682\n",
      "TIMESTEP 231104 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.725894 / Loss  0.04033500328660011\n",
      "fps: 7.897286234223989\n",
      "TIMESTEP 231105 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.221098 / Loss  0.0721249058842659\n",
      "fps: 8.616833450777287\n",
      "TIMESTEP 231106 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.557744 / Loss  0.04504464194178581\n",
      "fps: 8.099269689608429\n",
      "TIMESTEP 231107 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.112685 / Loss  0.10314343869686127\n",
      "fps: 7.668490711267696\n",
      "TIMESTEP 231108 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.902734 / Loss  2.960319757461548\n",
      "fps: 5.414862811470828\n",
      "TIMESTEP 231109 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD -1 / Q_MAX  12.395852 / Loss  0.0529286190867424\n",
      "fps: 7.655040754570972\n",
      "TIMESTEP 231110 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.337371 / Loss  0.0548824779689312\n",
      "fps: 7.674889340655118\n",
      "TIMESTEP 231111 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.33102 / Loss  0.15538670122623444\n",
      "fps: 7.907887517793343\n",
      "TIMESTEP 231112 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.426391 / Loss  0.17032425105571747\n",
      "fps: 7.8947889511081835\n",
      "TIMESTEP 231113 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.805571 / Loss  0.05186503753066063\n",
      "fps: 7.9992218774495125\n",
      "TIMESTEP 231114 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.389579 / Loss  0.05500318109989166\n",
      "fps: 9.222284031917257\n",
      "TIMESTEP 231115 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.477874 / Loss  0.05173756554722786\n",
      "fps: 9.46244399424263\n",
      "TIMESTEP 231116 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.461314 / Loss  0.016333989799022675\n",
      "fps: 9.529801760863391\n",
      "TIMESTEP 231117 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.992905 / Loss  0.04012930765748024\n",
      "fps: 9.446417873471319\n",
      "TIMESTEP 231118 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.445763 / Loss  0.05675007030367851\n",
      "fps: 9.054610846179918\n",
      "TIMESTEP 231119 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.643089 / Loss  0.0217096246778965\n",
      "fps: 9.159848962985448\n",
      "TIMESTEP 231120 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.191326 / Loss  0.019858945161104202\n",
      "fps: 9.423941006900053\n",
      "TIMESTEP 231121 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.687662 / Loss  0.0440368615090847\n",
      "fps: 9.107143399970905\n",
      "TIMESTEP 231122 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.6415415 / Loss  0.059087663888931274\n",
      "fps: 9.384028172417342\n",
      "TIMESTEP 231123 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.50152 / Loss  0.027178728953003883\n",
      "fps: 9.05535369236914\n",
      "TIMESTEP 231124 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.058006 / Loss  0.018290139734745026\n",
      "fps: 9.153412203228559\n",
      "TIMESTEP 231125 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.777313 / Loss  0.12279504537582397\n",
      "fps: 9.389195820163145\n",
      "TIMESTEP 231126 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.579096 / Loss  0.022153479978442192\n",
      "fps: 9.128927504940668\n",
      "TIMESTEP 231127 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.479891 / Loss  0.18652476370334625\n",
      "fps: 9.832466354257262\n",
      "TIMESTEP 231128 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.816449 / Loss  0.06428971141576767\n",
      "fps: 9.243950764212592\n",
      "TIMESTEP 231129 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.288055 / Loss  0.0652204379439354\n",
      "fps: 9.24307480750499\n",
      "TIMESTEP 231130 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.607875 / Loss  0.21210801601409912\n",
      "fps: 9.179856555986719\n",
      "TIMESTEP 231131 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.389173 / Loss  0.09649240225553513\n",
      "fps: 9.09744448445044\n",
      "TIMESTEP 231132 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.268943 / Loss  0.036859434098005295\n",
      "fps: 8.711544972116354\n",
      "TIMESTEP 231133 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.514292 / Loss  0.05636630207300186\n",
      "fps: 9.14359460667299\n",
      "TIMESTEP 231134 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.880075 / Loss  0.038042012602090836\n",
      "fps: 8.887536525466647\n",
      "TIMESTEP 231135 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.612209 / Loss  0.4563167095184326\n",
      "fps: 8.88476904240401\n",
      "TIMESTEP 231136 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.831618 / Loss  0.029824601486325264\n",
      "fps: 8.895056963260181\n",
      "TIMESTEP 231137 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.738028 / Loss  0.0783735141158104\n",
      "fps: 8.959833206229986\n",
      "TIMESTEP 231138 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.026868 / Loss  0.06691297888755798\n",
      "fps: 9.0316429120523\n",
      "TIMESTEP 231139 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.953532 / Loss  0.22900816798210144\n",
      "fps: 8.79019693727641\n",
      "TIMESTEP 231140 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.362424 / Loss  0.11332482099533081\n",
      "fps: 7.545910858919325\n",
      "TIMESTEP 231141 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.692118 / Loss  0.0408436544239521\n",
      "fps: 7.156855852873626\n",
      "TIMESTEP 231142 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.448511 / Loss  0.036030419170856476\n",
      "fps: 8.54050950200262\n",
      "TIMESTEP 231143 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.272212 / Loss  0.0321032889187336\n",
      "fps: 8.389883262255863\n",
      "TIMESTEP 231144 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.515591 / Loss  0.05473458766937256\n",
      "fps: 5.51830552672053\n",
      "TIMESTEP 231145 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.547319 / Loss  0.1466306746006012\n",
      "fps: 9.065942711890784\n",
      "TIMESTEP 231146 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.083704 / Loss  0.18942445516586304\n",
      "fps: 8.706318992680911\n",
      "TIMESTEP 231147 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.18814 / Loss  0.0594845786690712\n",
      "fps: 9.389931517122958\n",
      "TIMESTEP 231148 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.38894 / Loss  2.3363187313079834\n",
      "fps: 7.616659554183502\n",
      "TIMESTEP 231149 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.997542 / Loss  0.025605643168091774\n",
      "fps: 8.786422044486155\n",
      "TIMESTEP 231150 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.2820425 / Loss  0.11659185588359833\n",
      "fps: 8.961709310400085\n",
      "TIMESTEP 231151 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.430669 / Loss  0.09151561558246613\n",
      "fps: 9.654395838368494\n",
      "TIMESTEP 231152 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.162683 / Loss  0.06414689123630524\n",
      "fps: 9.002777479662582\n",
      "TIMESTEP 231153 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.6174555 / Loss  0.0673082023859024\n",
      "fps: 9.241791728821328\n",
      "TIMESTEP 231154 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.851477 / Loss  0.08838500827550888\n",
      "fps: 9.503609478449624\n",
      "TIMESTEP 231155 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.139891 / Loss  0.04991581290960312\n",
      "fps: 9.504449364263232\n",
      "TIMESTEP 231156 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  1.8467864 / Loss  3.0054686069488525\n",
      "fps: 7.967161111522674\n",
      "TIMESTEP 231157 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.085588 / Loss  0.02364106848835945\n",
      "fps: 9.176161212198116\n",
      "TIMESTEP 231158 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.372337 / Loss  0.042767852544784546\n",
      "fps: 9.32417730214236\n",
      "TIMESTEP 231159 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.057771 / Loss  0.05086895823478699\n",
      "fps: 9.417170159119332\n",
      "TIMESTEP 231160 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.151014 / Loss  0.05400047451257706\n",
      "fps: 9.324882113486751\n",
      "TIMESTEP 231161 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.262581 / Loss  0.2764895558357239\n",
      "fps: 9.399190123722382\n",
      "TIMESTEP 231162 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.296366 / Loss  0.056315504014492035\n",
      "fps: 9.393548618280931\n",
      "TIMESTEP 231163 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.557034 / Loss  0.0682327151298523\n",
      "fps: 8.248174579607602\n",
      "TIMESTEP 231164 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.914451 / Loss  0.030792461708188057\n",
      "fps: 7.727248274667738\n",
      "TIMESTEP 231165 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.93939 / Loss  0.036742016673088074\n",
      "fps: 8.121098998973803\n",
      "TIMESTEP 231166 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.093485 / Loss  0.20350567996501923\n",
      "fps: 7.951226910127696\n",
      "TIMESTEP 231167 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.307263 / Loss  0.04095364362001419\n",
      "fps: 9.331686946152015\n",
      "TIMESTEP 231168 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.498629 / Loss  0.059901900589466095\n",
      "fps: 9.076242266602325\n",
      "TIMESTEP 231169 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.322287 / Loss  0.05972260981798172\n",
      "fps: 9.671091435225216\n",
      "TIMESTEP 231170 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.02793 / Loss  0.11092880368232727\n",
      "fps: 7.81506069555334\n",
      "TIMESTEP 231171 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.095539 / Loss  0.07011539489030838\n",
      "fps: 8.015241997282583\n",
      "TIMESTEP 231172 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.697995 / Loss  0.057109348475933075\n",
      "fps: 8.967093110761443\n",
      "TIMESTEP 231173 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.968544 / Loss  0.09166516363620758\n",
      "fps: 9.334698346849935\n",
      "TIMESTEP 231174 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.413207 / Loss  0.06318400800228119\n",
      "fps: 8.107034478492983\n",
      "TIMESTEP 231175 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.964724 / Loss  0.07160824537277222\n",
      "fps: 9.108211345567941\n",
      "TIMESTEP 231176 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.959417 / Loss  0.03237932547926903\n",
      "fps: 7.935821754003572\n",
      "TIMESTEP 231177 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.994988 / Loss  0.07508822530508041\n",
      "fps: 8.119322548361056\n",
      "TIMESTEP 231178 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.907957 / Loss  0.06736607104539871\n",
      "fps: 7.865106510651065\n",
      "TIMESTEP 231179 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.114621 / Loss  0.06585978716611862\n",
      "fps: 7.5392103995455955\n",
      "TIMESTEP 231180 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.4590845 / Loss  0.2858915627002716\n",
      "fps: 5.60327568816838\n",
      "TIMESTEP 231181 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.907826 / Loss  0.06684230268001556\n",
      "fps: 9.347013362095861\n",
      "TIMESTEP 231182 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.733913 / Loss  0.043747954070568085\n",
      "fps: 8.87997239235878\n",
      "TIMESTEP 231183 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.073573 / Loss  4.317910671234131\n",
      "fps: 9.535174605628391\n",
      "TIMESTEP 231184 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.389653 / Loss  0.028607986867427826\n",
      "fps: 9.058384985854047\n",
      "TIMESTEP 231185 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.979444 / Loss  0.10807022452354431\n",
      "fps: 9.3452639834587\n",
      "TIMESTEP 231186 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.687107 / Loss  0.15203335881233215\n",
      "fps: 8.197587808877536\n",
      "TIMESTEP 231187 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.906815 / Loss  0.055600855499506\n",
      "fps: 7.9419977012669545\n",
      "TIMESTEP 231188 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.762542 / Loss  0.18266291916370392\n",
      "fps: 8.132720094933028\n",
      "TIMESTEP 231189 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.188735 / Loss  0.079937644302845\n",
      "fps: 8.042522185321255\n",
      "TIMESTEP 231190 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.383557 / Loss  1.5136878490447998\n",
      "fps: 8.101162550387162\n",
      "TIMESTEP 231191 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.309274 / Loss  1.6326940059661865\n",
      "fps: 9.365839715963647\n",
      "TIMESTEP 231192 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.930808 / Loss  0.036193180829286575\n",
      "fps: 9.081253355966258\n",
      "TIMESTEP 231193 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.264311 / Loss  0.016460586339235306\n",
      "fps: 9.249597537147872\n",
      "TIMESTEP 231194 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.904284 / Loss  0.1175452470779419\n",
      "fps: 8.125708816936825\n",
      "TIMESTEP 231195 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.764552 / Loss  0.0462404303252697\n",
      "fps: 8.191296060494802\n",
      "TIMESTEP 231196 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.448984 / Loss  0.21695689857006073\n",
      "fps: 8.09486166007905\n",
      "TIMESTEP 231197 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.162705 / Loss  0.09665156900882721\n",
      "fps: 8.226061033968778\n",
      "TIMESTEP 231198 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.67985487 / Loss  0.10545225441455841\n",
      "fps: 9.108626725388511\n",
      "TIMESTEP 231199 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.695376 / Loss  0.09504632651805878\n",
      "fps: 9.518361344728516\n",
      "TIMESTEP 231200 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.77029 / Loss  0.0377955436706543\n",
      "fps: 8.535191376703507\n",
      "TIMESTEP 231201 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.900719 / Loss  0.60639488697052\n",
      "fps: 8.835247427979205\n",
      "TIMESTEP 231202 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.739152 / Loss  0.07691879570484161\n",
      "fps: 9.404163630452574\n",
      "TIMESTEP 231203 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.822741 / Loss  0.032823171466588974\n",
      "fps: 9.532335775713168\n",
      "TIMESTEP 231204 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.263325 / Loss  0.05756383761763573\n",
      "fps: 9.426143629274213\n",
      "TIMESTEP 231205 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.839563 / Loss  0.0443548783659935\n",
      "fps: 8.820847152149636\n",
      "TIMESTEP 231206 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.195771 / Loss  0.09837637841701508\n",
      "fps: 9.470306396622187\n",
      "TIMESTEP 231207 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.0146675 / Loss  0.04826342687010765\n",
      "fps: 9.483453770948458\n",
      "TIMESTEP 231208 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.0278225 / Loss  0.045077938586473465\n",
      "fps: 9.166835682064551\n",
      "TIMESTEP 231209 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.485782 / Loss  0.07275184243917465\n",
      "fps: 9.336797091867513\n",
      "TIMESTEP 231210 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.912607 / Loss  0.05164250731468201\n",
      "fps: 8.965233914941187\n",
      "TIMESTEP 231211 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.597469 / Loss  0.5959956049919128\n",
      "fps: 8.072846675148252\n",
      "TIMESTEP 231212 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.184669 / Loss  0.03011397272348404\n",
      "fps: 9.197006475152998\n",
      "TIMESTEP 231213 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.482246 / Loss  0.04406992718577385\n",
      "fps: 9.659976876695671\n",
      "TIMESTEP 231214 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.256222 / Loss  0.09305077791213989\n",
      "fps: 9.542420195521258\n",
      "TIMESTEP 231215 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.6018715 / Loss  0.06336966902017593\n",
      "fps: 8.970123143122334\n",
      "TIMESTEP 231216 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.84399 / Loss  0.08653458207845688\n",
      "fps: 5.454735092576818\n",
      "TIMESTEP 231217 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.12091 / Loss  0.04505602642893791\n",
      "fps: 9.204615580436892\n",
      "TIMESTEP 231218 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.009974 / Loss  0.03155510127544403\n",
      "fps: 9.58266563398881\n",
      "TIMESTEP 231219 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.3101845 / Loss  0.1676923781633377\n",
      "fps: 7.744240707677025\n",
      "TIMESTEP 231220 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.709593 / Loss  0.16394254565238953\n",
      "fps: 9.148281277264003\n",
      "TIMESTEP 231221 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.379469 / Loss  0.019210709258913994\n",
      "fps: 9.043794754806727\n",
      "TIMESTEP 231222 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.654583 / Loss  0.16012540459632874\n",
      "fps: 9.350138882077301\n",
      "TIMESTEP 231223 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.831558 / Loss  0.06976793706417084\n",
      "fps: 8.02679230984158\n",
      "TIMESTEP 231224 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.009057 / Loss  0.11407546699047089\n",
      "fps: 8.512879007755211\n",
      "TIMESTEP 231225 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.895187 / Loss  0.022460900247097015\n",
      "fps: 9.884649737818888\n",
      "TIMESTEP 231226 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.07093 / Loss  0.047541968524456024\n",
      "fps: 8.147174627100505\n",
      "TIMESTEP 231227 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.9986925 / Loss  0.13410386443138123\n",
      "fps: 8.138022025782117\n",
      "TIMESTEP 231228 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.200015 / Loss  0.09646531939506531\n",
      "fps: 8.134786394906138\n",
      "TIMESTEP 231229 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.18031 / Loss  0.03732381388545036\n",
      "fps: 8.309353387391065\n",
      "TIMESTEP 231230 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.049614 / Loss  0.09156019985675812\n",
      "fps: 9.152812965763454\n",
      "TIMESTEP 231231 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.734168 / Loss  0.09873371571302414\n",
      "fps: 9.073257894178955\n",
      "TIMESTEP 231232 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.200322 / Loss  2.8081750869750977\n",
      "fps: 9.594436819471133\n",
      "TIMESTEP 231233 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.1095295 / Loss  0.11809937655925751\n",
      "fps: 9.183574985001686\n",
      "TIMESTEP 231234 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.66899 / Loss  0.04522685334086418\n",
      "fps: 9.203121023021493\n",
      "TIMESTEP 231235 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.212371 / Loss  0.06702259182929993\n",
      "fps: 9.280645039949905\n",
      "TIMESTEP 231236 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.840623 / Loss  0.10544311255216599\n",
      "fps: 9.170443315288212\n",
      "TIMESTEP 231237 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.001555 / Loss  0.1662643700838089\n",
      "fps: 9.650086623611779\n",
      "TIMESTEP 231238 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.778381 / Loss  0.5367738008499146\n",
      "fps: 9.151994134769383\n",
      "TIMESTEP 231239 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.440611 / Loss  0.063421331346035\n",
      "fps: 9.49721829112276\n",
      "TIMESTEP 231240 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.414437 / Loss  0.11201279610395432\n",
      "fps: 9.076222626157708\n",
      "TIMESTEP 231241 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.789034 / Loss  0.0471692718565464\n",
      "fps: 9.46118466018673\n",
      "TIMESTEP 231242 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.754253 / Loss  0.05231532081961632\n",
      "fps: 7.786710826530821\n",
      "TIMESTEP 231243 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.45363 / Loss  0.09708079695701599\n",
      "fps: 9.712229482839266\n",
      "TIMESTEP 231244 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.413118 / Loss  0.04620446637272835\n",
      "fps: 7.962986378091034\n",
      "TIMESTEP 231245 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.505083 / Loss  0.01810346357524395\n",
      "fps: 9.169761655946795\n",
      "TIMESTEP 231246 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.909081 / Loss  0.021338336169719696\n",
      "fps: 9.432630397675522\n",
      "TIMESTEP 231247 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.610339 / Loss  0.04659386724233627\n",
      "fps: 9.459392288244727\n",
      "TIMESTEP 231248 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.898057 / Loss  3.982834577560425\n",
      "fps: 8.683589536556836\n",
      "TIMESTEP 231249 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.725838 / Loss  0.025931397452950478\n",
      "fps: 9.576058392827381\n",
      "TIMESTEP 231250 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.377756 / Loss  0.05434328317642212\n",
      "fps: 9.382180964097975\n",
      "TIMESTEP 231251 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.138787 / Loss  0.038067031651735306\n",
      "fps: 8.955930364894614\n",
      "TIMESTEP 231252 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.528647 / Loss  0.08123023062944412\n",
      "fps: 5.420054816895803\n",
      "TIMESTEP 231253 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.111385 / Loss  0.056800104677677155\n",
      "fps: 7.811218361178414\n",
      "TIMESTEP 231254 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.8293705 / Loss  0.15416228771209717\n",
      "fps: 7.5186815117298345\n",
      "TIMESTEP 231255 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.695805 / Loss  4.297844886779785\n",
      "fps: 8.025041519022217\n",
      "TIMESTEP 231256 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.764639 / Loss  0.029729168862104416\n",
      "fps: 8.007499088387295\n",
      "TIMESTEP 231257 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.479068 / Loss  0.24429269134998322\n",
      "fps: 9.298792397446897\n",
      "TIMESTEP 231258 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.084706 / Loss  0.043365467339754105\n",
      "fps: 9.247354310709751\n",
      "TIMESTEP 231259 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.712702 / Loss  0.02633075974881649\n",
      "fps: 9.059030620068812\n",
      "TIMESTEP 231260 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.003276 / Loss  0.14160864055156708\n",
      "fps: 7.839571452869722\n",
      "TIMESTEP 231261 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.538776 / Loss  0.026238299906253815\n",
      "fps: 7.240396898282731\n",
      "TIMESTEP 231262 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.456621 / Loss  0.06963704526424408\n",
      "fps: 7.447074385447831\n",
      "TIMESTEP 231263 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.425595 / Loss  0.05996798723936081\n",
      "fps: 7.756155563075683\n",
      "TIMESTEP 231264 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.3877 / Loss  0.024289870634675026\n",
      "fps: 7.714329330535237\n",
      "TIMESTEP 231265 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.935613 / Loss  0.029865426942706108\n",
      "fps: 7.3352640783490735\n",
      "TIMESTEP 231266 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.949131 / Loss  0.036105215549468994\n",
      "fps: 9.43893492242811\n",
      "TIMESTEP 231267 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.890791 / Loss  0.09746120870113373\n",
      "fps: 7.896973987438057\n",
      "TIMESTEP 231268 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.712494 / Loss  0.052077099680900574\n",
      "fps: 9.078776596896036\n",
      "TIMESTEP 231269 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.805519 / Loss  0.10590069741010666\n",
      "fps: 9.323306799919088\n",
      "TIMESTEP 231270 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.914505 / Loss  0.03538866713643074\n",
      "fps: 9.37153173443442\n",
      "TIMESTEP 231271 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.753161 / Loss  0.44124868512153625\n",
      "fps: 9.54092244979664\n",
      "TIMESTEP 231272 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.735579 / Loss  0.04914803057909012\n",
      "fps: 9.462700171011132\n",
      "TIMESTEP 231273 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.554492 / Loss  0.05536622926592827\n",
      "fps: 9.141163419689345\n",
      "TIMESTEP 231274 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.82439 / Loss  0.02207411266863346\n",
      "fps: 9.406715648016077\n",
      "TIMESTEP 231275 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.127916 / Loss  0.20912733674049377\n",
      "fps: 8.048479266209966\n",
      "TIMESTEP 231276 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.18944 / Loss  0.169587180018425\n",
      "fps: 8.073561483779939\n",
      "TIMESTEP 231277 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.998525 / Loss  0.03858994320034981\n",
      "fps: 8.160124513618676\n",
      "TIMESTEP 231278 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.39629 / Loss  0.04175781458616257\n",
      "fps: 8.978110751974656\n",
      "TIMESTEP 231279 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.917539 / Loss  0.12914785742759705\n",
      "fps: 7.73450123090257\n",
      "TIMESTEP 231280 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.720059 / Loss  0.0954485535621643\n",
      "fps: 8.730712227939584\n",
      "TIMESTEP 231281 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.774745 / Loss  0.013648569583892822\n",
      "fps: 8.460402979685613\n",
      "TIMESTEP 231282 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.756759 / Loss  0.04861237853765488\n",
      "fps: 8.636777154765017\n",
      "TIMESTEP 231283 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.474401 / Loss  0.02463722787797451\n",
      "fps: 9.47634023786285\n",
      "TIMESTEP 231284 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.277421 / Loss  0.042886391282081604\n",
      "fps: 8.664682101105422\n",
      "TIMESTEP 231285 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.46202 / Loss  0.06108693778514862\n",
      "fps: 8.210666436977817\n",
      "TIMESTEP 231286 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.836211 / Loss  0.0331420823931694\n",
      "fps: 7.6869860365041225\n",
      "TIMESTEP 231287 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.557901 / Loss  2.919259548187256\n",
      "fps: 7.915722724441844\n",
      "TIMESTEP 231288 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.618899 / Loss  0.06104420870542526\n",
      "fps: 6.046784940934949\n",
      "TIMESTEP 231289 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.993239 / Loss  0.13624995946884155\n",
      "fps: 9.464066681408541\n",
      "TIMESTEP 231290 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.579693 / Loss  0.026797175407409668\n",
      "fps: 9.623516940888722\n",
      "TIMESTEP 231291 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.637024 / Loss  0.021743888035416603\n",
      "fps: 9.131093757823674\n",
      "TIMESTEP 231292 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.689783 / Loss  0.03394128754734993\n",
      "fps: 8.329104874774611\n",
      "TIMESTEP 231293 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.888035 / Loss  0.06763769686222076\n",
      "fps: 9.40574529634696\n",
      "TIMESTEP 231294 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.820778 / Loss  0.07329460978507996\n",
      "fps: 7.930345079250435\n",
      "TIMESTEP 231295 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.743615 / Loss  0.1525612473487854\n",
      "fps: 9.458389709729213\n",
      "TIMESTEP 231296 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.816066 / Loss  0.02116451784968376\n",
      "fps: 9.360843977155303\n",
      "TIMESTEP 231297 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.858434 / Loss  0.04316728189587593\n",
      "fps: 9.159528910261029\n",
      "TIMESTEP 231298 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  1.5322192 / Loss  0.07423929870128632\n",
      "fps: 9.416451328287941\n",
      "TIMESTEP 231299 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.172393 / Loss  0.015509353950619698\n",
      "fps: 8.169947524455473\n",
      "TIMESTEP 231300 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.9203005 / Loss  0.05988268926739693\n",
      "fps: 9.380691132825342\n",
      "TIMESTEP 231301 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.96431 / Loss  0.01992357149720192\n",
      "fps: 8.598074285749428\n",
      "TIMESTEP 231302 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.9844055 / Loss  0.04821176081895828\n",
      "fps: 9.078029902949606\n",
      "TIMESTEP 231303 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.644005 / Loss  0.04973787069320679\n",
      "fps: 9.28746769882797\n",
      "TIMESTEP 231304 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.695509 / Loss  0.0750502198934555\n",
      "fps: 9.435112992698103\n",
      "TIMESTEP 231305 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.025147 / Loss  0.031416453421115875\n",
      "fps: 9.563154654688889\n",
      "TIMESTEP 231306 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.121379 / Loss  0.041835635900497437\n",
      "fps: 9.300606912639616\n",
      "TIMESTEP 231307 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.0488205 / Loss  0.03951822966337204\n",
      "fps: 9.592505854800937\n",
      "TIMESTEP 231308 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.471037 / Loss  0.16447573900222778\n",
      "fps: 7.837432707418114\n",
      "TIMESTEP 231309 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.260574 / Loss  0.03728552162647247\n",
      "fps: 9.012972668647915\n",
      "TIMESTEP 231310 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.486979 / Loss  0.056166354566812515\n",
      "fps: 9.712791750514667\n",
      "TIMESTEP 231311 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.671576 / Loss  0.0292937271296978\n",
      "fps: 9.101985191357864\n",
      "TIMESTEP 231312 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.281385 / Loss  5.111726760864258\n",
      "fps: 9.303804656445202\n",
      "TIMESTEP 231313 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.617631 / Loss  0.03340663015842438\n",
      "fps: 9.552656511916041\n",
      "TIMESTEP 231314 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.753004 / Loss  2.9296457767486572\n",
      "fps: 9.074180483921216\n",
      "TIMESTEP 231315 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.225255 / Loss  0.5997046232223511\n",
      "fps: 9.346409335927142\n",
      "TIMESTEP 231316 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.752698 / Loss  0.030845068395137787\n",
      "fps: 9.46851056721162\n",
      "TIMESTEP 231317 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.66862 / Loss  0.025619834661483765\n",
      "fps: 8.58981584638574\n",
      "TIMESTEP 231318 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.376413 / Loss  0.10785983502864838\n",
      "fps: 7.52365816295414\n",
      "TIMESTEP 231319 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.618083 / Loss  0.08854889869689941\n",
      "fps: 9.004536291404662\n",
      "TIMESTEP 231320 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.553115 / Loss  0.03850758075714111\n",
      "fps: 9.028610052157216\n",
      "TIMESTEP 231321 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.207646 / Loss  0.05562756583094597\n",
      "fps: 8.584822707809698\n",
      "TIMESTEP 231322 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.94701 / Loss  0.054301243275403976\n",
      "fps: 8.67861251582894\n",
      "TIMESTEP 231323 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.105657 / Loss  0.0790289044380188\n",
      "fps: 8.56648244141351\n",
      "TIMESTEP 231324 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.775657 / Loss  0.06309442222118378\n",
      "fps: 5.806462509223356\n",
      "TIMESTEP 231325 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.133749 / Loss  0.9364320039749146\n",
      "fps: 7.861023283360541\n",
      "TIMESTEP 231326 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.11851 / Loss  0.05362509563565254\n",
      "fps: 7.27114877210744\n",
      "TIMESTEP 231327 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.99708 / Loss  0.59462571144104\n",
      "fps: 7.3201066696452255\n",
      "TIMESTEP 231328 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.479373 / Loss  0.07717519998550415\n",
      "fps: 7.854531290379365\n",
      "TIMESTEP 231329 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.186987 / Loss  0.1030210554599762\n",
      "fps: 8.127850306467897\n",
      "TIMESTEP 231330 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.335432 / Loss  0.04951518028974533\n",
      "fps: 9.360217273415026\n",
      "TIMESTEP 231331 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.259055 / Loss  0.08433184772729874\n",
      "fps: 7.709848369266514\n",
      "TIMESTEP 231332 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.844452 / Loss  0.051753923296928406\n",
      "fps: 7.925954201358312\n",
      "TIMESTEP 231333 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.1722355 / Loss  0.06111762300133705\n",
      "fps: 7.456633238102518\n",
      "TIMESTEP 231334 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.857007 / Loss  0.08249104022979736\n",
      "fps: 7.938074635961376\n",
      "TIMESTEP 231335 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.846942 / Loss  0.09000929445028305\n",
      "fps: 7.662648665436542\n",
      "TIMESTEP 231336 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.411597 / Loss  0.10069975256919861\n",
      "fps: 8.728895252524412\n",
      "TIMESTEP 231337 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.621576 / Loss  0.02977137081325054\n",
      "fps: 8.78364358666675\n",
      "TIMESTEP 231338 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.083821 / Loss  0.026785725727677345\n",
      "fps: 9.101728421852114\n",
      "TIMESTEP 231339 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.287651 / Loss  0.02897760272026062\n",
      "fps: 8.166527452457862\n",
      "TIMESTEP 231340 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.423209 / Loss  0.08452330529689789\n",
      "fps: 9.301555691079448\n",
      "TIMESTEP 231341 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.113692 / Loss  0.035630449652671814\n",
      "fps: 7.813590265203168\n",
      "TIMESTEP 231342 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.5350485 / Loss  0.2165592908859253\n",
      "fps: 7.64063561691748\n",
      "TIMESTEP 231343 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.344084 / Loss  0.07580706477165222\n",
      "fps: 7.955193165933605\n",
      "TIMESTEP 231344 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.936785 / Loss  0.07334485650062561\n",
      "fps: 9.2213310820318\n",
      "TIMESTEP 231345 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.445463 / Loss  2.050147294998169\n",
      "fps: 7.740639100866468\n",
      "TIMESTEP 231346 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.596226 / Loss  0.09382406622171402\n",
      "fps: 8.147237929112125\n",
      "TIMESTEP 231347 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.147336 / Loss  0.03943385183811188\n",
      "fps: 7.467585833624134\n",
      "TIMESTEP 231348 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.304728 / Loss  0.044723618775606155\n",
      "fps: 6.829756953830021\n",
      "TIMESTEP 231349 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.656796 / Loss  0.04643474519252777\n",
      "fps: 7.571055177692097\n",
      "TIMESTEP 231350 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.152792 / Loss  0.0913180410861969\n",
      "fps: 9.500100792523686\n",
      "TIMESTEP 231351 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.371309 / Loss  0.05195775255560875\n",
      "fps: 8.718027382682022\n",
      "TIMESTEP 231352 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.56652 / Loss  0.046747103333473206\n",
      "fps: 8.379926396253481\n",
      "TIMESTEP 231353 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.2578745 / Loss  0.06612324714660645\n",
      "fps: 7.629114402956841\n",
      "TIMESTEP 231354 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.2144375 / Loss  0.022912941873073578\n",
      "fps: 7.57179323317772\n",
      "TIMESTEP 231355 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.612683 / Loss  0.03867296129465103\n",
      "fps: 8.223206425948472\n",
      "TIMESTEP 231356 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.706575 / Loss  0.02351216971874237\n",
      "fps: 7.126722081382151\n",
      "TIMESTEP 231357 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.774512 / Loss  0.09562968462705612\n",
      "fps: 8.926501103494363\n",
      "TIMESTEP 231358 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.416245 / Loss  0.045757975429296494\n",
      "fps: 8.00531358552506\n",
      "TIMESTEP 231359 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.623102 / Loss  0.23790588974952698\n",
      "fps: 7.546019466383607\n",
      "TIMESTEP 231360 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.477698 / Loss  0.08964116871356964\n",
      "fps: 5.224092856066371\n",
      "TIMESTEP 231361 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.90128 / Loss  0.04872120916843414\n",
      "fps: 9.003898401140326\n",
      "TIMESTEP 231362 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.066597 / Loss  0.04991696774959564\n",
      "fps: 9.147523107053594\n",
      "TIMESTEP 231363 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.657569 / Loss  0.04714806377887726\n",
      "fps: 7.995211608038094\n",
      "TIMESTEP 231364 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.872236 / Loss  0.044121477752923965\n",
      "fps: 7.808411771714524\n",
      "TIMESTEP 231365 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.544472 / Loss  0.04571733996272087\n",
      "fps: 7.963364344028859\n",
      "TIMESTEP 231366 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.34233 / Loss  0.1175072193145752\n",
      "fps: 7.328368900894227\n",
      "TIMESTEP 231367 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.303277 / Loss  0.08987867832183838\n",
      "fps: 8.808158190951398\n",
      "TIMESTEP 231368 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.519791 / Loss  0.14577844738960266\n",
      "fps: 8.91248379762436\n",
      "TIMESTEP 231369 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.746148 / Loss  0.08095835149288177\n",
      "fps: 8.77247391350725\n",
      "TIMESTEP 231370 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.472913 / Loss  0.09727242588996887\n",
      "fps: 7.796915664083994\n",
      "TIMESTEP 231371 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.441475 / Loss  0.06250926852226257\n",
      "fps: 9.097207702351568\n",
      "TIMESTEP 231372 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.680631 / Loss  0.4966157376766205\n",
      "fps: 8.7334027401824\n",
      "TIMESTEP 231373 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.442402 / Loss  0.028252029791474342\n",
      "fps: 9.335508641508174\n",
      "TIMESTEP 231374 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.749381 / Loss  0.2815178632736206\n",
      "fps: 8.53076466233312\n",
      "TIMESTEP 231375 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.297731 / Loss  0.08240155875682831\n",
      "fps: 7.310805228398171\n",
      "TIMESTEP 231376 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.558575 / Loss  0.076976478099823\n",
      "fps: 9.26750069600647\n",
      "TIMESTEP 231377 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.147401 / Loss  0.06393064558506012\n",
      "fps: 9.067510657984625\n",
      "TIMESTEP 231378 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.570619 / Loss  0.06524242460727692\n",
      "fps: 9.135926813330428\n",
      "TIMESTEP 231379 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.359612 / Loss  0.07287059724330902\n",
      "fps: 9.351473073544428\n",
      "TIMESTEP 231380 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.851057 / Loss  0.07637423276901245\n",
      "fps: 9.170363114811446\n",
      "TIMESTEP 231381 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.4983 / Loss  0.046434611082077026\n",
      "fps: 8.694515845508366\n",
      "TIMESTEP 231382 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.574577 / Loss  0.048062048852443695\n",
      "fps: 7.5059798316019295\n",
      "TIMESTEP 231383 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  13.420663 / Loss  6.713386058807373\n",
      "fps: 8.805754187363798\n",
      "TIMESTEP 231384 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.21334 / Loss  0.057203635573387146\n",
      "fps: 8.000640920483894\n",
      "TIMESTEP 231385 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.202721 / Loss  0.07264000177383423\n",
      "fps: 8.544528557110146\n",
      "TIMESTEP 231386 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.41736 / Loss  0.045590054243803024\n",
      "fps: 8.149042450053333\n",
      "TIMESTEP 231387 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.267007 / Loss  0.0372275672852993\n",
      "fps: 8.14353641512328\n",
      "TIMESTEP 231388 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.909063 / Loss  0.03790006786584854\n",
      "fps: 8.731166589991735\n",
      "TIMESTEP 231389 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.046603 / Loss  0.03567245975136757\n",
      "fps: 7.487555563489655\n",
      "TIMESTEP 231390 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.706568 / Loss  0.0651359111070633\n",
      "fps: 6.79958563468737\n",
      "TIMESTEP 231391 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.5454 / Loss  4.58485746383667\n",
      "fps: 8.881401440317454\n",
      "TIMESTEP 231392 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.700918 / Loss  0.0730905681848526\n",
      "fps: 8.57296095231866\n",
      "TIMESTEP 231393 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.1850012 / Loss  3.7544732093811035\n",
      "fps: 9.087529926659373\n",
      "TIMESTEP 231394 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.401052 / Loss  3.128204822540283\n",
      "fps: 8.683176064823057\n",
      "TIMESTEP 231395 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.312426 / Loss  0.031831417232751846\n",
      "fps: 8.32807951806272\n",
      "TIMESTEP 231396 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.058407 / Loss  0.11326391994953156\n",
      "fps: 5.535872998274949\n",
      "TIMESTEP 231397 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.387905 / Loss  0.1464148908853531\n",
      "fps: 7.219807761161144\n",
      "TIMESTEP 231398 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD -1 / Q_MAX  11.253531 / Loss  0.30685660243034363\n",
      "fps: 8.77785311869543\n",
      "TIMESTEP 231399 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.422939 / Loss  0.9281196594238281\n",
      "fps: 8.833386686435395\n",
      "TIMESTEP 231400 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.349234 / Loss  0.054056376218795776\n",
      "fps: 8.828998442302025\n",
      "TIMESTEP 231401 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.755984 / Loss  0.19264090061187744\n",
      "fps: 9.134255548973831\n",
      "TIMESTEP 231402 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.727273 / Loss  0.07895605266094208\n",
      "fps: 8.090630093650839\n",
      "TIMESTEP 231403 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.472165 / Loss  0.12999054789543152\n",
      "fps: 8.530157432433807\n",
      "TIMESTEP 231404 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.495554 / Loss  0.09406071156263351\n",
      "fps: 9.162550298624188\n",
      "TIMESTEP 231405 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.086742 / Loss  0.04667501151561737\n",
      "fps: 8.832996030283566\n",
      "TIMESTEP 231406 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.474974 / Loss  0.08766341954469681\n",
      "fps: 8.786642924478894\n",
      "TIMESTEP 231407 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.49337 / Loss  0.14516183733940125\n",
      "fps: 9.0624168150312\n",
      "TIMESTEP 231408 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.143652 / Loss  0.9766858816146851\n",
      "fps: 9.128748685960288\n",
      "TIMESTEP 231409 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.82007 / Loss  1.7494927644729614\n",
      "fps: 9.413872897238214\n",
      "TIMESTEP 231410 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.759824 / Loss  0.10349217057228088\n",
      "fps: 8.71232307622003\n",
      "TIMESTEP 231411 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.988438 / Loss  0.09181465953588486\n",
      "fps: 8.830243814119365\n",
      "TIMESTEP 231412 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.028618 / Loss  0.4690646231174469\n",
      "fps: 9.288948635438514\n",
      "TIMESTEP 231413 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.944749 / Loss  0.2670925259590149\n",
      "fps: 8.955930364894614\n",
      "TIMESTEP 231414 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.890235 / Loss  0.07853779196739197\n",
      "fps: 8.588215300002663\n",
      "TIMESTEP 231415 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.527951 / Loss  0.17598719894886017\n",
      "fps: 9.277463193657985\n",
      "TIMESTEP 231416 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.765657 / Loss  0.20165099203586578\n",
      "fps: 7.522983434134722\n",
      "TIMESTEP 231417 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  9.935822 / Loss  0.2702881693840027\n",
      "fps: 7.422088757783869\n",
      "TIMESTEP 231418 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  9.952217 / Loss  0.11031733453273773\n",
      "fps: 7.773693311660992\n",
      "TIMESTEP 231419 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.903529 / Loss  0.5991394519805908\n",
      "fps: 7.6869860365041225\n",
      "TIMESTEP 231420 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.465905 / Loss  0.11281570792198181\n",
      "fps: 7.460744988731427\n",
      "TIMESTEP 231421 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.36618 / Loss  0.24984551966190338\n",
      "fps: 8.763547621435496\n",
      "TIMESTEP 231422 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.734915 / Loss  0.11599794030189514\n",
      "fps: 8.996038512436755\n",
      "TIMESTEP 231423 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.738477 / Loss  0.092552050948143\n",
      "fps: 8.506594465232778\n",
      "TIMESTEP 231424 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.736715 / Loss  0.0909629613161087\n",
      "fps: 8.781694195582672\n",
      "TIMESTEP 231425 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.237864 / Loss  0.11426839232444763\n",
      "fps: 7.686760633589479\n",
      "TIMESTEP 231426 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.277408 / Loss  0.13980650901794434\n",
      "fps: 7.696634388653701\n",
      "TIMESTEP 231427 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.59199 / Loss  0.14067615568637848\n",
      "fps: 7.78846039574544\n",
      "TIMESTEP 231428 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.633156 / Loss  0.6287481784820557\n",
      "fps: 7.54677980618021\n",
      "TIMESTEP 231429 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.9694605 / Loss  0.14157819747924805\n",
      "fps: 7.916155978869132\n",
      "TIMESTEP 231430 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  10.732327 / Loss  0.23410889506340027\n",
      "fps: 6.350618360647795\n",
      "TIMESTEP 231431 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.436079 / Loss  0.09378208220005035\n",
      "fps: 8.28432491793306\n",
      "TIMESTEP 231432 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  10.992046 / Loss  0.06159500405192375\n",
      "fps: 5.600866375471212\n",
      "TIMESTEP 231433 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.823201 / Loss  0.028363458812236786\n",
      "fps: 8.710947916709934\n",
      "TIMESTEP 231434 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  1.9820893 / Loss  0.13685965538024902\n",
      "fps: 8.92817322040176\n",
      "TIMESTEP 231435 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.175795 / Loss  0.055133156478405\n",
      "fps: 7.269082123929387\n",
      "TIMESTEP 231436 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.777608 / Loss  0.10295319557189941\n",
      "fps: 8.983418077764975\n",
      "TIMESTEP 231437 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.611138 / Loss  0.06980061531066895\n",
      "fps: 7.820014729050722\n",
      "TIMESTEP 231438 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.377522 / Loss  0.21423698961734772\n",
      "fps: 9.078953463454125\n",
      "TIMESTEP 231439 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.354396 / Loss  0.26895272731781006\n",
      "fps: 8.005114962601608\n",
      "TIMESTEP 231440 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.749119 / Loss  0.2465975135564804\n",
      "fps: 8.215104982764023\n",
      "TIMESTEP 231441 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.896053 / Loss  0.03621061146259308\n",
      "fps: 7.43672240553618\n",
      "TIMESTEP 231442 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.5385 / Loss  0.08801716566085815\n",
      "fps: 7.480891577740164\n",
      "TIMESTEP 231443 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.794824 / Loss  0.19047416746616364\n",
      "fps: 9.497390331659975\n",
      "TIMESTEP 231444 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.126136 / Loss  0.5116633772850037\n",
      "fps: 7.920610790813966\n",
      "TIMESTEP 231445 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  12.117807 / Loss  0.08721897006034851\n",
      "fps: 7.544037872138365\n",
      "TIMESTEP 231446 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  11.875091 / Loss  0.07917072623968124\n",
      "fps: 8.63782657226293\n",
      "TIMESTEP 231447 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.110098 / Loss  0.06731070578098297\n",
      "fps: 8.616143107174258\n",
      "TIMESTEP 231448 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.145113 / Loss  0.07623578608036041\n",
      "fps: 7.647364275503953\n",
      "TIMESTEP 231449 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.765568 / Loss  0.06820671260356903\n",
      "fps: 8.986998294436779\n",
      "TIMESTEP 231450 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.514183 / Loss  0.08215226978063583\n",
      "fps: 9.18188624393063\n",
      "TIMESTEP 231451 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.987978 / Loss  0.5449973344802856\n",
      "fps: 8.741338490779953\n",
      "TIMESTEP 231452 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.522124 / Loss  0.15964800119400024\n",
      "fps: 9.105640789619367\n",
      "TIMESTEP 231453 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.620012 / Loss  0.04523114114999771\n",
      "fps: 9.139171607431956\n",
      "TIMESTEP 231454 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.194241 / Loss  0.08233417570590973\n",
      "fps: 9.460373741132953\n",
      "TIMESTEP 231455 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.263102 / Loss  0.05810421705245972\n",
      "fps: 8.398568702481143\n",
      "TIMESTEP 231456 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.458421 / Loss  0.07219958305358887\n",
      "fps: 8.970756256509958\n",
      "TIMESTEP 231457 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.139662 / Loss  1.2765483856201172\n",
      "fps: 8.789054920277692\n",
      "TIMESTEP 231458 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.198823 / Loss  0.04047622159123421\n",
      "fps: 8.267456689669581\n",
      "TIMESTEP 231459 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.958471 / Loss  0.1026671975851059\n",
      "fps: 8.513967659823237\n",
      "TIMESTEP 231460 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.401753 / Loss  0.03991060331463814\n",
      "fps: 8.775465626686863\n",
      "TIMESTEP 231461 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.599162 / Loss  0.06487482786178589\n",
      "fps: 7.664833136579108\n",
      "TIMESTEP 231462 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.440678 / Loss  0.23731309175491333\n",
      "fps: 7.917650323459955\n",
      "TIMESTEP 231463 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.016371 / Loss  0.05434105917811394\n",
      "fps: 8.968991435811352\n",
      "TIMESTEP 231464 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.348791 / Loss  0.07533705234527588\n",
      "fps: 8.931329146943147\n",
      "TIMESTEP 231465 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.033573 / Loss  0.03127896040678024\n",
      "fps: 8.92619714952744\n",
      "TIMESTEP 231466 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.847618 / Loss  0.08305822312831879\n",
      "fps: 9.4051336557845\n",
      "TIMESTEP 231467 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.701651 / Loss  0.06075645983219147\n",
      "fps: 8.839232049904112\n",
      "TIMESTEP 231468 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.3103695 / Loss  0.06877642869949341\n",
      "fps: 5.8361461407558615\n",
      "TIMESTEP 231469 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.878319 / Loss  0.06095505505800247\n",
      "fps: 9.588470893761773\n",
      "TIMESTEP 231470 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.30045283 / Loss  0.19765068590641022\n",
      "fps: 9.279351510163627\n",
      "TIMESTEP 231471 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.73956 / Loss  0.0787825882434845\n",
      "fps: 9.46118466018673\n",
      "TIMESTEP 231472 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.090344 / Loss  0.1232801228761673\n",
      "fps: 9.598345011922689\n",
      "TIMESTEP 231473 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  12.684904 / Loss  0.10450025647878647\n",
      "fps: 9.738229182387016\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-72cb52f7ef17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplay_Game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-e511e924bf20>\u001b[0m in \u001b[0;36mplay_Game\u001b[0;34m(observe)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain_Network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgame_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-e1b764ad5ca8>\u001b[0m in \u001b[0;36mtrain_Network\u001b[0;34m(model, game_state, observe)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mloss_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mq_values_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_sa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0ms_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ms_t1\u001b[0m \u001b[0;31m#reset game to initial frame if terminate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    449\u001b[0m                                        name=indexer)\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   6668\u001b[0m             \u001b[0midx_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6669\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6670\u001b[0;31m                 \u001b[0mcombined_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6671\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6672\u001b[0m                 \u001b[0mcombined_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4013\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4015\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4017\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_concat\u001b[0;34m(self, to_concat, name)\u001b[0m\n\u001b[1;32m   4020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4021\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4022\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concat_same_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4023\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_concat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concat_index_asobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_concat_same_dtype\u001b[0;34m(self, to_concat, name)\u001b[0m\n\u001b[1;32m   4028\u001b[0m         \"\"\"\n\u001b[1;32m   4029\u001b[0m         \u001b[0;31m# must be overridden in specific classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4030\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_concat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concat_index_asobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4032\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/concat.py\u001b[0m in \u001b[0;36m_concat_index_asobject\u001b[0;34m(to_concat, name)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m     \u001b[0mattribs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_attributes_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m     \u001b[0mattribs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_attributes_dict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0man\u001b[0m \u001b[0mattributes\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmy\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \"\"\"\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attributes\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     _index_shared_docs['_shallow_copy'] = \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "play_Game(observe=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
