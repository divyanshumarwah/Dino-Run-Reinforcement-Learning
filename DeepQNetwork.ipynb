{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2  #opencv\n",
    "from IPython.display import clear_output\n",
    "from random import randint\n",
    "import io\n",
    "from io import BytesIO\n",
    "import time\n",
    "import os\n",
    "\n",
    "#keras imports\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import SGD , Adam\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "import random\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "import base64\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path variables\n",
    "game_url = \"chrome://dino\"\n",
    "chromedriver_path = \"./chrome_driver/chromedriver\"\n",
    "loss_file_path = \"./objects_dqn/loss_df.csv\"\n",
    "actions_file_path = \"./objects_dqn/actions_df.csv\"\n",
    "q_value_file_path = \"./objects_dqn/q_values.csv\"\n",
    "scores_file_path = \"./objects_dqn/scores_df.csv\"\n",
    "\n",
    "#scripts\n",
    "#create id for canvas for faster selection from DOM\n",
    "init_script = \"document.getElementsByClassName('runner-canvas')[0].id = 'runner-canvas'\"\n",
    "\n",
    "#get image from canvas\n",
    "getbase64Script = \"canvasRunner = document.getElementById('runner-canvas'); \\\n",
    "return canvasRunner.toDataURL().substring(22)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Game class: Selenium interfacing between the python and browser\n",
    "* __init__():  Launch the broswer window using the attributes in chrome_options\n",
    "* crashed() : return true if the agent as crashed on an obstacles. Gets javascript variable from game decribing the state\n",
    "* get_playing(): true if game in progress, false is crashed or paused\n",
    "* restart() : sends a signal to browser-javascript to restart the game\n",
    "* press_up(): sends a single to press up get to the browser\n",
    "* get_score(): gets current game score from javascript variables.\n",
    "* pause(): pause the game\n",
    "* resume(): resume a paused game if not crashed\n",
    "* end(): close the browser and end the game\n",
    "'''\n",
    "class Game:\n",
    "    def __init__(self,custom_config=True):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"disable-infobars\")\n",
    "        chrome_options.add_argument(\"--mute-audio\")\n",
    "        self._driver = webdriver.Chrome(executable_path = chromedriver_path,chrome_options=chrome_options)\n",
    "        self._driver.set_window_position(x=-10,y=0)\n",
    "        self._driver.get('chrome://dino')\n",
    "        self._driver.execute_script(\"Runner.config.ACCELERATION=0\")\n",
    "        self._driver.execute_script(init_script)\n",
    "    def crashed(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.crashed\")\n",
    "    def get_playing(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.playing\")\n",
    "    def restart(self):\n",
    "        self._driver.execute_script(\"Runner.instance_.restart()\")\n",
    "    def press_up(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ARROW_UP)\n",
    "    def get_score(self):\n",
    "        score_array = self._driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = ''.join(score_array) # the javascript object is of type array with score in the formate[1,0,0] which is 100.\n",
    "        return int(score)\n",
    "    def pause(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.stop()\")\n",
    "    def resume(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.play()\")\n",
    "    def end(self):\n",
    "        self._driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dino_Agent:\n",
    "    def __init__(self,game): #takes game as input for taking actions\n",
    "        self._game = game; \n",
    "        self.jump(); #to start the game, we need to jump once\n",
    "    def running(self):\n",
    "        return self._game.get_playing()\n",
    "    def is_crashed(self):\n",
    "        return self._game.crashed()\n",
    "    def jump(self):\n",
    "        self._game.press_up()\n",
    "    def duck(self):\n",
    "        self._game.press_down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game_state:\n",
    "    def __init__(self,agent,game):\n",
    "        self._agent = agent\n",
    "        self._game = game\n",
    "        self._display = show_img() #display the processed image on screen using openCV, implemented using python coroutine \n",
    "        self._display.__next__() # initiliaze the display coroutine \n",
    "    def get_state(self,actions):\n",
    "        actions_df.loc[len(actions_df)] = actions[1] # storing actions in a dataframe\n",
    "        score = self._game.get_score() \n",
    "        reward = 0.1\n",
    "        game_over = False #game over\n",
    "        if actions[1] == 1:\n",
    "            self._agent.jump()\n",
    "        image = grab_screen(self._game._driver) \n",
    "        self._display.send(image) #display the image on screen\n",
    "        if self._agent.is_crashed():\n",
    "            scores_df.loc[len(loss_df)] = score # log the score when game is over\n",
    "            self._game.restart()\n",
    "            reward = -1\n",
    "            game_over = True\n",
    "        return image, reward, game_over #return the Experience tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, name):\n",
    "    with open('objects_dqn/'+ name + '.pkl', 'wb') as f: #dump files into objects folder\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "def load_object(name):\n",
    "    with open('objects_dqn/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def grab_screen(_driver):\n",
    "    image_b64 = _driver.execute_script(getbase64Script)\n",
    "    screen = np.array(Image.open(BytesIO(base64.b64decode(image_b64))))\n",
    "    image = img_process(screen)#processing image as required\n",
    "    return image\n",
    "\n",
    "def img_process(image):\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #RGB to Grey Scale\n",
    "    image = image[:300, :500] #Crop Region of Interest(ROI)\n",
    "    image = cv2.resize(image, (80,80))\n",
    "    return  image\n",
    "\n",
    "def show_img(graphs = False):\n",
    "    \"\"\"\n",
    "    Show images in new window\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        screen = (yield)\n",
    "        window_title = \"logs\" if graphs else \"game_play\"\n",
    "        cv2.namedWindow(window_title, cv2.WINDOW_NORMAL)        \n",
    "        imS = cv2.resize(screen, (800, 400)) \n",
    "        cv2.imshow(window_title, screen)\n",
    "        if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize log structures from file if exists else create new\n",
    "loss_df = pd.read_csv(loss_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns =['loss'])\n",
    "scores_df = pd.read_csv(scores_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns = ['scores'])\n",
    "actions_df = pd.read_csv(actions_file_path) if os.path.isfile(actions_file_path) else pd.DataFrame(columns = ['actions'])\n",
    "q_values_df =pd.read_csv(actions_file_path) if os.path.isfile(q_value_file_path) else pd.DataFrame(columns = ['qvalues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game parameters\n",
    "ACTIONS = 2 # possible actions: jump, do nothing\n",
    "GAMMA = 0.99 # decay rate of past observations original 0.99\n",
    "OBSERVATION = 100 # timesteps to observe before training\n",
    "EXPLORE = 100000  # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.0001 # final value of epsilon\n",
    "INITIAL_EPSILON = 0.1 # starting value of epsilon\n",
    "REPLAY_MEMORY = 50000 # number of previous transitions to remember\n",
    "BATCH_SIZE = 16 # size of minibatch\n",
    "FRAME_PER_ACTION = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "img_rows , img_cols = 80,80\n",
    "img_channels = 4 #We stack 4 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training variables saved as checkpoints to filesystem to resume training from the same step\n",
    "def init_cache():\n",
    "    \"\"\"initial variable caching, done only once\"\"\"\n",
    "    save_object(INITIAL_EPSILON,\"epsilon\")\n",
    "    t = 0\n",
    "    save_object(t,\"time\")\n",
    "    D = deque()\n",
    "    save_object(D,\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Call only once to init file structure\n",
    "'''\n",
    "init_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    print(\"Now we build the model\")\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (8, 8), padding='same',strides=(4, 4),input_shape=(img_cols,img_rows,img_channels)))  #80*80*4\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (4, 4),strides=(2, 2),  padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3),strides=(1, 1),  padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(ACTIONS))\n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    model.compile(loss='mse',optimizer=adam)\n",
    "    \n",
    "    #create model file if not present\n",
    "    if not os.path.isfile(loss_file_path):\n",
    "        model.save_weights('model_dqn.h5')\n",
    "    print(\"We finish building the model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "main training module\n",
    "Parameters:\n",
    "* model => Keras Model to be trained\n",
    "* game_state => Game State module with access to game environment and dino\n",
    "* observe => flag to indicate whether the model is to be trained(weight updates), else just play\n",
    "'''\n",
    "def train_Network(model,game_state,observe=False):\n",
    "    last_time = time.time()\n",
    "    # store the previous observations in replay memory\n",
    "    D = load_object(\"D\") #load from file system\n",
    "    # get the first state by doing nothing\n",
    "    do_nothing = np.zeros(ACTIONS)\n",
    "    do_nothing[0] =1 #0 => do nothing,\n",
    "                     #1=> jump\n",
    "    \n",
    "    x_t, r_0, terminal = game_state.get_state(do_nothing) # get next step after performing the action\n",
    "    \n",
    "\n",
    "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2) # stack 4 images to create placeholder input\n",
    "    \n",
    "\n",
    "    \n",
    "    s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])  #1*20*40*4\n",
    "    \n",
    "    initial_state = s_t \n",
    "\n",
    "    if observe :\n",
    "        OBSERVE = 999999999    #We keep observe, never train\n",
    "        epsilon = FINAL_EPSILON\n",
    "        print (\"Now we load weight\")\n",
    "        model.load_weights(\"model_dqn.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "        print (\"Weight load successfully\")    \n",
    "    else:                       #We go to training mode\n",
    "        OBSERVE = OBSERVATION\n",
    "        epsilon = load_object(\"epsilon\") \n",
    "        model.load_weights(\"model_dqn.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "\n",
    "    t = load_object(\"time\") # resume from the previous time step stored in file system\n",
    "    while (True): #endless running\n",
    "        \n",
    "        loss = 0\n",
    "        Q_sa = 0\n",
    "        action_index = 0\n",
    "        r_t = 0 #reward at 4\n",
    "        a_t = np.zeros([ACTIONS]) # action at t\n",
    "        \n",
    "        #choose an action epsilon greedy\n",
    "        if t % FRAME_PER_ACTION == 0: #parameter to skip frames for actions\n",
    "            if  random.random() <= epsilon: #randomly explore an action\n",
    "                print(\"----------Random Action----------\")\n",
    "                action_index = random.randrange(ACTIONS)\n",
    "                a_t[action_index] = 1\n",
    "            else: # predict the output\n",
    "                q = model.predict(s_t)       #input a stack of 4 images, get the prediction\n",
    "                max_Q = np.argmax(q)         # chosing index with maximum q value\n",
    "                action_index = max_Q \n",
    "                a_t[action_index] = 1        # o=> do nothing, 1=> jump\n",
    "                \n",
    "        #We reduced the epsilon (exploration parameter) gradually\n",
    "        if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE \n",
    "\n",
    "        #run the selected action and observed next state and reward\n",
    "        x_t1, r_t, terminal = game_state.get_state(a_t)\n",
    "        print('fps: {0}'.format(1 / (time.time()-last_time))) # helpful for measuring frame rate\n",
    "        last_time = time.time()\n",
    "        x_t1 = x_t1.reshape(1, x_t1.shape[0], x_t1.shape[1], 1) #1x20x40x1\n",
    "        s_t1 = np.append(x_t1, s_t[:, :, :, :3], axis=3) # append the new image to input stack and remove the first one\n",
    "        \n",
    "        \n",
    "        # store the transition in D\n",
    "        D.append((s_t, action_index, r_t, s_t1, terminal))\n",
    "        if len(D) > REPLAY_MEMORY:\n",
    "            D.popleft()\n",
    "\n",
    "        #only train if done observing\n",
    "        if t > OBSERVE: \n",
    "            \n",
    "            #sample a minibatch to train on\n",
    "            minibatch = random.sample(D, BATCH_SIZE)\n",
    "            inputs = np.zeros((BATCH_SIZE, s_t.shape[1], s_t.shape[2], s_t.shape[3]))   #32, 20, 40, 4\n",
    "            targets = np.zeros((inputs.shape[0], ACTIONS))                         #32, 2\n",
    "\n",
    "            #Now we do the experience replay\n",
    "            for i in range(0, len(minibatch)):\n",
    "                state_t = minibatch[i][0]    # 4D stack of images\n",
    "                action_t = minibatch[i][1]   #This is action index\n",
    "                reward_t = minibatch[i][2]   #reward at state_t due to action_t\n",
    "                state_t1 = minibatch[i][3]   #next state\n",
    "                terminal = minibatch[i][4]   #wheather the agent died or survided due the action\n",
    "                \n",
    "\n",
    "                inputs[i:i + 1] = state_t    \n",
    "\n",
    "                targets[i] = model.predict(state_t)  # predicted q values\n",
    "                Q_sa = model.predict(state_t1)      #predict q values for next step\n",
    "                \n",
    "                if terminal:\n",
    "                    targets[i, action_t] = reward_t # if terminated, only equals reward\n",
    "                else:\n",
    "                    targets[i, action_t] = reward_t + GAMMA * np.max(Q_sa)\n",
    "\n",
    "            loss += model.train_on_batch(inputs, targets)\n",
    "            loss_df.loc[len(loss_df)] = loss\n",
    "            q_values_df.loc[len(q_values_df)] = np.max(Q_sa)\n",
    "        s_t = initial_state if terminal else s_t1 #reset game to initial frame if terminate\n",
    "        t = t + 1\n",
    "        \n",
    "        # save progress every 1000 iterations\n",
    "        if t % 1000 == 0:\n",
    "            print(\"Now we save model\")\n",
    "            game_state._game.pause() #pause game while saving to filesystem\n",
    "            model.save_weights(\"model_dqn.h5\", overwrite=True)\n",
    "            save_object(D,\"D\") #saving episodes\n",
    "            save_object(t,\"time\") #caching time steps\n",
    "            save_object(epsilon,\"epsilon\") #cache epsilon to avoid repeated randomness in actions\n",
    "            loss_df.to_csv(\"./objects_dqn/loss_df.csv\",index=False)\n",
    "            scores_df.to_csv(\"./objects_dqn/scores_df.csv\",index=False)\n",
    "            actions_df.to_csv(\"./objects_dqn/actions_df.csv\",index=False)\n",
    "            q_values_df.to_csv(q_value_file_path,index=False)\n",
    "            with open(\"model_dqn.json\", \"w\") as outfile:\n",
    "                json.dump(model.to_json(), outfile)\n",
    "            clear_output()\n",
    "            game_state._game.resume()\n",
    "        # print info\n",
    "        state = \"\"\n",
    "        if t <= OBSERVE:\n",
    "            state = \"observe\"\n",
    "        elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "            state = \"explore\"\n",
    "        else:\n",
    "            state = \"train\"\n",
    "\n",
    "        print(\"TIMESTEP\", t, \"/ STATE\", state, \"/ EPSILON\", epsilon, \"/ ACTION\", action_index, \"/ REWARD\", r_t, \"/ Q_MAX \", np.max(Q_sa), \"/ Loss \", loss)\n",
    "\n",
    "    print(\"Episode finished!\")\n",
    "    print(\"************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function\n",
    "def play_Game(observe=False):\n",
    "    game = Game()\n",
    "    dino = Dino_Agent(game)\n",
    "    game_state = Game_state(dino,game)    \n",
    "    model = build_model()\n",
    "    try:\n",
    "        train_Network(model,game_state,observe=observe)\n",
    "    except StopIteration:\n",
    "        game.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 429000 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.740464 / Loss  0.05242258682847023\n",
      "fps: 0.14722106508440413\n",
      "TIMESTEP 429001 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.676862 / Loss  0.05543455109000206\n",
      "fps: 6.315514954218094\n",
      "TIMESTEP 429002 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.708941 / Loss  0.02170681580901146\n",
      "fps: 6.193789234456473\n",
      "TIMESTEP 429003 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.791992 / Loss  0.36152100563049316\n",
      "fps: 5.678306757967872\n",
      "TIMESTEP 429004 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.702464 / Loss  0.014309640973806381\n",
      "fps: 6.076992845489819\n",
      "TIMESTEP 429005 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.731352 / Loss  0.008921011351048946\n",
      "fps: 5.859161225613044\n",
      "TIMESTEP 429006 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  6.5055103 / Loss  0.0925070270895958\n",
      "fps: 5.679875414720022\n",
      "TIMESTEP 429007 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.57353 / Loss  0.011254177428781986\n",
      "fps: 5.489826102663041\n",
      "TIMESTEP 429008 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.66466 / Loss  0.0058377389796078205\n",
      "fps: 6.264100672363788\n",
      "TIMESTEP 429009 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.635422 / Loss  0.021647294983267784\n",
      "fps: 5.442652562299192\n",
      "TIMESTEP 429010 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.644675 / Loss  0.021424636244773865\n",
      "fps: 6.036237828378336\n",
      "TIMESTEP 429011 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.654078 / Loss  0.020411904901266098\n",
      "fps: 5.45562907532879\n",
      "TIMESTEP 429012 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.615646 / Loss  0.007937580347061157\n",
      "fps: 5.491457696975727\n",
      "TIMESTEP 429013 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.633788 / Loss  0.31938645243644714\n",
      "fps: 5.491457696975727\n",
      "TIMESTEP 429014 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.755193 / Loss  0.05054643750190735\n",
      "fps: 5.014368939467301\n",
      "TIMESTEP 429015 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.537884 / Loss  0.03995689004659653\n",
      "fps: 5.516969964025228\n",
      "TIMESTEP 429016 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.563307 / Loss  0.02025734633207321\n",
      "fps: 6.131369020557748\n",
      "TIMESTEP 429017 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.488993 / Loss  2.571726083755493\n",
      "fps: 6.12538755529463\n",
      "TIMESTEP 429018 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.3538 / Loss  0.016170591115951538\n",
      "fps: 5.463133037315679\n",
      "TIMESTEP 429019 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.54307 / Loss  0.028427306562662125\n",
      "fps: 5.643027047971671\n",
      "TIMESTEP 429020 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.43138 / Loss  0.26214683055877686\n",
      "fps: 4.890455441665666\n",
      "TIMESTEP 429021 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.443542 / Loss  0.013740768656134605\n",
      "fps: 5.168097627332498\n",
      "TIMESTEP 429022 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.350318 / Loss  0.85505610704422\n",
      "fps: 6.4158889584037615\n",
      "TIMESTEP 429023 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.265951 / Loss  0.033007800579071045\n",
      "fps: 5.1319653978392\n",
      "TIMESTEP 429024 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.356422 / Loss  2.6429407596588135\n",
      "fps: 5.142239936640034\n",
      "TIMESTEP 429025 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.368645 / Loss  2.900062084197998\n",
      "fps: 6.24414412000274\n",
      "TIMESTEP 429026 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.181374 / Loss  0.015552652068436146\n",
      "fps: 5.670990133949516\n",
      "TIMESTEP 429027 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  7.762752 / Loss  0.04224763065576553\n",
      "fps: 5.015652148956703\n",
      "TIMESTEP 429028 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.099708 / Loss  0.0214421097189188\n",
      "fps: 6.1397878896557785\n",
      "TIMESTEP 429029 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.23551 / Loss  0.02877858839929104\n",
      "fps: 5.9266359947096525\n",
      "TIMESTEP 429030 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  7.7176323 / Loss  0.04411138594150543\n",
      "fps: 5.606391411106908\n",
      "TIMESTEP 429031 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  7.713931 / Loss  0.04095138609409332\n",
      "fps: 5.900331852026914\n",
      "TIMESTEP 429032 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  7.832389 / Loss  0.07105459272861481\n",
      "fps: 5.588061546824268\n",
      "TIMESTEP 429033 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  7.536434 / Loss  0.1324000358581543\n",
      "fps: 5.124842074909644\n",
      "TIMESTEP 429034 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.122287 / Loss  0.055083684623241425\n",
      "fps: 6.3890033024213695\n",
      "TIMESTEP 429035 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  7.7756586 / Loss  0.08924533426761627\n",
      "fps: 5.140298909879713\n",
      "TIMESTEP 429036 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  7.9571934 / Loss  0.06931418925523758\n",
      "fps: 5.082895853026007\n",
      "TIMESTEP 429037 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  7.7317576 / Loss  0.05499495565891266\n",
      "fps: 5.505752135719949\n",
      "TIMESTEP 429038 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  7.8155937 / Loss  0.04991603642702103\n",
      "fps: 5.725996652568867\n",
      "TIMESTEP 429039 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  7.900389 / Loss  0.0316200889647007\n",
      "fps: 3.2848478772993834\n",
      "TIMESTEP 429040 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.161339 / Loss  0.03786074370145798\n",
      "fps: 6.2848443437503745\n",
      "TIMESTEP 429041 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.008452 / Loss  0.024306120350956917\n",
      "fps: 5.749071360624594\n",
      "TIMESTEP 429042 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.014448 / Loss  0.022339841350913048\n",
      "fps: 5.388199747181485\n",
      "TIMESTEP 429043 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.186944 / Loss  0.024643555283546448\n",
      "fps: 5.141225126192362\n",
      "TIMESTEP 429044 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  7.749645 / Loss  0.02322724089026451\n",
      "fps: 5.61558647429924\n",
      "TIMESTEP 429045 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.341513 / Loss  0.13997556269168854\n",
      "fps: 5.904302057628231\n",
      "TIMESTEP 429046 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.352786 / Loss  0.08560796827077866\n",
      "fps: 6.168157613387197\n",
      "TIMESTEP 429047 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.516988 / Loss  0.03613000363111496\n",
      "fps: 6.242545654794684\n",
      "TIMESTEP 429048 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.13108 / Loss  0.013400125317275524\n",
      "fps: 5.299525301061723\n",
      "TIMESTEP 429049 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.33218 / Loss  0.031077411025762558\n",
      "fps: 6.269990686883454\n",
      "TIMESTEP 429050 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.366126 / Loss  0.01225080993026495\n",
      "fps: 6.2726631013483605\n",
      "TIMESTEP 429051 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.568154 / Loss  0.07974129170179367\n",
      "fps: 5.998761432790566\n",
      "TIMESTEP 429052 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.452969 / Loss  0.014967329800128937\n",
      "fps: 6.264718182795828\n",
      "TIMESTEP 429053 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.477678 / Loss  0.010361477732658386\n",
      "fps: 5.50333206934693\n",
      "TIMESTEP 429054 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.618548 / Loss  0.018115848302841187\n",
      "fps: 5.637520530969169\n",
      "TIMESTEP 429055 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.57017 / Loss  0.08764059841632843\n",
      "fps: 5.980798380139599\n",
      "TIMESTEP 429056 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.62959 / Loss  0.00516536133363843\n",
      "fps: 5.464620644189604\n",
      "TIMESTEP 429057 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.769158 / Loss  0.050483815371990204\n",
      "fps: 5.403854057557052\n",
      "TIMESTEP 429058 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.60157 / Loss  0.6534098386764526\n",
      "fps: 5.96252722320469\n",
      "TIMESTEP 429059 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.7856045 / Loss  0.08916885405778885\n",
      "fps: 4.894981432162622\n",
      "TIMESTEP 429060 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD -1 / Q_MAX  8.826275 / Loss  0.16480296850204468\n",
      "fps: 5.14787594935466\n",
      "TIMESTEP 429061 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.912936 / Loss  0.12319745123386383\n",
      "fps: 6.084936304300204\n",
      "TIMESTEP 429062 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.833279 / Loss  0.017675243318080902\n",
      "fps: 5.223735011184011\n",
      "TIMESTEP 429063 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.925154 / Loss  0.0212736614048481\n",
      "fps: 5.290054057053777\n",
      "TIMESTEP 429064 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.950754 / Loss  0.005917977076023817\n",
      "fps: 5.905025243068363\n",
      "TIMESTEP 429065 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.943567 / Loss  0.014277203008532524\n",
      "fps: 5.132474067221482\n",
      "TIMESTEP 429066 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.934641 / Loss  0.009685356169939041\n",
      "fps: 5.000422036504966\n",
      "TIMESTEP 429067 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.968443 / Loss  0.0881057009100914\n",
      "fps: 5.853396580044351\n",
      "TIMESTEP 429068 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.858807 / Loss  0.018723927438259125\n",
      "fps: 5.05045756670841\n",
      "TIMESTEP 429069 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.892679 / Loss  0.0207224041223526\n",
      "fps: 4.938199277337381\n",
      "TIMESTEP 429070 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.772889 / Loss  0.009392451494932175\n",
      "fps: 5.823367867446762\n",
      "TIMESTEP 429071 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  7.9193287 / Loss  0.4086027443408966\n",
      "fps: 3.3822522845079237\n",
      "TIMESTEP 429072 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.829018 / Loss  0.018155500292778015\n",
      "fps: 3.9560545696003864\n",
      "TIMESTEP 429073 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.912105 / Loss  0.01668393611907959\n",
      "fps: 4.415851695410437\n",
      "TIMESTEP 429074 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.798571 / Loss  0.015759624540805817\n",
      "fps: 4.521960754295497\n",
      "TIMESTEP 429075 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.079153 / Loss  0.014299275353550911\n",
      "fps: 2.911811280541777\n",
      "TIMESTEP 429076 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.95403 / Loss  1.30563223361969\n",
      "fps: 5.366105914698662\n",
      "TIMESTEP 429077 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.908559 / Loss  0.006793588399887085\n",
      "fps: 5.324734480806193\n",
      "TIMESTEP 429078 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.793419 / Loss  0.008977577090263367\n",
      "fps: 5.029853144689536\n",
      "TIMESTEP 429079 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.767408 / Loss  0.02222708985209465\n",
      "fps: 5.317477563367086\n",
      "TIMESTEP 429080 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.932341 / Loss  0.14534106850624084\n",
      "fps: 5.312507045464621\n",
      "TIMESTEP 429081 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.906875 / Loss  0.007780453655868769\n",
      "fps: 4.55050378475963\n",
      "TIMESTEP 429082 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.91195 / Loss  0.019631609320640564\n",
      "fps: 4.8050113300233015\n",
      "TIMESTEP 429083 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.609861 / Loss  0.010306332260370255\n",
      "fps: 5.27072259209273\n",
      "TIMESTEP 429084 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.9809 / Loss  0.01873229444026947\n",
      "fps: 4.751363340802349\n",
      "TIMESTEP 429085 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.964953 / Loss  0.015464630909264088\n",
      "fps: 4.997276360092361\n",
      "TIMESTEP 429086 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.2005637 / Loss  2.4827322959899902\n",
      "fps: 4.592823275626074\n",
      "TIMESTEP 429087 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  9.182119 / Loss  2.743129253387451\n",
      "fps: 4.302609280816719\n",
      "TIMESTEP 429088 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.988649 / Loss  0.7507270574569702\n",
      "fps: 4.744279903537705\n",
      "TIMESTEP 429089 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.957401 / Loss  0.014443540014326572\n",
      "fps: 5.016803998799117\n",
      "TIMESTEP 429090 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -2.3408115 / Loss  0.059717897325754166\n",
      "fps: 4.882172863418484\n",
      "TIMESTEP 429091 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.750671 / Loss  0.02296861819922924\n",
      "fps: 5.134585180315667\n",
      "TIMESTEP 429092 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.5402143 / Loss  0.048168737441301346\n",
      "fps: 5.148059184888338\n",
      "TIMESTEP 429093 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.729486 / Loss  0.011465633288025856\n",
      "fps: 4.414211172175436\n",
      "TIMESTEP 429094 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.9171715 / Loss  0.018187064677476883\n",
      "fps: 4.631458063718237\n",
      "TIMESTEP 429095 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.651985 / Loss  0.011620039120316505\n",
      "fps: 4.69250227391979\n",
      "TIMESTEP 429096 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.743929 / Loss  0.007386848330497742\n",
      "fps: 4.830822884969328\n",
      "TIMESTEP 429097 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.716669 / Loss  0.016326937824487686\n",
      "fps: 5.551854587426768\n",
      "TIMESTEP 429098 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.781351 / Loss  0.03296642750501633\n",
      "fps: 5.108003176134177\n",
      "TIMESTEP 429099 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.640015 / Loss  0.027981262654066086\n",
      "fps: 4.322981878598359\n",
      "TIMESTEP 429100 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.378202 / Loss  0.01514846459031105\n",
      "fps: 4.703468584699472\n",
      "TIMESTEP 429101 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.675838 / Loss  0.022440480068325996\n",
      "fps: 4.5072611722328135\n",
      "TIMESTEP 429102 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.599761 / Loss  0.06271262466907501\n",
      "fps: 4.737115899585843\n",
      "TIMESTEP 429103 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.627755 / Loss  0.672290563583374\n",
      "fps: 5.25940109368554\n",
      "TIMESTEP 429104 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.574862 / Loss  0.022364597767591476\n",
      "fps: 4.991293834282967\n",
      "TIMESTEP 429105 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.620336 / Loss  0.025334011763334274\n",
      "fps: 4.643296878234657\n",
      "TIMESTEP 429106 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.561486 / Loss  0.006994308903813362\n",
      "fps: 4.726945694779098\n",
      "TIMESTEP 429107 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.432121 / Loss  0.025806790217757225\n",
      "fps: 4.986113835403597\n",
      "TIMESTEP 429108 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  7.640481 / Loss  1.0424774885177612\n",
      "fps: 4.121279056399654\n",
      "TIMESTEP 429109 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.376913 / Loss  0.004978401120752096\n",
      "fps: 4.75624481205463\n",
      "TIMESTEP 429110 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.618919 / Loss  0.03691447898745537\n",
      "fps: 4.282620193633102\n",
      "TIMESTEP 429111 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.554656 / Loss  0.028146499767899513\n",
      "fps: 2.9120397241747042\n",
      "TIMESTEP 429112 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.646421 / Loss  0.010418682359158993\n",
      "fps: 4.318779873514433\n",
      "TIMESTEP 429113 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD -1 / Q_MAX  8.605078 / Loss  0.00921613909304142\n",
      "fps: 4.536256053851428\n",
      "TIMESTEP 429114 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.293965 / Loss  0.010509833693504333\n",
      "fps: 4.695344177142921\n",
      "TIMESTEP 429115 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.491486 / Loss  0.10368257761001587\n",
      "fps: 4.999873641346459\n",
      "TIMESTEP 429116 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.509252 / Loss  0.07886111736297607\n",
      "fps: 4.997699127908708\n",
      "TIMESTEP 429117 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  5.4208336 / Loss  0.2779267430305481\n",
      "fps: 4.603115932167675\n",
      "TIMESTEP 429118 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.607552 / Loss  0.016539933159947395\n",
      "fps: 5.050682587486438\n",
      "TIMESTEP 429119 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.731409 / Loss  0.01059296727180481\n",
      "fps: 5.235465272308094\n",
      "TIMESTEP 429120 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.5514765 / Loss  0.012302334420382977\n",
      "fps: 4.818114983090722\n",
      "TIMESTEP 429121 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.620953 / Loss  0.0076992628164589405\n",
      "fps: 5.156451428494153\n",
      "TIMESTEP 429122 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.604235 / Loss  0.021876133978366852\n",
      "fps: 5.121400382917204\n",
      "TIMESTEP 429123 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.71608 / Loss  0.007184860296547413\n",
      "fps: 4.8549118562846525\n",
      "TIMESTEP 429124 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.783642 / Loss  0.00830345693975687\n",
      "fps: 5.089785611051582\n",
      "TIMESTEP 429125 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.6102295 / Loss  0.02451838180422783\n",
      "fps: 5.251268902071058\n",
      "TIMESTEP 429126 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.718962 / Loss  2.939181089401245\n",
      "fps: 4.955984265831355\n",
      "TIMESTEP 429127 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.810514 / Loss  0.003943181596696377\n",
      "fps: 5.311074192633413\n",
      "TIMESTEP 429128 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.46119 / Loss  1.1337233781814575\n",
      "fps: 5.331658783315685\n",
      "TIMESTEP 429129 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  7.8473396 / Loss  0.028474699705839157\n",
      "fps: 4.976087090635573\n",
      "TIMESTEP 429130 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.630305 / Loss  0.005667202174663544\n",
      "fps: 5.249264417848208\n",
      "TIMESTEP 429131 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.681681 / Loss  0.010455643758177757\n",
      "fps: 5.449405662865525\n",
      "TIMESTEP 429132 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.771088 / Loss  0.34648266434669495\n",
      "fps: 4.929528367414818\n",
      "TIMESTEP 429133 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.467139 / Loss  0.03000275418162346\n",
      "fps: 5.679360123057425\n",
      "TIMESTEP 429134 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.64958 / Loss  0.7639719843864441\n",
      "fps: 5.478102890488984\n",
      "TIMESTEP 429135 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.556594 / Loss  0.007764089852571487\n",
      "fps: 4.596054298325202\n",
      "TIMESTEP 429136 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.700409 / Loss  0.049020446836948395\n",
      "fps: 5.666362699284393\n",
      "TIMESTEP 429137 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.513871 / Loss  0.015463637188076973\n",
      "fps: 5.357271131842671\n",
      "TIMESTEP 429138 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.732026 / Loss  0.02129429206252098\n",
      "fps: 5.192885494897871\n",
      "TIMESTEP 429139 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.580378 / Loss  0.02472435124218464\n",
      "fps: 5.7983712098695115\n",
      "TIMESTEP 429140 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.482717 / Loss  0.02454090304672718\n",
      "fps: 5.413597806838657\n",
      "TIMESTEP 429141 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.406587 / Loss  0.021433399990200996\n",
      "fps: 5.175265160675771\n",
      "TIMESTEP 429142 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.664364 / Loss  0.04721621423959732\n",
      "fps: 5.140802931785729\n",
      "TIMESTEP 429143 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.424865 / Loss  0.7262346148490906\n",
      "fps: 4.892178097834138\n",
      "TIMESTEP 429144 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.488047 / Loss  0.00866292230784893\n",
      "fps: 5.116258985434235\n",
      "TIMESTEP 429145 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.482686 / Loss  0.012332096695899963\n",
      "fps: 5.92887281835697\n",
      "TIMESTEP 429146 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.645125 / Loss  0.013917173258960247\n",
      "fps: 5.300489697398601\n",
      "TIMESTEP 429147 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.529453 / Loss  0.011140967719256878\n",
      "fps: 3.265788170512553\n",
      "TIMESTEP 429148 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.509846 / Loss  0.041461534798145294\n",
      "fps: 5.054742484718767\n",
      "TIMESTEP 429149 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.838001 / Loss  0.02893991209566593\n",
      "fps: 5.655688719647038\n",
      "TIMESTEP 429150 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.628494 / Loss  0.01996360346674919\n",
      "fps: 5.403095282875465\n",
      "TIMESTEP 429151 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.67092 / Loss  0.011063055135309696\n",
      "fps: 5.643239635974189\n",
      "TIMESTEP 429152 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.904282 / Loss  0.09349574148654938\n",
      "fps: 5.824823559800798\n",
      "TIMESTEP 429153 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.7204895 / Loss  1.1091020107269287\n",
      "fps: 5.401049741685252\n",
      "TIMESTEP 429154 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.721639 / Loss  0.0033871878404170275\n",
      "fps: 5.799830470272147\n",
      "TIMESTEP 429155 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.715354 / Loss  0.019985351711511612\n",
      "fps: 5.795286731219879\n",
      "TIMESTEP 429156 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.696859 / Loss  0.03288435563445091\n",
      "fps: 5.494889363430323\n",
      "TIMESTEP 429157 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.649497 / Loss  0.011021438986063004\n",
      "fps: 5.571745301754428\n",
      "TIMESTEP 429158 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  5.0592294 / Loss  0.30216845870018005\n",
      "fps: 4.81192959994126\n",
      "TIMESTEP 429159 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.978054 / Loss  0.010707298293709755\n",
      "fps: 5.3060887826229965\n",
      "TIMESTEP 429160 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.088553 / Loss  1.0625627040863037\n",
      "fps: 5.753503429355281\n",
      "TIMESTEP 429161 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.007852 / Loss  0.017848053947091103\n",
      "fps: 5.770244261471897\n",
      "TIMESTEP 429162 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.795235 / Loss  0.21677909791469574\n",
      "fps: 5.567344858344306\n",
      "TIMESTEP 429163 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.964533 / Loss  0.02965010330080986\n",
      "fps: 5.200444373908903\n",
      "TIMESTEP 429164 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.741169 / Loss  0.018575983121991158\n",
      "fps: 5.6248720950660545\n",
      "TIMESTEP 429165 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.746373 / Loss  0.007198052480816841\n",
      "fps: 5.531222636015487\n",
      "TIMESTEP 429166 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.702425 / Loss  0.0375806987285614\n",
      "fps: 5.7750668476809155\n",
      "TIMESTEP 429167 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.821135 / Loss  0.44156327843666077\n",
      "fps: 6.001035869114218\n",
      "TIMESTEP 429168 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.930331 / Loss  0.2253722995519638\n",
      "fps: 5.674987755146221\n",
      "TIMESTEP 429169 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.978481 / Loss  0.018990520387887955\n",
      "fps: 5.4866375916008465\n",
      "TIMESTEP 429170 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  9.118031 / Loss  0.022768083959817886\n",
      "fps: 5.941546446663116\n",
      "TIMESTEP 429171 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.828027 / Loss  0.012164372950792313\n",
      "fps: 5.677691834950063\n",
      "TIMESTEP 429172 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.09263 / Loss  0.008030526340007782\n",
      "fps: 6.055357606906708\n",
      "TIMESTEP 429173 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.935163 / Loss  0.01558811217546463\n",
      "fps: 5.327372121852582\n",
      "TIMESTEP 429174 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.880579 / Loss  0.012812584638595581\n",
      "fps: 5.07132346628975\n",
      "TIMESTEP 429175 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  9.044485 / Loss  0.07408911734819412\n",
      "fps: 6.109069723407664\n",
      "TIMESTEP 429176 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.903749 / Loss  0.048991989344358444\n",
      "fps: 5.690934377183639\n",
      "TIMESTEP 429177 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.047651 / Loss  0.7866562008857727\n",
      "fps: 5.5215382306556124\n",
      "TIMESTEP 429178 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.160178 / Loss  0.004093674011528492\n",
      "fps: 6.148815771727466\n",
      "TIMESTEP 429179 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.110049 / Loss  0.008479341864585876\n",
      "fps: 5.400263942267457\n",
      "TIMESTEP 429180 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.975872 / Loss  3.267063856124878\n",
      "fps: 5.323740970668237\n",
      "TIMESTEP 429181 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.976813 / Loss  0.017551057040691376\n",
      "fps: 5.978138758592774\n",
      "TIMESTEP 429182 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.056885 / Loss  0.03013872355222702\n",
      "fps: 4.7809832335752525\n",
      "TIMESTEP 429183 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.833072 / Loss  0.043312784284353256\n",
      "fps: 3.11383917302901\n",
      "TIMESTEP 429184 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.926113 / Loss  0.0030604014173150063\n",
      "fps: 5.9485911058415075\n",
      "TIMESTEP 429185 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.8585415 / Loss  0.020023059099912643\n",
      "fps: 6.029547529200359\n",
      "TIMESTEP 429186 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.873472 / Loss  0.021835410967469215\n",
      "fps: 5.618715907020609\n",
      "TIMESTEP 429187 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.023245 / Loss  0.012461032718420029\n",
      "fps: 5.448881787062117\n",
      "TIMESTEP 429188 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  9.131274 / Loss  0.01553608849644661\n",
      "fps: 5.454110897418393\n",
      "TIMESTEP 429189 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.987549 / Loss  0.042333830147981644\n",
      "fps: 5.6159022684244215\n",
      "TIMESTEP 429190 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.889832 / Loss  0.011690812185406685\n",
      "fps: 6.161470536819977\n",
      "TIMESTEP 429191 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.900679 / Loss  0.01693754829466343\n",
      "fps: 5.3635395260631995\n",
      "TIMESTEP 429192 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  9.02238 / Loss  0.011283330619335175\n",
      "fps: 5.57727233439933\n",
      "TIMESTEP 429193 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.014576 / Loss  0.16112498939037323\n",
      "fps: 5.48739129695311\n",
      "TIMESTEP 429194 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.948872 / Loss  0.6450316905975342\n",
      "fps: 5.884776734227724\n",
      "TIMESTEP 429195 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.930048 / Loss  0.010249897837638855\n",
      "fps: 5.626418911124048\n",
      "TIMESTEP 429196 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.835626 / Loss  0.01489624660462141\n",
      "fps: 6.137487909556901\n",
      "TIMESTEP 429197 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.040034 / Loss  0.028932999819517136\n",
      "fps: 5.556790013871096\n",
      "TIMESTEP 429198 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  9.04891 / Loss  0.00786692462861538\n",
      "fps: 5.570864656660911\n",
      "TIMESTEP 429199 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.000224 / Loss  0.016861703246831894\n",
      "fps: 6.012864935381439\n",
      "TIMESTEP 429200 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.872556 / Loss  0.02008562907576561\n",
      "fps: 6.033910594111537\n",
      "TIMESTEP 429201 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.143648 / Loss  0.34382665157318115\n",
      "fps: 5.606578764449862\n",
      "TIMESTEP 429202 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.8721075 / Loss  1.440270185470581\n",
      "fps: 5.901377873266051\n",
      "TIMESTEP 429203 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.488726 / Loss  0.03785651922225952\n",
      "fps: 5.7715464394176035\n",
      "TIMESTEP 429204 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.914652 / Loss  0.03784572705626488\n",
      "fps: 5.190250856316946\n",
      "TIMESTEP 429205 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.756221 / Loss  0.23264169692993164\n",
      "fps: 5.829543385532272\n",
      "TIMESTEP 429206 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.874492 / Loss  0.007837177254259586\n",
      "fps: 5.918582352501245\n",
      "TIMESTEP 429207 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.785888 / Loss  0.018990162760019302\n",
      "fps: 5.600552270035478\n",
      "TIMESTEP 429208 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.712022 / Loss  0.0061917416751384735\n",
      "fps: 6.169436877438031\n",
      "TIMESTEP 429209 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.791842 / Loss  2.501275062561035\n",
      "fps: 5.250033170194389\n",
      "TIMESTEP 429210 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.814829 / Loss  0.0023641251027584076\n",
      "fps: 4.920414486133156\n",
      "TIMESTEP 429211 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.753646 / Loss  0.032704632729291916\n",
      "fps: 6.1266222905830094\n",
      "TIMESTEP 429212 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.734581 / Loss  0.1292477548122406\n",
      "fps: 5.760243467321846\n",
      "TIMESTEP 429213 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.34878 / Loss  0.007361839059740305\n",
      "fps: 5.612017463696464\n",
      "TIMESTEP 429214 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.840482 / Loss  0.0411732941865921\n",
      "fps: 5.70955007541396\n",
      "TIMESTEP 429215 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.632752 / Loss  0.005970838479697704\n",
      "fps: 5.348431291538512\n",
      "TIMESTEP 429216 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.593423 / Loss  0.25816255807876587\n",
      "fps: 4.898308489318865\n",
      "TIMESTEP 429217 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.68562 / Loss  0.009820620529353619\n",
      "fps: 5.817705682046729\n",
      "TIMESTEP 429218 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.61063 / Loss  0.011876396834850311\n",
      "fps: 4.961201578858344\n",
      "TIMESTEP 429219 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.756687 / Loss  0.007131473161280155\n",
      "fps: 1.91371565633545\n",
      "TIMESTEP 429220 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.76063 / Loss  0.01933431439101696\n",
      "fps: 4.97259461945929\n",
      "TIMESTEP 429221 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD -1 / Q_MAX  8.773567 / Loss  0.02180250734090805\n",
      "fps: 5.283483571245018\n",
      "TIMESTEP 429222 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  5.93378 / Loss  0.2410023957490921\n",
      "fps: 5.285021439704846\n",
      "TIMESTEP 429223 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.459451 / Loss  0.04547618329524994\n",
      "fps: 5.655154932463954\n",
      "TIMESTEP 429224 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.737758 / Loss  0.057348284870386124\n",
      "fps: 5.4495897512521845\n",
      "TIMESTEP 429225 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.763506 / Loss  0.012070169672369957\n",
      "fps: 5.313301165319858\n",
      "TIMESTEP 429226 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.667513 / Loss  0.01193974632769823\n",
      "fps: 5.753377154959562\n",
      "TIMESTEP 429227 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.497205 / Loss  0.146408811211586\n",
      "fps: 5.316378938829315\n",
      "TIMESTEP 429228 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.28229 / Loss  0.08085083961486816\n",
      "fps: 4.941224425362171\n",
      "TIMESTEP 429229 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.699082 / Loss  0.019317667931318283\n",
      "fps: 5.396748032336967\n",
      "TIMESTEP 429230 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.834983 / Loss  0.008591396734118462\n",
      "fps: 4.903359153793456\n",
      "TIMESTEP 429231 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.695183 / Loss  0.03440754860639572\n",
      "fps: 4.806674306669723\n",
      "TIMESTEP 429232 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.797709 / Loss  0.02898998185992241\n",
      "fps: 5.277573448456793\n",
      "TIMESTEP 429233 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.847951 / Loss  0.029478758573532104\n",
      "fps: 2.455445730035289\n",
      "TIMESTEP 429234 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.869683 / Loss  2.9080891609191895\n",
      "fps: 2.9763322805043075\n",
      "TIMESTEP 429235 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.957679 / Loss  0.007386010605841875\n",
      "fps: 4.5839187588250985\n",
      "TIMESTEP 429236 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.928158 / Loss  0.00719965947791934\n",
      "fps: 5.161318268068842\n",
      "TIMESTEP 429237 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.838879 / Loss  0.005320476368069649\n",
      "fps: 5.326600848841669\n",
      "TIMESTEP 429238 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.009653 / Loss  0.011282112449407578\n",
      "fps: 4.9617943500686135\n",
      "TIMESTEP 429239 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.74954 / Loss  0.011363123543560505\n",
      "fps: 4.610483087326817\n",
      "TIMESTEP 429240 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.735811 / Loss  0.1571861356496811\n",
      "fps: 4.210083392555298\n",
      "TIMESTEP 429241 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.943444 / Loss  0.1417538821697235\n",
      "fps: 5.193477049566003\n",
      "TIMESTEP 429242 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.697014 / Loss  0.04140559583902359\n",
      "fps: 4.227775297026559\n",
      "TIMESTEP 429243 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.9687 / Loss  0.0160503126680851\n",
      "fps: 4.531590263297211\n",
      "TIMESTEP 429244 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.915444 / Loss  0.07106950134038925\n",
      "fps: 5.432424066199793\n",
      "TIMESTEP 429245 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.797569 / Loss  0.13854292035102844\n",
      "fps: 4.539717484221999\n",
      "TIMESTEP 429246 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.9672985 / Loss  0.12192569673061371\n",
      "fps: 4.506999634652168\n",
      "TIMESTEP 429247 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.954297 / Loss  0.011847885325551033\n",
      "fps: 5.6356419785931\n",
      "TIMESTEP 429248 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.838321 / Loss  0.017872467637062073\n",
      "fps: 4.577470306986958\n",
      "TIMESTEP 429249 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.881132 / Loss  0.016923343762755394\n",
      "fps: 4.660306709066384\n",
      "TIMESTEP 429250 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.885846 / Loss  0.010966692119836807\n",
      "fps: 5.621886506171697\n",
      "TIMESTEP 429251 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.745501 / Loss  0.0191606767475605\n",
      "fps: 4.637403242408931\n",
      "TIMESTEP 429252 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.985917 / Loss  0.05482003837823868\n",
      "fps: 4.60116677307602\n",
      "TIMESTEP 429253 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.686878 / Loss  0.00658716494217515\n",
      "fps: 5.528925892189805\n",
      "TIMESTEP 429254 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.98751 / Loss  0.01918925903737545\n",
      "fps: 4.477377219978714\n",
      "TIMESTEP 429255 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.634545 / Loss  0.011663731187582016\n",
      "fps: 2.9462885706478485\n",
      "TIMESTEP 429256 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.947851 / Loss  0.023475192487239838\n",
      "fps: 5.221959524654354\n",
      "TIMESTEP 429257 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.933425 / Loss  0.0037611054722219706\n",
      "fps: 5.461048903702932\n",
      "TIMESTEP 429258 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.9755535 / Loss  0.010135103017091751\n",
      "fps: 4.776371769293139\n",
      "TIMESTEP 429259 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.880264 / Loss  0.0036419059615582228\n",
      "fps: 5.263876286537928\n",
      "TIMESTEP 429260 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.007666 / Loss  0.25942105054855347\n",
      "fps: 5.366964212595201\n",
      "TIMESTEP 429261 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.851893 / Loss  0.020604418590664864\n",
      "fps: 4.992535545728859\n",
      "TIMESTEP 429262 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.947114 / Loss  0.6662548780441284\n",
      "fps: 5.498671316294893\n",
      "TIMESTEP 429263 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.040037 / Loss  0.016452606767416\n",
      "fps: 5.151397617559171\n",
      "TIMESTEP 429264 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.003889 / Loss  0.011156907305121422\n",
      "fps: 5.074520109080966\n",
      "TIMESTEP 429265 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.929808 / Loss  0.02996852621436119\n",
      "fps: 5.486214171823518\n",
      "TIMESTEP 429266 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.010566 / Loss  0.008600945584475994\n",
      "fps: 5.525983017463423\n",
      "TIMESTEP 429267 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.14876 / Loss  0.008844736963510513\n",
      "fps: 4.962510559655844\n",
      "TIMESTEP 429268 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.038928 / Loss  0.013779458589851856\n",
      "fps: 5.2144676692869725\n",
      "TIMESTEP 429269 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.083942 / Loss  0.005136125721037388\n",
      "fps: 5.436705341298985\n",
      "TIMESTEP 429270 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.056509 / Loss  0.07736944407224655\n",
      "fps: 5.007609964827492\n",
      "TIMESTEP 429271 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.08387 / Loss  0.014503412880003452\n",
      "fps: 5.514257279172895\n",
      "TIMESTEP 429272 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.023438 / Loss  0.017837131395936012\n",
      "fps: 5.571989563572404\n",
      "TIMESTEP 429273 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.630742 / Loss  0.12998101115226746\n",
      "fps: 5.221276966550896\n",
      "TIMESTEP 429274 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.193465 / Loss  0.005302694626152515\n",
      "fps: 5.608362995509891\n",
      "TIMESTEP 429275 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.167404 / Loss  0.010394241660833359\n",
      "fps: 5.857745587806046\n",
      "TIMESTEP 429276 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.199046 / Loss  0.0032995278015732765\n",
      "fps: 5.162595191527754\n",
      "TIMESTEP 429277 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.149211 / Loss  0.007847953587770462\n",
      "fps: 5.841323603141886\n",
      "TIMESTEP 429278 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.861545 / Loss  0.05855889245867729\n",
      "fps: 5.61558647429924\n",
      "TIMESTEP 429279 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.203072 / Loss  0.00457004364579916\n",
      "fps: 4.926181921964316\n",
      "TIMESTEP 429280 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.340362 / Loss  0.11587652564048767\n",
      "fps: 6.019423216297477\n",
      "TIMESTEP 429281 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.28498 / Loss  2.6049344539642334\n",
      "fps: 4.700358720976492\n",
      "TIMESTEP 429282 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.879044 / Loss  0.006666922476142645\n",
      "fps: 2.573974305080377\n",
      "TIMESTEP 429283 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.1432705 / Loss  0.05181910842657089\n",
      "fps: 3.235796392587678\n",
      "TIMESTEP 429284 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.147738 / Loss  0.02384774014353752\n",
      "fps: 3.15825204849832\n",
      "TIMESTEP 429285 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.190517 / Loss  0.0068908026441931725\n",
      "fps: 4.596114734553615\n",
      "TIMESTEP 429286 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.778642 / Loss  0.015119867399334908\n",
      "fps: 4.960767361131645\n",
      "TIMESTEP 429287 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.135902 / Loss  0.02096741646528244\n",
      "fps: 4.916809486855463\n",
      "TIMESTEP 429288 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.126168 / Loss  0.08789879083633423\n",
      "fps: 4.80270599241287\n",
      "TIMESTEP 429289 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.136392 / Loss  0.6929103136062622\n",
      "fps: 5.798884272668828\n",
      "TIMESTEP 429290 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.107314 / Loss  0.05111399292945862\n",
      "fps: 4.736056801462493\n",
      "TIMESTEP 429291 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.053755 / Loss  0.014208300970494747\n",
      "fps: 3.1905989888801156\n",
      "TIMESTEP 429292 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.11237 / Loss  0.025319892913103104\n",
      "fps: 5.475549799871019\n",
      "TIMESTEP 429293 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  1.0088058 / Loss  0.8541362285614014\n",
      "fps: 5.724683691157001\n",
      "TIMESTEP 429294 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.174964 / Loss  0.015757355839014053\n",
      "fps: 5.277852369261821\n",
      "TIMESTEP 429295 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.977785 / Loss  0.004064834211021662\n",
      "fps: 5.5970620889913745\n",
      "TIMESTEP 429296 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.185742 / Loss  0.005382044240832329\n",
      "fps: 5.627747588187149\n",
      "TIMESTEP 429297 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.730673 / Loss  0.023578114807605743\n",
      "fps: 5.162461752057327\n",
      "TIMESTEP 429298 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.179766 / Loss  0.04636165127158165\n",
      "fps: 5.664663784569299\n",
      "TIMESTEP 429299 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.804998 / Loss  0.20130057632923126\n",
      "fps: 5.650096586209591\n",
      "TIMESTEP 429300 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.158423 / Loss  0.007337985094636679\n",
      "fps: 5.351543082285813\n",
      "TIMESTEP 429301 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.197269 / Loss  0.004837619140744209\n",
      "fps: 5.453011810102292\n",
      "TIMESTEP 429302 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.161065 / Loss  0.011298483237624168\n",
      "fps: 5.444581320753982\n",
      "TIMESTEP 429303 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.236102 / Loss  0.014986995607614517\n",
      "fps: 5.39846372454128\n",
      "TIMESTEP 429304 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.163743 / Loss  0.013769678771495819\n",
      "fps: 5.664434279633149\n",
      "TIMESTEP 429305 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.318455 / Loss  0.00434559490531683\n",
      "fps: 5.428641320174729\n",
      "TIMESTEP 429306 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.381285 / Loss  0.020254436880350113\n",
      "fps: 5.284408848034491\n",
      "TIMESTEP 429307 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.350475 / Loss  0.012077542021870613\n",
      "fps: 5.671603606088757\n",
      "TIMESTEP 429308 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.356244 / Loss  0.011031992733478546\n",
      "fps: 5.166175213517302\n",
      "TIMESTEP 429309 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.436103 / Loss  0.10874642431735992\n",
      "fps: 5.125662505575618\n",
      "TIMESTEP 429310 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.239376 / Loss  0.04469480738043785\n",
      "fps: 4.918694963335276\n",
      "TIMESTEP 429311 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.263762 / Loss  0.005043116398155689\n",
      "fps: 4.78791988292478\n",
      "TIMESTEP 429312 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.427684 / Loss  0.006495137233287096\n",
      "fps: 4.758327604241116\n",
      "TIMESTEP 429313 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.486181 / Loss  0.013842832297086716\n",
      "fps: 5.609968274009834\n",
      "TIMESTEP 429314 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.500148 / Loss  0.01662147231400013\n",
      "fps: 4.890769080079664\n",
      "TIMESTEP 429315 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.400683 / Loss  3.3050692081451416\n",
      "fps: 5.229225185733752\n",
      "TIMESTEP 429316 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.645734 / Loss  0.00663556344807148\n",
      "fps: 5.6449029305878\n",
      "TIMESTEP 429317 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.245724 / Loss  0.012002328410744667\n",
      "fps: 5.223136543864193\n",
      "TIMESTEP 429318 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.538491 / Loss  0.012747270986437798\n",
      "fps: 5.188818992125789\n",
      "TIMESTEP 429319 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.381889 / Loss  0.011379674077033997\n",
      "fps: 5.5870268887817325\n",
      "TIMESTEP 429320 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.398885 / Loss  0.016091294586658478\n",
      "fps: 5.216867394951921\n",
      "TIMESTEP 429321 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.403857 / Loss  0.08964554220438004\n",
      "fps: 4.892434888907552\n",
      "TIMESTEP 429322 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.371848 / Loss  0.00326673686504364\n",
      "fps: 5.560775641484569\n",
      "TIMESTEP 429323 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.351956 / Loss  1.4419071674346924\n",
      "fps: 4.965589091176004\n",
      "TIMESTEP 429324 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.258439 / Loss  0.007488051429390907\n",
      "fps: 5.126314026920364\n",
      "TIMESTEP 429325 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.284957 / Loss  0.02272975631058216\n",
      "fps: 5.76066277156521\n",
      "TIMESTEP 429326 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.427132 / Loss  0.011282412335276604\n",
      "fps: 5.0433220506099286\n",
      "TIMESTEP 429327 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.212035 / Loss  0.024389665573835373\n",
      "fps: 3.384588569086114\n",
      "TIMESTEP 429328 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.255123 / Loss  0.00462206220254302\n",
      "fps: 5.831383191707078\n",
      "TIMESTEP 429329 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.109716 / Loss  0.004420443903654814\n",
      "fps: 5.808657790432613\n",
      "TIMESTEP 429330 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.238702 / Loss  0.02348659746348858\n",
      "fps: 5.576345458413104\n",
      "TIMESTEP 429331 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.1758678 / Loss  0.05787871778011322\n",
      "fps: 5.785901301940357\n",
      "TIMESTEP 429332 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.193785 / Loss  0.004522418137639761\n",
      "fps: 5.919467766360271\n",
      "TIMESTEP 429333 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.238405 / Loss  0.009019729681313038\n",
      "fps: 5.571308644599118\n",
      "TIMESTEP 429334 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.05011 / Loss  0.030260005965828896\n",
      "fps: 5.7379503567832595\n",
      "TIMESTEP 429335 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.033849 / Loss  0.01879340037703514\n",
      "fps: 5.812223631060023\n",
      "TIMESTEP 429336 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.321735 / Loss  0.04005593806505203\n",
      "fps: 5.51240925029308\n",
      "TIMESTEP 429337 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.235891 / Loss  0.013372456654906273\n",
      "fps: 5.841461903030962\n",
      "TIMESTEP 429338 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.04892 / Loss  0.30267831683158875\n",
      "fps: 5.892887600683942\n",
      "TIMESTEP 429339 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.303736 / Loss  0.005952739156782627\n",
      "fps: 5.535938758001715\n",
      "TIMESTEP 429340 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.20088 / Loss  0.10138391703367233\n",
      "fps: 5.754766478239394\n",
      "TIMESTEP 429341 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.293717 / Loss  0.034122396260499954\n",
      "fps: 5.851616332555314\n",
      "TIMESTEP 429342 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.190225 / Loss  0.0077203367836773396\n",
      "fps: 5.685696237193199\n",
      "TIMESTEP 429343 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.071235 / Loss  0.006577848456799984\n",
      "fps: 6.038688573682786\n",
      "TIMESTEP 429344 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.323184 / Loss  0.053644463419914246\n",
      "fps: 5.968186209850351\n",
      "TIMESTEP 429345 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.387764 / Loss  0.010890938341617584\n",
      "fps: 5.718806200514574\n",
      "TIMESTEP 429346 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.365585 / Loss  0.009155385196208954\n",
      "fps: 5.945690324848746\n",
      "TIMESTEP 429347 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.138828 / Loss  2.6672470569610596\n",
      "fps: 6.056494303495877\n",
      "TIMESTEP 429348 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.308083 / Loss  0.013035125099122524\n",
      "fps: 5.607170883326092\n",
      "TIMESTEP 429349 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.279796 / Loss  0.015298032201826572\n",
      "fps: 5.889453671304123\n",
      "TIMESTEP 429350 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.048722 / Loss  0.06009151041507721\n",
      "fps: 5.910900409815273\n",
      "TIMESTEP 429351 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.192425 / Loss  0.7578282356262207\n",
      "fps: 5.609120512460466\n",
      "TIMESTEP 429352 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.315495 / Loss  0.024522997438907623\n",
      "fps: 5.860528415354757\n",
      "TIMESTEP 429353 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.1067095 / Loss  0.023200079798698425\n",
      "fps: 5.937223438017559\n",
      "TIMESTEP 429354 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.978818 / Loss  0.011460153385996819\n",
      "fps: 5.648825805478452\n",
      "TIMESTEP 429355 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.115751 / Loss  0.15344975888729095\n",
      "fps: 5.805152564517781\n",
      "TIMESTEP 429356 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.174806 / Loss  0.16655021905899048\n",
      "fps: 5.336638059915134\n",
      "TIMESTEP 429357 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.0163965 / Loss  0.02523810602724552\n",
      "fps: 4.500364809998369\n",
      "TIMESTEP 429358 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.035055 / Loss  0.007518816739320755\n",
      "fps: 5.391240191006253\n",
      "TIMESTEP 429359 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.010755 / Loss  0.027037562802433968\n",
      "fps: 4.896198541986471\n",
      "TIMESTEP 429360 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.014538 / Loss  0.004341672640293837\n",
      "fps: 4.626951750370107\n",
      "TIMESTEP 429361 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.053083 / Loss  0.0021768114529550076\n",
      "fps: 3.9177134317205304\n",
      "TIMESTEP 429362 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.002557 / Loss  0.008378259837627411\n",
      "fps: 4.2674133250853625\n",
      "TIMESTEP 429363 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.070974 / Loss  0.0044001126661896706\n",
      "fps: 3.386444063535227\n",
      "TIMESTEP 429364 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.124373 / Loss  0.054372578859329224\n",
      "fps: 4.261520970263974\n",
      "TIMESTEP 429365 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.129461 / Loss  0.01976902410387993\n",
      "fps: 5.445471978105441\n",
      "TIMESTEP 429366 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.982271 / Loss  0.004989803768694401\n",
      "fps: 4.13126909613123\n",
      "TIMESTEP 429367 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.040121 / Loss  0.017059653997421265\n",
      "fps: 4.593457043228373\n",
      "TIMESTEP 429368 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.048194 / Loss  0.012341476045548916\n",
      "fps: 5.293358792787722\n",
      "TIMESTEP 429369 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.987692 / Loss  0.06614575535058975\n",
      "fps: 4.7483403523072045\n",
      "TIMESTEP 429370 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.066959 / Loss  0.017178911715745926\n",
      "fps: 5.1140693775528865\n",
      "TIMESTEP 429371 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.165279 / Loss  0.01097381953150034\n",
      "fps: 5.1343086262129445\n",
      "TIMESTEP 429372 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.066994 / Loss  0.0059005264192819595\n",
      "fps: 4.691620460425571\n",
      "TIMESTEP 429373 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.18784 / Loss  0.020855434238910675\n",
      "fps: 5.1976990014300695\n",
      "TIMESTEP 429374 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.301828 / Loss  0.025555897504091263\n",
      "fps: 5.210852796002569\n",
      "TIMESTEP 429375 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.168473 / Loss  0.08282947540283203\n",
      "fps: 4.904322366251727\n",
      "TIMESTEP 429376 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.114052 / Loss  0.010512028820812702\n",
      "fps: 5.294000189328201\n",
      "TIMESTEP 429377 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.201032 / Loss  0.017616774886846542\n",
      "fps: 5.300985426506292\n",
      "TIMESTEP 429378 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.2471695 / Loss  0.009254668839275837\n",
      "fps: 4.685697815622106\n",
      "TIMESTEP 429379 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.464777 / Loss  0.017872683703899384\n",
      "fps: 4.140927445230973\n",
      "TIMESTEP 429380 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.204223 / Loss  0.009989175014197826\n",
      "fps: 5.197808503018203\n",
      "TIMESTEP 429381 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.221197 / Loss  0.006778037175536156\n",
      "fps: 4.743947211860592\n",
      "TIMESTEP 429382 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.329036 / Loss  0.005937646143138409\n",
      "fps: 5.197209521331301\n",
      "TIMESTEP 429383 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.281035 / Loss  0.3325318694114685\n",
      "fps: 4.73265271120499\n",
      "TIMESTEP 429384 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.29479 / Loss  0.010442065075039864\n",
      "fps: 5.068559565155393\n",
      "TIMESTEP 429385 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.435376 / Loss  0.02015625312924385\n",
      "fps: 5.2899406343685005\n",
      "TIMESTEP 429386 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.308567 / Loss  0.4879727065563202\n",
      "fps: 4.9654656414445455\n",
      "TIMESTEP 429387 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.914708 / Loss  0.0074060093611478806\n",
      "fps: 4.31296665148223\n",
      "TIMESTEP 429388 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.479308 / Loss  0.05655830353498459\n",
      "fps: 4.863840880205579\n",
      "TIMESTEP 429389 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.334342 / Loss  0.09310805052518845\n",
      "fps: 5.212944665259746\n",
      "TIMESTEP 429390 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.349134 / Loss  0.017819039523601532\n",
      "fps: 5.0353420819162205\n",
      "TIMESTEP 429391 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.309655 / Loss  0.08815017342567444\n",
      "fps: 5.063315833123081\n",
      "TIMESTEP 429392 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.2300625 / Loss  3.3403148651123047\n",
      "fps: 4.755764841412294\n",
      "TIMESTEP 429393 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.398235 / Loss  0.011010176502168179\n",
      "fps: 4.2854249915963125\n",
      "TIMESTEP 429394 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.157512 / Loss  0.01144922524690628\n",
      "fps: 4.7143378993380844\n",
      "TIMESTEP 429395 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.265171 / Loss  0.004961269907653332\n",
      "fps: 4.446675042009234\n",
      "TIMESTEP 429396 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  8.997201 / Loss  0.02229420654475689\n",
      "fps: 4.8353338836191595\n",
      "TIMESTEP 429397 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.332919 / Loss  0.03603348508477211\n",
      "fps: 5.074851661488128\n",
      "TIMESTEP 429398 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  7.855269 / Loss  0.06578496098518372\n",
      "fps: 5.071249886648732\n",
      "TIMESTEP 429399 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.286731 / Loss  0.07325425744056702\n",
      "fps: 3.310787300885654\n",
      "TIMESTEP 429400 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.376942 / Loss  0.016929613426327705\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-72cb52f7ef17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplay_Game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-e511e924bf20>\u001b[0m in \u001b[0;36mplay_Game\u001b[0;34m(observe)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain_Network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgame_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-e1b764ad5ca8>\u001b[0m in \u001b[0;36mtrain_Network\u001b[0;34m(model, game_state, observe)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m#run the selected action and observed next state and reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mx_t1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fps: {0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlast_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# helpful for measuring frame rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mlast_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-999ca9103e92>\u001b[0m in \u001b[0;36mget_state\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrab_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_game\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_driver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#display the image on screen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_crashed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mscores_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;31m# log the score when game is over\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-14f251621639>\u001b[0m in \u001b[0;36mshow_img\u001b[0;34m(graphs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mimS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "play_Game(observe=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
